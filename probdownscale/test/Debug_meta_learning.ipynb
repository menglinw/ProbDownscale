{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import os\n",
    "import sys\n",
    "from importlib import reload\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import probdownscale\n",
    "reload(probdownscale.TaskExtractor)\n",
    "reload(probdownscale.MetaTrain)\n",
    "from probdownscale.MetaTrain import MetaSGD\n",
    "\n",
    "from probdownscale.TaskExtractor import TaskExtractor\n",
    "import math\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow_probability import distributions as tfd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Debug TaskExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\96349\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\96349\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \n",
      "C:\\Users\\96349\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\96349\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "C:\\Users\\96349\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\ipykernel_launcher.py:21: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "C:\\Users\\96349\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\ipykernel_launcher.py:22: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    }
   ],
   "source": [
    "file_path_g_05 = r'C:\\Users\\96349\\Documents\\Downscale_data\\MERRA2\\G5NR_aerosol_variables_over_MiddleEast_daily_20050516-20060515.nc'\n",
    "file_path_g_06 =  r'C:\\Users\\96349\\Documents\\Downscale_data\\MERRA2\\G5NR_aerosol_variables_over_MiddleEast_daily_20060516-20070515.nc'\n",
    "file_path_m = r'C:\\Users\\96349\\Documents\\Downscale_data\\MERRA2\\MERRA2_aerosol_variables_over_MiddleEast_daily_20000516-20180515.nc'\n",
    "target_var = 'BCSMASS'\n",
    "\n",
    "# read data\n",
    "g05_data = nc.Dataset(file_path_g_05)\n",
    "g06_data = nc.Dataset(file_path_g_06)\n",
    "m_data_nc = nc.Dataset(file_path_m)\n",
    "\n",
    "# define lat&lon of MERRA, G5NR and mete\n",
    "M_lons = m_data_nc.variables['lon'][:15]\n",
    "# self.M_lons = (M_lons-M_lons.mean())/M_lons.std()\n",
    "M_lats = m_data_nc.variables['lat'][:15]\n",
    "# self.M_lats = (M_lats-M_lats.mean())/M_lats.std()\n",
    "G_lons = g05_data.variables['lon'][:30]\n",
    "# self.G_lons = (G_lons-G_lons.mean())/G_lons.std()\n",
    "G_lats = g05_data.variables['lat'][:30]\n",
    "\n",
    "# extract target data\n",
    "g_data = np.concatenate((g05_data.variables[target_var][:, :30, :30], g06_data.variables[target_var][:, :30, :30]), axis=0)\n",
    "m_data = m_data_nc.variables[target_var][5*365:7*365, :15, :15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_g_data, test_g_data = g_data[:657], g_data[657:]\n",
    "train_m_data, test_m_data = m_data[:657], m_data[657:]\n",
    "data = [train_g_data, train_m_data]\n",
    "lats_lons = [G_lats, G_lons, M_lats, M_lons]\n",
    "task_dim = 3\n",
    "test_proportion = 0.3\n",
    "n_lag = 10\n",
    "taskextractor = TaskExtractor(data, lats_lons, task_dim, test_proportion, n_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y, location = taskextractor._get_one_random_task(return_init=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y, locations = taskextractor.get_random_tasks(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y, locations = taskextractor.get_random_tasks(locations=locations[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(12.0625, 25.75): 1,\n",
       " (11.75, 26.5): 1,\n",
       " (12.375, 25.8125): 1,\n",
       " (10.9375, 27.3125): 1,\n",
       " (11.375, 25.875): 1,\n",
       " (11.6875, 26.0625): 1,\n",
       " (11.125, 26.4375): 1,\n",
       " (11.875, 27.0625): 1,\n",
       " (12.625, 25.9375): 1,\n",
       " (12.0625, 26.9375): 1}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taskextractor.get_seen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(range(10))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 7, 8]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[6:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow_probability import distributions as tfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the last channel is the comonents\n",
    "alpha = np.random.rand(5)\n",
    "alpha = alpha/alpha.sum()\n",
    "mu = np.random.rand(3, 2, 5)\n",
    "mu = np.abs(mu)\n",
    "test_md = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=alpha),\n",
    "        components_distribution=tfd.Gamma(concentration=mu, rate=mu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float64, numpy=\n",
       "array([[ 7.44577378, 12.65164306],\n",
       "       [ 7.45454975,  4.21166889],\n",
       "       [ 6.20041569,  3.6764311 ]])>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_md.variance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96121876, 0.84317056],\n",
       "       [0.9761822 , 0.81684038],\n",
       "       [0.99552519, 0.81038832]])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_md.sample(100).numpy().mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float64, numpy=\n",
       "array([[-1.54147116, -1.3535997 ],\n",
       "       [-1.3061699 , -1.69724539],\n",
       "       [-1.56801883, -1.40614818]])>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_like = test_md.log_prob(np.ones((3,2)))\n",
    "#-tf.reduce_mean(log_like, axis=-1)\n",
    "log_like\n",
    "\n",
    "# when the Y is really small, log_prob return a positive log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float64, numpy=\n",
       "array([[0.15880819, 0.10569395],\n",
       "       [0.17997603, 0.15908541],\n",
       "       [0.20016422, 0.19627221]])>"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_md.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float64, numpy=\n",
       "array([[-1.07151844, -1.96976935],\n",
       "       [-0.88054633, -1.06112697],\n",
       "       [-1.63395563, -0.41498473]])>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =  np.random.rand(3,3,3)\n",
    "#a = (a - a.min())/(a.max() - a.min())\n",
    "a = a/a.sum()\n",
    "a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define necessary tool functions\n",
    "components = 100\n",
    "no_parameters = 2\n",
    "\n",
    "def nnelu(input):\n",
    "    return tf.add(tf.constant(1, dtype=tf.float32), tf.nn.elu(input))\n",
    "\n",
    "def slice_parameter_vectors(parameter_vector):\n",
    "    return [parameter_vector[:, i*components:(i+1)*components] for i in range(3*3*3)]\n",
    "\n",
    "def gamma_loss(y, parameter_vector):\n",
    "    a1, a2, a3, a4, a5, a6, a7, a8, a9, m1, m2, m3, m4, m5, m6, m7, m8, m9, s1, s2, s3, s4, s5, s6, s7, s8, s9 = slice_parameter_vectors(parameter_vector)  # Unpack parameter vectors\n",
    "    \n",
    "    gm1 = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=a1),\n",
    "        components_distribution=tfd.Gamma(\n",
    "        concentration=m1, rate=s1)\n",
    "    )\n",
    "    gm2 = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=a2),\n",
    "        components_distribution=tfd.Gamma(\n",
    "        concentration=m2, rate=s2)\n",
    "    )\n",
    "    gm3 = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=a3),\n",
    "        components_distribution=tfd.Gamma(\n",
    "        concentration=m3, rate=s3)\n",
    "    )\n",
    "    gm4 = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=a4),\n",
    "        components_distribution=tfd.Gamma(\n",
    "        concentration=m4, rate=s4)\n",
    "    )\n",
    "    gm5 = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=a5),\n",
    "        components_distribution=tfd.Gamma(\n",
    "        concentration=m5, rate=s5)\n",
    "    )\n",
    "    gm6 = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=a6),\n",
    "        components_distribution=tfd.Gamma(\n",
    "        concentration=m6, rate=s6)\n",
    "    )\n",
    "    gm7 = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=a7),\n",
    "        components_distribution=tfd.Gamma(\n",
    "        concentration=m7, rate=s7)\n",
    "    )\n",
    "    gm8 = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=a8),\n",
    "        components_distribution=tfd.Gamma(\n",
    "        concentration=m8, rate=s8)\n",
    "    )    \n",
    "    gm9 = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=a9),\n",
    "        components_distribution=tfd.Gamma(\n",
    "        concentration=m9, rate=s9)\n",
    "    )\n",
    "    '''\n",
    "    mae = tf.keras.losses.MeanAbsoluteError()\n",
    "    all_result = tf.concat([gm1.mean(), gm2.mean(), gm3.mean(), gm4.mean(), gm5.mean(), gm6.mean(), gm7.mean(), gm8.mean(), gm9.mean()], axis=0)\n",
    "    all_result = tf.reshape(all_result, (tf.shape(a1)[0], 3, 3))\n",
    "    avg_loss = mae(all_result, y)\n",
    "    '''\n",
    "    l1 = -tf.reduce_mean(gm1.log_prob(y[:, 0, 0]), axis=-1)\n",
    "    l2 = -tf.reduce_mean(gm1.log_prob(y[:, 0, 1]), axis=-1)\n",
    "    l3 = -tf.reduce_mean(gm1.log_prob(y[:, 0, 2]), axis=-1)\n",
    "    l4 = -tf.reduce_mean(gm1.log_prob(y[:, 1, 0]), axis=-1)\n",
    "    l5 = -tf.reduce_mean(gm1.log_prob(y[:, 1, 1]), axis=-1)\n",
    "    l6 = -tf.reduce_mean(gm1.log_prob(y[:, 1, 2]), axis=-1)\n",
    "    l7 = -tf.reduce_mean(gm1.log_prob(y[:, 2, 0]), axis=-1)\n",
    "    l8 = -tf.reduce_mean(gm1.log_prob(y[:, 2, 1]), axis=-1)\n",
    "    l9 = -tf.reduce_mean(gm1.log_prob(y[:, 2, 2]), axis=-1)\n",
    "    return tf.reduce_mean([l1, l2, l3, l4, l5, l6, l7, l8, l9])\n",
    "    '''\n",
    "    return tf.add(tf.reduce_mean([l1, l2, l3, l4, l5, l6, l7, l8, l9]),\n",
    "                  tf.reduce_mean([gm1.variance(), gm2.variance(), gm3.variance(), gm4.variance(), \n",
    "                                  gm5.variance(), gm6.variance(), gm7.variance(), gm8.variance(), gm9.variance(), ]))\n",
    "    '''\n",
    "\n",
    "tf.keras.utils.get_custom_objects().update({'nnelu': layers.Activation(nnelu)})\n",
    "\n",
    "def plot_history(history, title):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(title)\n",
    "    \n",
    "def model_generator():\n",
    "    # define MDN Exponentialmodel\n",
    "    # input dim (time, channel, rows, cols)\n",
    "    input1 = layers.Input(shape=(n_lag, 1, task_dim, task_dim)) \n",
    "    input1 = layers.BatchNormalization()(input1)\n",
    "    input2 = layers.Input(shape=(task_dim, task_dim, 1))\n",
    "    input2 = layers.BatchNormalization()(input2)\n",
    "    input3 = layers.Input(shape=(1))\n",
    "    input3 = layers.BatchNormalization()(input3)\n",
    "\n",
    "    X = layers.ConvLSTM2D(filters=20, kernel_size=(1,2), activation='tanh', return_sequences=True)(input1)\n",
    "    X = layers.ConvLSTM2D(filters=20, kernel_size=(1,2), activation='relu', return_sequences=True)(X)\n",
    "    X = layers.ConvLSTM2D(filters=20, kernel_size=(1,1), activation='relu')(X)\n",
    "    X = layers.Flatten()(X)\n",
    "    X = layers.Dense(512, activation='relu')(X)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    X = layers.Dense(300, activation='relu')(X)\n",
    "\n",
    "    X1 = layers.Conv2D(20, (2,2), activation='tanh')(input2)\n",
    "    X1 = layers.Flatten()(X1)\n",
    "    X2 = layers.BatchNormalization()(input3)\n",
    "\n",
    "    X = layers.Concatenate()([X, X1, X2])\n",
    "    X = layers.Dense(128, activation='relu')(X)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    X = layers.Dense(128, activation='relu')(X)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    alphas1 = layers.Dense(components, activation=\"softmax\")(X)\n",
    "    alphas2 = layers.Dense(components, activation=\"softmax\")(X)\n",
    "    alphas3 = layers.Dense(components, activation=\"softmax\")(X)\n",
    "    alphas4 = layers.Dense(components, activation=\"softmax\")(X)\n",
    "    alphas5 = layers.Dense(components, activation=\"softmax\")(X)\n",
    "    alphas6 = layers.Dense(components, activation=\"softmax\")(X)\n",
    "    alphas7 = layers.Dense(components, activation=\"softmax\")(X)\n",
    "    alphas8 = layers.Dense(components, activation=\"softmax\")(X)\n",
    "    alphas9 = layers.Dense(components, activation=\"softmax\")(X)\n",
    "    mus1 = layers.Dense(components, activation='nnelu')(X)\n",
    "    mus2 = layers.Dense(components, activation='nnelu')(X)\n",
    "    mus3 = layers.Dense(components, activation='nnelu')(X)\n",
    "    mus4 = layers.Dense(components, activation='nnelu')(X)\n",
    "    mus5 = layers.Dense(components, activation='nnelu')(X)\n",
    "    mus6 = layers.Dense(components, activation='nnelu')(X)\n",
    "    mus7 = layers.Dense(components, activation='nnelu')(X)\n",
    "    mus8 = layers.Dense(components, activation='nnelu')(X)\n",
    "    mus9 = layers.Dense(components, activation='nnelu')(X)\n",
    "    sigmas1 = layers.Dense(components, activation='nnelu')(X)\n",
    "    sigmas2 = layers.Dense(components, activation='nnelu')(X)\n",
    "    sigmas3 = layers.Dense(components, activation='nnelu')(X)\n",
    "    sigmas4 = layers.Dense(components, activation='nnelu')(X)\n",
    "    sigmas5 = layers.Dense(components, activation='nnelu')(X)\n",
    "    sigmas6 = layers.Dense(components, activation='nnelu')(X)\n",
    "    sigmas7 = layers.Dense(components, activation='nnelu')(X)\n",
    "    sigmas8 = layers.Dense(components, activation='nnelu')(X)\n",
    "    sigmas9 = layers.Dense(components, activation='nnelu')(X)\n",
    "    output = layers.Concatenate()([alphas1,  alphas2, alphas3, alphas4, alphas5, alphas6, alphas7, alphas8, alphas9, \n",
    "                                                               mus1,  mus2,  mus3,  mus4,  mus5,  mus6,  mus7,  mus8,  mus9, \n",
    "                                                               sigmas1,  sigmas2, sigmas3, sigmas4, sigmas5, sigmas6, sigmas7, sigmas8, sigmas9,])\n",
    "    model = Model([input1, input2, input3], output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "15/15 [==============================] - 17s 135ms/step - loss: 123.1448 - val_loss: 122.8864 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 28.5507 - val_loss: 117.5929 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 20.5919 - val_loss: 120.5214 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 18.3711 - val_loss: 118.5793 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 17.4290 - val_loss: 113.7974 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 16.8724 - val_loss: 108.0540 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 16.8763 - val_loss: 102.6829 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 16.7989 - val_loss: 97.7708 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 16.7493 - val_loss: 92.9243 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 16.8009 - val_loss: 88.4031 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 16.6811 - val_loss: 84.1044 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 16.5860 - val_loss: 78.7216 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 16.6431 - val_loss: 71.4814 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 16.5382 - val_loss: 63.9368 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 16.5970 - val_loss: 57.7792 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 16.5130 - val_loss: 51.6625 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 16.4799 - val_loss: 46.0740 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 16.4636 - val_loss: 41.5672 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 16.4156 - val_loss: 37.8738 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 16.4523 - val_loss: 34.9522 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 16.4077 - val_loss: 32.3582 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 16.3308 - val_loss: 30.3977 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 16.3859 - val_loss: 28.6587 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 16.3191 - val_loss: 27.1675 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 16.3124 - val_loss: 26.0075 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 16.3044 - val_loss: 24.8147 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 16.2465 - val_loss: 23.7284 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 16.2175 - val_loss: 22.8040 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 16.2739 - val_loss: 21.9405 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 1s 42ms/step - loss: 16.0562 - val_loss: 21.2987 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 16.2730 - val_loss: 20.6114 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 1s 33ms/step - loss: 16.1312 - val_loss: 20.0079 - lr: 5.0000e-05\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 16.1232 - val_loss: 19.4234 - lr: 5.0000e-05\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 16.1347 - val_loss: 18.9179 - lr: 5.0000e-05\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 16.1425 - val_loss: 18.5078 - lr: 5.0000e-05\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 16.1557 - val_loss: 18.0614 - lr: 5.0000e-05\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 16.1254 - val_loss: 17.6847 - lr: 5.0000e-05\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 16.1092 - val_loss: 17.3934 - lr: 5.0000e-05\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 15.9945 - val_loss: 17.1917 - lr: 5.0000e-05\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 16.0389 - val_loss: 17.0470 - lr: 5.0000e-05\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 16.0378 - val_loss: 16.8949 - lr: 5.0000e-05\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 16.0455 - val_loss: 16.7921 - lr: 5.0000e-05\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 15.9477 - val_loss: 16.6738 - lr: 5.0000e-05\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 1s 38ms/step - loss: 15.9991 - val_loss: 16.5441 - lr: 5.0000e-05\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 16.1063 - val_loss: 16.4473 - lr: 5.0000e-05\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 16.0061 - val_loss: 16.3509 - lr: 5.0000e-05\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 15.9450 - val_loss: 16.2800 - lr: 5.0000e-05\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 16.0002 - val_loss: 16.2320 - lr: 5.0000e-05\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 15.9081 - val_loss: 16.1894 - lr: 5.0000e-05\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 1s 36ms/step - loss: 15.9878 - val_loss: 16.1375 - lr: 5.0000e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define MDN Gamma model\n",
    "MDN_model_ref_gamma = model_generator()\n",
    "#MDN_model_ref_gamma.set_weights(meta_learner.meta_model.get_weights())\n",
    "MDN_model_ref_gamma.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss=gamma_loss)\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch <= 5:\n",
    "        return lr\n",
    "    elif epoch <= 30 and epoch > 5:\n",
    "        return 0.0001\n",
    "    else:\n",
    "        return 0.00005\n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "history_gamma = MDN_model_ref_gamma.fit(train_x, train_y, epochs=50, validation_data=[test_x, test_y], callbacks=callback)\n",
    "plot_history(history_gamma, 'Regular Training, Gamma MDN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = MDN_model_ref_gamma.predict(test_x)\n",
    "a1, a2, a3, a4, a5, a6, a7, a8, a9, m1, m2, m3, m4, m5, m6, m7, m8, m9, s1, s2, s3, s4, s5, s6, s7, s8, s9  = slice_parameter_vectors(y_hat)\n",
    "gm1 = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=a1),\n",
    "        components_distribution=tfd.Gamma(\n",
    "        concentration=m1, rate=s1)\n",
    "    )\n",
    "gm2 = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=a2),\n",
    "        components_distribution=tfd.Gamma(\n",
    "        concentration=m2, rate=s2)\n",
    "    )\n",
    "gm3 = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=a3),\n",
    "        components_distribution=tfd.Gamma(\n",
    "        concentration=m3, rate=s3)\n",
    "    )\n",
    "gm4 = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=a4),\n",
    "        components_distribution=tfd.Gamma(\n",
    "        concentration=m4, rate=s4)\n",
    "    )\n",
    "gm5 = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=a5),\n",
    "        components_distribution=tfd.Gamma(\n",
    "        concentration=m5, rate=s5)\n",
    "    )\n",
    "gm6 = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=a6),\n",
    "        components_distribution=tfd.Gamma(\n",
    "        concentration=m6, rate=s6)\n",
    "    )\n",
    "gm7 = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=a7),\n",
    "        components_distribution=tfd.Gamma(\n",
    "        concentration=m7, rate=s7)\n",
    "    )\n",
    "gm8 = tfd.MixtureSameFamily(\n",
    "    mixture_distribution=tfd.Categorical(probs=a8),\n",
    "        components_distribution=tfd.Gamma(\n",
    "        concentration=m8, rate=s8)\n",
    "    )    \n",
    "gm9 = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=a9),\n",
    "        components_distribution=tfd.Gamma(\n",
    "        concentration=m9, rate=s9)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([167.,  16.,   5.,   3.,   1.,   0.,   1.,   0.,   0.,   1.]),\n",
       " array([1.1480076e-25, 5.1916409e-01, 1.0383282e+00, 1.5574923e+00,\n",
       "        2.0766563e+00, 2.5958204e+00, 3.1149845e+00, 3.6341486e+00,\n",
       "        4.1533127e+00, 4.6724768e+00, 5.1916409e+00], dtype=float32),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = np.mean(gm2.sample(1).numpy(), axis=0)\n",
    "plt.plot(pred)\n",
    "plt.show()\n",
    "plt.hist(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([133.,  52.,   6.,   0.,   1.,   0.,   0.,   1.,   0.,   1.]),\n",
       " array([  59.53921066,  241.98668282,  424.43415498,  606.88162714,\n",
       "         789.32909931,  971.77657147, 1154.22404363, 1336.67151579,\n",
       "        1519.11898796, 1701.56646012, 1884.01393228]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(test_y[:, 0, 1])\n",
    "plt.show()\n",
    "plt.hist(test_y[:, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5288835981993701"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.array([gm1.mean()[0], gm2.mean()[0], gm3.mean()[0], gm4.mean()[0], gm5.mean()[0], gm6.mean()[0], gm7.mean()[0], gm8.mean()[0], gm9.mean()[0]])\n",
    "pred = pred.reshape((3, 3))\n",
    "pred = (pred - pred.min())/(pred.max() - pred.min())\n",
    "true = test_y[0]\n",
    "true = (true - true.min())/(true.max() - true.min())\n",
    "np.mean(np.abs(pred - true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MAE between mean of MD and Y is not a stable loss to track."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Debug Meta Learning Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(probdownscale.MetaTrain)\n",
    "from probdownscale.MetaTrain import MetaSGD\n",
    "\n",
    "# define necessary tool functions\n",
    "components = 100\n",
    "no_parameters = 3\n",
    "data = [train_g_data, train_m_data]\n",
    "lats_lons = [G_lats, G_lons, M_lats, M_lons]\n",
    "task_dim = 3\n",
    "test_proportion = 0.5\n",
    "n_lag = 10\n",
    "\n",
    "MDN_model = model_generator()\n",
    "\n",
    "# define TaskExtractor\n",
    "\n",
    "taskextractor = TaskExtractor(data, lats_lons, task_dim, test_proportion, n_lag)\n",
    "\n",
    "# define meta learner\n",
    "meta_optimizer = tf.keras.optimizers.Adam(0.0001)\n",
    "inner_step = 1\n",
    "inner_optimizer = tf.keras.optimizers.Adam(0.0001)\n",
    "\n",
    "meta_learner = MetaSGD(MDN_model, gamma_loss,  meta_optimizer, inner_step, inner_optimizer, taskextractor, meta_lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\beta = lr\\times e^{-\\bar{Cov}}\\times (e^{(b/s)^{0.5}}-1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9330329915368074"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5**0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covariance factor: 0.7154835175546712\n",
      "batch size factor: 1.718281828459045\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0012294024>\n",
      "Epoch: 1 / 10  Basic training step:  1 / 8 loss:  32.79431\n",
      "covariance factor: 0.7525019391642964\n",
      "batch size factor: 1.5422079918208849\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0007736585>\n",
      "Epoch: 1 / 10  Basic training step:  2 / 8 loss:  29.129059\n",
      "covariance factor: 0.7775011477369007\n",
      "batch size factor: 1.449682587009316\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0006074711>\n",
      "Epoch: 1 / 10  Basic training step:  3 / 8 loss:  25.068172\n",
      "covariance factor: 0.7686410301642882\n",
      "batch size factor: 1.3882253608578883\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0004986338>\n",
      "Epoch: 1 / 10  Basic training step:  4 / 8 loss:  21.636108\n",
      "covariance factor: 0.7795515870531867\n",
      "batch size factor: 1.3427838986640035\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0004396268>\n",
      "Epoch: 1 / 10  Basic training step:  5 / 8 loss:  19.441587\n",
      "covariance factor: 0.7746202560026745\n",
      "batch size factor: 1.3070249685338564\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0003905485>\n",
      "Epoch: 1 / 10  Basic training step:  6 / 8 loss:  18.24599\n",
      "covariance factor: 0.795965107623483\n",
      "batch size factor: 1.2777115983270289\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0003655956>\n",
      "Epoch: 1 / 10  Basic training step:  7 / 8 loss:  15.964633\n",
      "covariance factor: 0.7996007604293885\n",
      "batch size factor: 1.2529768728622077\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0003391259>\n",
      "Epoch: 1 / 10  Basic training step:  8 / 8 loss:  15.243652\n",
      "covariance factor: 0.7827601041493506\n",
      "batch size factor: 1.2356848011497834\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00031379212>\n",
      "Epoch: 1 / 10 Bootstrap training step: 1 / 10 loss:  16.40707\n",
      "covariance factor: 0.7866009313638241\n",
      "batch size factor: 1.220156010703748\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00029963057>\n",
      "Epoch: 1 / 10 Bootstrap training step: 2 / 10 loss:  14.608432\n",
      "covariance factor: 0.7804250819116447\n",
      "batch size factor: 1.2044149244010653\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00028214455>\n",
      "Epoch: 1 / 10 Bootstrap training step: 3 / 10 loss:  15.073542\n",
      "covariance factor: 0.8185649180540615\n",
      "batch size factor: 1.1886912632827027\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00028074358>\n",
      "Epoch: 1 / 10 Bootstrap training step: 4 / 10 loss:  13.488963\n",
      "covariance factor: 0.8175321073752981\n",
      "batch size factor: 1.1800114362328\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00027229023>\n",
      "Epoch: 1 / 10 Bootstrap training step: 5 / 10 loss:  13.086804\n",
      "covariance factor: 0.783521677327947\n",
      "batch size factor: 1.1691961128646606\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00025154566>\n",
      "Epoch: 1 / 10 Bootstrap training step: 6 / 10 loss:  12.2248745\n",
      "covariance factor: 0.8129225239521045\n",
      "batch size factor: 1.1567375965534268\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0002500842>\n",
      "Epoch: 1 / 10 Bootstrap training step: 7 / 10 loss:  14.90919\n",
      "covariance factor: 0.7926192151184815\n",
      "batch size factor: 1.1497584487998629\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00023804196>\n",
      "Epoch: 1 / 10 Bootstrap training step: 8 / 10 loss:  14.620583\n",
      "covariance factor: 0.8073696518271292\n",
      "batch size factor: 1.1399028958135875\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00023432611>\n",
      "Epoch: 1 / 10 Bootstrap training step: 9 / 10 loss:  11.99424\n",
      "covariance factor: 0.7912917788632665\n",
      "batch size factor: 1.1297172867403735\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00022163495>\n",
      "Epoch: 1 / 10 Bootstrap training step: 10 / 10 loss:  12.41452\n",
      "covariance factor: 0.7880295757694861\n",
      "batch size factor: 1.1297172867403735\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00022072124>\n",
      "Epoch: 2 / 10  Basic training step:  1 / 8 loss:  12.211314\n",
      "covariance factor: 0.8015297717578842\n",
      "batch size factor: 1.1297172867403735\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00022450254>\n",
      "Epoch: 2 / 10  Basic training step:  2 / 8 loss:  11.342899\n",
      "covariance factor: 0.806442452541348\n",
      "batch size factor: 1.1297172867403735\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00022587854>\n",
      "Epoch: 2 / 10  Basic training step:  3 / 8 loss:  12.22578\n",
      "covariance factor: 0.8022025375629721\n",
      "batch size factor: 1.1297172867403735\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00022469097>\n",
      "Epoch: 2 / 10  Basic training step:  4 / 8 loss:  11.229235\n",
      "covariance factor: 0.8065264215815189\n",
      "batch size factor: 1.1297172867403735\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00022590205>\n",
      "Epoch: 2 / 10  Basic training step:  5 / 8 loss:  12.224314\n",
      "covariance factor: 0.8036263914621903\n",
      "batch size factor: 1.1297172867403735\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00022508978>\n",
      "Epoch: 2 / 10  Basic training step:  6 / 8 loss:  11.526482\n",
      "covariance factor: 0.824917476494663\n",
      "batch size factor: 1.1297172867403735\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00023105326>\n",
      "Epoch: 2 / 10  Basic training step:  7 / 8 loss:  10.818688\n",
      "covariance factor: 0.8238399693722404\n",
      "batch size factor: 1.1297172867403735\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00023075145>\n",
      "Epoch: 2 / 10  Basic training step:  8 / 8 loss:  11.116173\n",
      "covariance factor: 0.8160631186002274\n",
      "batch size factor: 1.1230123885368313\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00022325187>\n",
      "Epoch: 2 / 10 Bootstrap training step: 1 / 10 loss:  10.210854\n",
      "covariance factor: 0.8193597986954695\n",
      "batch size factor: 1.1175171488304394\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0002198487>\n",
      "Epoch: 2 / 10 Bootstrap training step: 2 / 10 loss:  11.685142\n",
      "covariance factor: 0.8097388162766496\n",
      "batch size factor: 1.109671981484519\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00021130547>\n",
      "Epoch: 2 / 10 Bootstrap training step: 3 / 10 loss:  11.53575\n",
      "covariance factor: 0.8347651344026732\n",
      "batch size factor: 1.1038723253356095\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00021337873>\n",
      "Epoch: 2 / 10 Bootstrap training step: 4 / 10 loss:  10.857104\n",
      "covariance factor: 0.8205352188951786\n",
      "batch size factor: 1.0960022161397962\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00020390868>\n",
      "Epoch: 2 / 10 Bootstrap training step: 5 / 10 loss:  10.781914\n",
      "covariance factor: 0.7967068698796668\n",
      "batch size factor: 1.0907591901905174\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00019428339>\n",
      "Epoch: 2 / 10 Bootstrap training step: 6 / 10 loss:  10.34061\n",
      "covariance factor: 0.8083804309625059\n",
      "batch size factor: 1.0864258735640173\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0001940658>\n",
      "Epoch: 2 / 10 Bootstrap training step: 7 / 10 loss:  11.3042965\n",
      "covariance factor: 0.8288956415404075\n",
      "batch size factor: 1.0808629426444223\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00019501324>\n",
      "Epoch: 2 / 10 Bootstrap training step: 8 / 10 loss:  10.752827\n",
      "covariance factor: 0.8263028885499243\n",
      "batch size factor: 1.0761832993071403\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00019111579>\n",
      "Epoch: 2 / 10 Bootstrap training step: 9 / 10 loss:  10.21682\n",
      "covariance factor: 0.8103460502102643\n",
      "batch size factor: 1.0716671210192974\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00018435415>\n",
      "Epoch: 2 / 10 Bootstrap training step: 10 / 10 loss:  12.444823\n",
      "covariance factor: 0.806924076768673\n",
      "batch size factor: 1.0716671210192974\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00018357566>\n",
      "Epoch: 3 / 10  Basic training step:  1 / 8 loss:  10.301619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covariance factor: 0.8180543961784151\n",
      "batch size factor: 1.0716671210192974\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0001861078>\n",
      "Epoch: 3 / 10  Basic training step:  2 / 8 loss:  9.2460985\n",
      "covariance factor: 0.8233567426020918\n",
      "batch size factor: 1.0716671210192974\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0001873141>\n",
      "Epoch: 3 / 10  Basic training step:  3 / 8 loss:  10.345139\n",
      "covariance factor: 0.8190132927671052\n",
      "batch size factor: 1.0716671210192974\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00018632597>\n",
      "Epoch: 3 / 10  Basic training step:  4 / 8 loss:  9.637252\n",
      "covariance factor: 0.825030691811471\n",
      "batch size factor: 1.0716671210192974\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00018769492>\n",
      "Epoch: 3 / 10  Basic training step:  5 / 8 loss:  10.021298\n",
      "covariance factor: 0.8217125879997568\n",
      "batch size factor: 1.0716671210192974\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00018694006>\n",
      "Epoch: 3 / 10  Basic training step:  6 / 8 loss:  9.821672\n",
      "covariance factor: 0.8403196909396453\n",
      "batch size factor: 1.0716671210192974\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00019117318>\n",
      "Epoch: 3 / 10  Basic training step:  7 / 8 loss:  9.20381\n",
      "covariance factor: 0.8398929600805943\n",
      "batch size factor: 1.0716671210192974\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00019107609>\n",
      "Epoch: 3 / 10  Basic training step:  8 / 8 loss:  9.5845785\n",
      "covariance factor: 0.8251298171576028\n",
      "batch size factor: 1.066692765494349\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00018431946>\n",
      "Epoch: 3 / 10 Bootstrap training step: 1 / 10 loss:  10.477483\n",
      "covariance factor: 0.822754032769357\n",
      "batch size factor: 1.0624933615150263\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00018096557>\n",
      "Epoch: 3 / 10 Bootstrap training step: 2 / 10 loss:  9.851343\n",
      "covariance factor: 0.826051620200045\n",
      "batch size factor: 1.0590008741068444\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00017935933>\n",
      "Epoch: 3 / 10 Bootstrap training step: 3 / 10 loss:  9.605507\n",
      "covariance factor: 0.844148748875959\n",
      "batch size factor: 1.0544889934181025\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00018024574>\n",
      "Epoch: 3 / 10 Bootstrap training step: 4 / 10 loss:  9.933846\n",
      "covariance factor: 0.8361970234070305\n",
      "batch size factor: 1.0501328397658658\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00017567439>\n",
      "Epoch: 3 / 10 Bootstrap training step: 5 / 10 loss:  9.399534\n",
      "covariance factor: 0.8266765844486665\n",
      "batch size factor: 1.0454062626171177\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00017063197>\n",
      "Epoch: 3 / 10 Bootstrap training step: 6 / 10 loss:  9.435648\n",
      "covariance factor: 0.8294958348886884\n",
      "batch size factor: 1.043361570366125\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00016990615>\n",
      "Epoch: 3 / 10 Bootstrap training step: 7 / 10 loss:  9.274854\n",
      "covariance factor: 0.8380055640475793\n",
      "batch size factor: 1.0403561005604165\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00016972137>\n",
      "Epoch: 3 / 10 Bootstrap training step: 8 / 10 loss:  8.780279\n",
      "covariance factor: 0.8363273280050012\n",
      "batch size factor: 1.0379059103500876\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0001678253>\n",
      "Epoch: 3 / 10 Bootstrap training step: 9 / 10 loss:  9.0185585\n",
      "covariance factor: 0.8271977150198538\n",
      "batch size factor: 1.0345551038449678\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00016390593>\n",
      "Epoch: 3 / 10 Bootstrap training step: 10 / 10 loss:  9.031009\n",
      "covariance factor: 0.823256552187068\n",
      "batch size factor: 1.0345551038449678\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.000163125>\n",
      "Epoch: 4 / 10  Basic training step:  1 / 8 loss:  9.159426\n",
      "covariance factor: 0.833543987916124\n",
      "batch size factor: 1.0345551038449678\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00016516342>\n",
      "Epoch: 4 / 10  Basic training step:  2 / 8 loss:  8.4183445\n",
      "covariance factor: 0.8378146318719988\n",
      "batch size factor: 1.0345551038449678\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00016600963>\n",
      "Epoch: 4 / 10  Basic training step:  3 / 8 loss:  9.336937\n",
      "covariance factor: 0.8334671864800488\n",
      "batch size factor: 1.0345551038449678\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0001651482>\n",
      "Epoch: 4 / 10  Basic training step:  4 / 8 loss:  8.765223\n",
      "covariance factor: 0.8380724014300347\n",
      "batch size factor: 1.0345551038449678\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00016606071>\n",
      "Epoch: 4 / 10  Basic training step:  5 / 8 loss:  9.309932\n",
      "covariance factor: 0.8338865320506367\n",
      "batch size factor: 1.0345551038449678\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0001652313>\n",
      "Epoch: 4 / 10  Basic training step:  6 / 8 loss:  8.826823\n",
      "covariance factor: 0.8523581008288926\n",
      "batch size factor: 1.0345551038449678\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00016889136>\n",
      "Epoch: 4 / 10  Basic training step:  7 / 8 loss:  8.427544\n",
      "covariance factor: 0.8511436333302143\n",
      "batch size factor: 1.0345551038449678\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00016865073>\n",
      "Epoch: 4 / 10  Basic training step:  8 / 8 loss:  8.771907\n",
      "covariance factor: 0.8431624455651979\n",
      "batch size factor: 1.0308338272840714\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00016473055>\n",
      "Epoch: 4 / 10 Bootstrap training step: 1 / 10 loss:  8.649649\n",
      "covariance factor: 0.85010124578794\n",
      "batch size factor: 1.0272219373092941\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00016382181>\n",
      "Epoch: 4 / 10 Bootstrap training step: 2 / 10 loss:  8.109975\n",
      "covariance factor: 0.8508239677517356\n",
      "batch size factor: 1.0241466693717798\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00016205019>\n",
      "Epoch: 4 / 10 Bootstrap training step: 3 / 10 loss:  9.534957\n",
      "covariance factor: 0.843458044849119\n",
      "batch size factor: 1.0224235619098647\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00015959323>\n",
      "Epoch: 4 / 10 Bootstrap training step: 4 / 10 loss:  8.173136\n",
      "covariance factor: 0.8487051721637218\n",
      "batch size factor: 1.0190489006877423\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00015852436>\n",
      "Epoch: 4 / 10 Bootstrap training step: 5 / 10 loss:  8.551065\n",
      "covariance factor: 0.8429921847142253\n",
      "batch size factor: 1.016986446202111\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00015621564>\n",
      "Epoch: 4 / 10 Bootstrap training step: 6 / 10 loss:  9.158951\n",
      "covariance factor: 0.8393123099139079\n",
      "batch size factor: 1.0141568720298264\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00015384983>\n",
      "Epoch: 4 / 10 Bootstrap training step: 7 / 10 loss:  8.743042\n",
      "covariance factor: 0.8350866805945989\n",
      "batch size factor: 1.0125692899494294\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0001521413>\n",
      "Epoch: 4 / 10 Bootstrap training step: 8 / 10 loss:  8.087147\n",
      "covariance factor: 0.8344966909479032\n",
      "batch size factor: 1.0110023837034334\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00015111695>\n",
      "Epoch: 4 / 10 Bootstrap training step: 9 / 10 loss:  7.9886246\n",
      "covariance factor: 0.8483904390007904\n",
      "batch size factor: 1.0102265285674745\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.000153173>\n",
      "Epoch: 4 / 10 Bootstrap training step: 10 / 10 loss:  8.957882\n",
      "covariance factor: 0.8349063885493914\n",
      "batch size factor: 1.0102265285674745\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0001507385>\n",
      "Epoch: 5 / 10  Basic training step:  1 / 8 loss:  8.62641\n",
      "covariance factor: 0.8456772611773348\n",
      "batch size factor: 1.0102265285674745\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00015268313>\n",
      "Epoch: 5 / 10  Basic training step:  2 / 8 loss:  7.8938475\n",
      "covariance factor: 0.8485136198036818\n",
      "batch size factor: 1.0102265285674745\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00015319523>\n",
      "Epoch: 5 / 10  Basic training step:  3 / 8 loss:  8.77067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covariance factor: 0.8439388184221224\n",
      "batch size factor: 1.0102265285674745\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00015236926>\n",
      "Epoch: 5 / 10  Basic training step:  4 / 8 loss:  8.227309\n",
      "covariance factor: 0.8475936136429476\n",
      "batch size factor: 1.0102265285674745\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00015302912>\n",
      "Epoch: 5 / 10  Basic training step:  5 / 8 loss:  8.727991\n",
      "covariance factor: 0.8430399082305869\n",
      "batch size factor: 1.0102265285674745\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00015220698>\n",
      "Epoch: 5 / 10  Basic training step:  6 / 8 loss:  8.362554\n",
      "covariance factor: 0.86116082750783\n",
      "batch size factor: 1.0102265285674745\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00015547863>\n",
      "Epoch: 5 / 10  Basic training step:  7 / 8 loss:  7.9701767\n",
      "covariance factor: 0.8598044500693223\n",
      "batch size factor: 1.0102265285674745\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00015523373>\n",
      "Epoch: 5 / 10  Basic training step:  8 / 8 loss:  8.2826185\n",
      "covariance factor: 0.8508855446006877\n",
      "batch size factor: 1.0079286347809866\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00015226335>\n",
      "Epoch: 5 / 10 Bootstrap training step: 1 / 10 loss:  7.727853\n",
      "covariance factor: 0.8365059094315304\n",
      "batch size factor: 1.0064208522300033\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0001488177>\n",
      "Epoch: 5 / 10 Bootstrap training step: 2 / 10 loss:  8.810831\n",
      "covariance factor: 0.8455678037859437\n",
      "batch size factor: 1.003461239725631\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0001487101>\n",
      "Epoch: 5 / 10 Bootstrap training step: 3 / 10 loss:  7.9827743\n",
      "covariance factor: 0.8617668034720364\n",
      "batch size factor: 1.0005734272252678\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00014986358>\n",
      "Epoch: 5 / 10 Bootstrap training step: 4 / 10 loss:  7.9995437\n",
      "covariance factor: 0.857911618556932\n",
      "batch size factor: 0.9995083540558125\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00014857427>\n",
      "Epoch: 5 / 10 Bootstrap training step: 5 / 10 loss:  8.314692\n",
      "covariance factor: 0.8570811071672708\n",
      "batch size factor: 0.9977542406528375\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00014741642>\n",
      "Epoch: 5 / 10 Bootstrap training step: 6 / 10 loss:  8.012927\n",
      "covariance factor: 0.8612437037706009\n",
      "batch size factor: 0.9956830908861898\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00014693607>\n",
      "Epoch: 5 / 10 Bootstrap training step: 7 / 10 loss:  8.1793165\n",
      "covariance factor: 0.845894847433925\n",
      "batch size factor: 0.9943222510688619\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00014354932>\n",
      "Epoch: 5 / 10 Bootstrap training step: 8 / 10 loss:  8.7702465\n",
      "covariance factor: 0.8572300449714015\n",
      "batch size factor: 0.9936476815764894\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00014508824>\n",
      "Epoch: 5 / 10 Bootstrap training step: 9 / 10 loss:  7.418354\n",
      "covariance factor: 0.8501982305371829\n",
      "batch size factor: 0.9923100373411464\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0001431438>\n",
      "Epoch: 5 / 10 Bootstrap training step: 10 / 10 loss:  8.952771\n",
      "covariance factor: 0.8437863737415795\n",
      "batch size factor: 0.9923100373411464\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00014206427>\n",
      "Epoch: 6 / 10  Basic training step:  1 / 8 loss:  8.27376\n",
      "covariance factor: 0.8531778555083072\n",
      "batch size factor: 0.9923100373411464\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00014364546>\n",
      "Epoch: 6 / 10  Basic training step:  2 / 8 loss:  7.572118\n",
      "covariance factor: 0.855989128487407\n",
      "batch size factor: 0.9923100373411464\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00014411878>\n",
      "Epoch: 6 / 10  Basic training step:  3 / 8 loss:  8.529535\n",
      "covariance factor: 0.8511865399488632\n",
      "batch size factor: 0.9923100373411464\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0001433102>\n",
      "Epoch: 6 / 10  Basic training step:  4 / 8 loss:  7.834876\n",
      "covariance factor: 0.8550139043267038\n",
      "batch size factor: 0.9923100373411464\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00014395459>\n",
      "Epoch: 6 / 10  Basic training step:  5 / 8 loss:  8.320104\n",
      "covariance factor: 0.851406202359672\n",
      "batch size factor: 0.9923100373411464\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00014334718>\n",
      "Epoch: 6 / 10  Basic training step:  6 / 8 loss:  8.021025\n",
      "covariance factor: 0.8672305153877028\n",
      "batch size factor: 0.9923100373411464\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00014601144>\n",
      "Epoch: 6 / 10  Basic training step:  7 / 8 loss:  7.610855\n",
      "covariance factor: 0.8661247830893041\n",
      "batch size factor: 0.9923100373411464\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00014582528>\n",
      "Epoch: 6 / 10  Basic training step:  8 / 8 loss:  8.010034\n",
      "covariance factor: 0.8589107657330841\n",
      "batch size factor: 0.9906591218232148\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00014367438>\n",
      "Epoch: 6 / 10 Bootstrap training step: 1 / 10 loss:  7.8328323\n",
      "covariance factor: 0.8688938827241369\n",
      "batch size factor: 0.9890311287016984\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00014441482>\n",
      "Epoch: 6 / 10 Bootstrap training step: 2 / 10 loss:  7.6868286\n",
      "covariance factor: 0.8631872565985854\n",
      "batch size factor: 0.9871069721040409\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00014238077>\n",
      "Epoch: 6 / 10 Bootstrap training step: 3 / 10 loss:  9.356563\n",
      "covariance factor: 0.8516178293654704\n",
      "batch size factor: 0.9852140118363895\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00013942472>\n",
      "Epoch: 6 / 10 Bootstrap training step: 4 / 10 loss:  8.384691\n",
      "covariance factor: 0.8401713408873707\n",
      "batch size factor: 0.9836597046188442\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00013670641>\n",
      "Epoch: 6 / 10 Bootstrap training step: 5 / 10 loss:  8.043142\n",
      "covariance factor: 0.8673045100324764\n",
      "batch size factor: 0.9830437508138934\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00014077703>\n",
      "Epoch: 6 / 10 Bootstrap training step: 6 / 10 loss:  7.46927\n",
      "covariance factor: 0.871360226068914\n",
      "batch size factor: 0.9821259003095657\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00014092111>\n",
      "Epoch: 6 / 10 Bootstrap training step: 7 / 10 loss:  9.287634\n",
      "covariance factor: 0.8719661502539605\n",
      "batch size factor: 0.9800120750224364\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00013983935>\n",
      "Epoch: 6 / 10 Bootstrap training step: 8 / 10 loss:  7.9675293\n",
      "covariance factor: 0.8648610461892337\n",
      "batch size factor: 0.9788212745194098\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00013804396>\n",
      "Epoch: 6 / 10 Bootstrap training step: 9 / 10 loss:  7.607619\n",
      "covariance factor: 0.8511483878152064\n",
      "batch size factor: 0.9767664503773086\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00013474675>\n",
      "Epoch: 6 / 10 Bootstrap training step: 10 / 10 loss:  8.113554\n",
      "covariance factor: 0.8506066197414967\n",
      "batch size factor: 0.9767664503773086\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00013466098>\n",
      "Epoch: 7 / 10  Basic training step:  1 / 8 loss:  7.982768\n",
      "covariance factor: 0.8594066793190692\n",
      "batch size factor: 0.9767664503773086\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00013605412>\n",
      "Epoch: 7 / 10  Basic training step:  2 / 8 loss:  7.273668\n",
      "covariance factor: 0.8619400668632089\n",
      "batch size factor: 0.9767664503773086\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00013645519>\n",
      "Epoch: 7 / 10  Basic training step:  3 / 8 loss:  8.166082\n",
      "covariance factor: 0.8572420035987566\n",
      "batch size factor: 0.9767664503773086\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00013571144>\n",
      "Epoch: 7 / 10  Basic training step:  4 / 8 loss:  7.597612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covariance factor: 0.8607768804168191\n",
      "batch size factor: 0.9767664503773086\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00013627105>\n",
      "Epoch: 7 / 10  Basic training step:  5 / 8 loss:  8.081879\n",
      "covariance factor: 0.857137076040918\n",
      "batch size factor: 0.9767664503773086\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00013569482>\n",
      "Epoch: 7 / 10  Basic training step:  6 / 8 loss:  7.7298307\n",
      "covariance factor: 0.8723858246148523\n",
      "batch size factor: 0.9767664503773086\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00013810888>\n",
      "Epoch: 7 / 10  Basic training step:  7 / 8 loss:  7.4247894\n",
      "covariance factor: 0.8711512837364237\n",
      "batch size factor: 0.9767664503773086\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00013791343>\n",
      "Epoch: 7 / 10  Basic training step:  8 / 8 loss:  7.795022\n",
      "covariance factor: 0.8625543775968061\n",
      "batch size factor: 0.9753208119516386\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00013576628>\n",
      "Epoch: 7 / 10 Bootstrap training step: 1 / 10 loss:  7.4083815\n",
      "covariance factor: 0.8621667583962493\n",
      "batch size factor: 0.9744620614080186\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0001352401>\n",
      "Epoch: 7 / 10 Bootstrap training step: 2 / 10 loss:  7.1607056\n",
      "covariance factor: 0.8562090575089425\n",
      "batch size factor: 0.9730449122099434\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00013354584>\n",
      "Epoch: 7 / 10 Bootstrap training step: 3 / 10 loss:  8.294721\n",
      "covariance factor: 0.8719131280217426\n",
      "batch size factor: 0.9724829131029029\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00013568935>\n",
      "Epoch: 7 / 10 Bootstrap training step: 4 / 10 loss:  8.452799\n",
      "covariance factor: 0.8715137790779219\n",
      "batch size factor: 0.9713671090952605\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00013502168>\n",
      "Epoch: 7 / 10 Bootstrap training step: 5 / 10 loss:  8.876016\n",
      "covariance factor: 0.8693903843649906\n",
      "batch size factor: 0.9705373293542374\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00013424482>\n",
      "Epoch: 7 / 10 Bootstrap training step: 6 / 10 loss:  7.8027854\n",
      "covariance factor: 0.8466494884721595\n",
      "batch size factor: 0.9699874658778336\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0001304449>\n",
      "Epoch: 7 / 10 Bootstrap training step: 7 / 10 loss:  7.8986855\n",
      "covariance factor: 0.8601511446405189\n",
      "batch size factor: 0.9688956079660545\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00013194469>\n",
      "Epoch: 7 / 10 Bootstrap training step: 8 / 10 loss:  7.010183\n",
      "covariance factor: 0.873132799011041\n",
      "batch size factor: 0.9686242659414608\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00013378993>\n",
      "Epoch: 7 / 10 Bootstrap training step: 9 / 10 loss:  7.7790985\n",
      "covariance factor: 0.8706607756501874\n",
      "batch size factor: 0.967009623571091\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00013254657>\n",
      "Epoch: 7 / 10 Bootstrap training step: 10 / 10 loss:  7.780771\n",
      "covariance factor: 0.8567121876646667\n",
      "batch size factor: 0.967009623571091\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00013042308>\n",
      "Epoch: 8 / 10  Basic training step:  1 / 8 loss:  7.6968384\n",
      "covariance factor: 0.865105626249718\n",
      "batch size factor: 0.967009623571091\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00013170087>\n",
      "Epoch: 8 / 10  Basic training step:  2 / 8 loss:  7.1134825\n",
      "covariance factor: 0.8676762038161937\n",
      "batch size factor: 0.967009623571091\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0001320922>\n",
      "Epoch: 8 / 10  Basic training step:  3 / 8 loss:  8.003275\n",
      "covariance factor: 0.8627359527464747\n",
      "batch size factor: 0.967009623571091\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00013134012>\n",
      "Epoch: 8 / 10  Basic training step:  4 / 8 loss:  7.4177656\n",
      "covariance factor: 0.8659934970153174\n",
      "batch size factor: 0.967009623571091\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00013183603>\n",
      "Epoch: 8 / 10  Basic training step:  5 / 8 loss:  7.842163\n",
      "covariance factor: 0.8630755484826647\n",
      "batch size factor: 0.967009623571091\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00013139182>\n",
      "Epoch: 8 / 10  Basic training step:  6 / 8 loss:  7.514903\n",
      "covariance factor: 0.8771275434112474\n",
      "batch size factor: 0.967009623571091\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00013353104>\n",
      "Epoch: 8 / 10  Basic training step:  7 / 8 loss:  7.1347513\n",
      "covariance factor: 0.8759538425805351\n",
      "batch size factor: 0.967009623571091\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00013335237>\n",
      "Epoch: 8 / 10  Basic training step:  8 / 8 loss:  7.506524\n",
      "covariance factor: 0.8638109557346655\n",
      "batch size factor: 0.9659457630923833\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00013094088>\n",
      "Epoch: 8 / 10 Bootstrap training step: 1 / 10 loss:  7.313971\n",
      "covariance factor: 0.8827181612813754\n",
      "batch size factor: 0.9648917545744122\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0001332389>\n",
      "Epoch: 8 / 10 Bootstrap training step: 2 / 10 loss:  8.062178\n",
      "covariance factor: 0.8650178240908267\n",
      "batch size factor: 0.9643683919844688\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00013029143>\n",
      "Epoch: 8 / 10 Bootstrap training step: 3 / 10 loss:  6.94732\n",
      "covariance factor: 0.86952502412887\n",
      "batch size factor: 0.963587841971006\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00013055775>\n",
      "Epoch: 8 / 10 Bootstrap training step: 4 / 10 loss:  7.4176536\n",
      "covariance factor: 0.8677502691455898\n",
      "batch size factor: 0.9628126236614436\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012988331>\n",
      "Epoch: 8 / 10 Bootstrap training step: 5 / 10 loss:  7.9561143\n",
      "covariance factor: 0.8653027962666282\n",
      "batch size factor: 0.9620426696573412\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012911388>\n",
      "Epoch: 8 / 10 Bootstrap training step: 6 / 10 loss:  7.535051\n",
      "covariance factor: 0.8700025443274243\n",
      "batch size factor: 0.9610241390615759\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012928047>\n",
      "Epoch: 8 / 10 Bootstrap training step: 7 / 10 loss:  7.29012\n",
      "covariance factor: 0.8777300511230015\n",
      "batch size factor: 0.9602662132311153\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00013002843>\n",
      "Epoch: 8 / 10 Bootstrap training step: 8 / 10 loss:  7.689912\n",
      "covariance factor: 0.8699399507803511\n",
      "batch size factor: 0.9597637378875816\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012861186>\n",
      "Epoch: 8 / 10 Bootstrap training step: 9 / 10 loss:  7.4260397\n",
      "covariance factor: 0.8625021789414374\n",
      "batch size factor: 0.9592634877652657\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012725352>\n",
      "Epoch: 8 / 10 Bootstrap training step: 10 / 10 loss:  7.253151\n",
      "covariance factor: 0.8625979315315385\n",
      "batch size factor: 0.9592634877652657\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012726765>\n",
      "Epoch: 9 / 10  Basic training step:  1 / 8 loss:  7.535238\n",
      "covariance factor: 0.8702553042084704\n",
      "batch size factor: 0.9592634877652657\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012839741>\n",
      "Epoch: 9 / 10  Basic training step:  2 / 8 loss:  6.925617\n",
      "covariance factor: 0.8728143214666384\n",
      "batch size factor: 0.9592634877652657\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012877498>\n",
      "Epoch: 9 / 10  Basic training step:  3 / 8 loss:  7.7576265\n",
      "covariance factor: 0.8679424605140613\n",
      "batch size factor: 0.9592634877652657\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012805618>\n",
      "Epoch: 9 / 10  Basic training step:  4 / 8 loss:  7.267717\n",
      "covariance factor: 0.8711764150212792\n",
      "batch size factor: 0.9592634877652657\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012853331>\n",
      "Epoch: 9 / 10  Basic training step:  5 / 8 loss:  7.5312777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covariance factor: 0.8686165095762111\n",
      "batch size factor: 0.9592634877652657\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012815563>\n",
      "Epoch: 9 / 10  Basic training step:  6 / 8 loss:  7.3312845\n",
      "covariance factor: 0.8816296054201007\n",
      "batch size factor: 0.9592634877652657\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00013007558>\n",
      "Epoch: 9 / 10  Basic training step:  7 / 8 loss:  6.9908133\n",
      "covariance factor: 0.8806939907345712\n",
      "batch size factor: 0.9592634877652657\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012993754>\n",
      "Epoch: 9 / 10  Basic training step:  8 / 8 loss:  7.3106356\n",
      "covariance factor: 0.8706731551234503\n",
      "batch size factor: 0.9585172449534249\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012807017>\n",
      "Epoch: 9 / 10 Bootstrap training step: 1 / 10 loss:  7.6686325\n",
      "covariance factor: 0.87584884894921\n",
      "batch size factor: 0.9580224784053231\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0001285726>\n",
      "Epoch: 9 / 10 Bootstrap training step: 2 / 10 loss:  7.6011305\n",
      "covariance factor: 0.8843747791604657\n",
      "batch size factor: 0.9572843772330502\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012943495>\n",
      "Epoch: 9 / 10 Bootstrap training step: 3 / 10 loss:  7.272743\n",
      "covariance factor: 0.8812269341618156\n",
      "batch size factor: 0.9565510820969785\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012858977>\n",
      "Epoch: 9 / 10 Bootstrap training step: 4 / 10 loss:  7.4246483\n",
      "covariance factor: 0.8767120357586526\n",
      "batch size factor: 0.9558225350615968\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012755179>\n",
      "Epoch: 9 / 10 Bootstrap training step: 5 / 10 loss:  7.3928123\n",
      "covariance factor: 0.871993139803488\n",
      "batch size factor: 0.9548584267114211\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012636748>\n",
      "Epoch: 9 / 10 Bootstrap training step: 6 / 10 loss:  7.514374\n",
      "covariance factor: 0.8725562061414196\n",
      "batch size factor: 0.9539025261624694\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012595666>\n",
      "Epoch: 9 / 10 Bootstrap training step: 7 / 10 loss:  8.032179\n",
      "covariance factor: 0.8785843680147492\n",
      "batch size factor: 0.9527189962285714\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012621499>\n",
      "Epoch: 9 / 10 Bootstrap training step: 8 / 10 loss:  7.2268915\n",
      "covariance factor: 0.8804311196653064\n",
      "batch size factor: 0.9520148348218453\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012611653>\n",
      "Epoch: 9 / 10 Bootstrap training step: 9 / 10 loss:  7.1470566\n",
      "covariance factor: 0.8918153192569621\n",
      "batch size factor: 0.9517810955161778\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012762511>\n",
      "Epoch: 9 / 10 Bootstrap training step: 10 / 10 loss:  7.267003\n",
      "covariance factor: 0.8671267928822018\n",
      "batch size factor: 0.9517810955161778\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012409201>\n",
      "Epoch: 10 / 10  Basic training step:  1 / 8 loss:  7.3608046\n",
      "covariance factor: 0.8738602954578663\n",
      "batch size factor: 0.9517810955161778\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012505562>\n",
      "Epoch: 10 / 10  Basic training step:  2 / 8 loss:  6.739989\n",
      "covariance factor: 0.8770009024176756\n",
      "batch size factor: 0.9517810955161778\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012550507>\n",
      "Epoch: 10 / 10  Basic training step:  3 / 8 loss:  7.6078506\n",
      "covariance factor: 0.8719678919659538\n",
      "batch size factor: 0.9517810955161778\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012478481>\n",
      "Epoch: 10 / 10  Basic training step:  4 / 8 loss:  7.070714\n",
      "covariance factor: 0.8750185702029738\n",
      "batch size factor: 0.9517810955161778\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012522138>\n",
      "Epoch: 10 / 10  Basic training step:  5 / 8 loss:  7.4415298\n",
      "covariance factor: 0.8736223172888357\n",
      "batch size factor: 0.9517810955161778\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012502157>\n",
      "Epoch: 10 / 10  Basic training step:  6 / 8 loss:  7.197358\n",
      "covariance factor: 0.8851050914271479\n",
      "batch size factor: 0.9517810955161778\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012666483>\n",
      "Epoch: 10 / 10  Basic training step:  7 / 8 loss:  6.887946\n",
      "covariance factor: 0.8842888347113497\n",
      "batch size factor: 0.9517810955161778\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012654802>\n",
      "Epoch: 10 / 10  Basic training step:  8 / 8 loss:  7.2160683\n",
      "covariance factor: 0.8914598661921788\n",
      "batch size factor: 0.9513150772348302\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.0001273311>\n",
      "Epoch: 10 / 10 Bootstrap training step: 1 / 10 loss:  7.660834\n",
      "covariance factor: 0.8864494771805285\n",
      "batch size factor: 0.9510827944918625\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012649507>\n",
      "Epoch: 10 / 10 Bootstrap training step: 2 / 10 loss:  7.744258\n",
      "covariance factor: 0.8860142044586857\n",
      "batch size factor: 0.9503888294727352\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.000126074>\n",
      "Epoch: 10 / 10 Bootstrap training step: 3 / 10 loss:  7.3385963\n",
      "covariance factor: 0.8675539249061891\n",
      "batch size factor: 0.9501584627137825\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012333071>\n",
      "Epoch: 10 / 10 Bootstrap training step: 4 / 10 loss:  7.5333686\n",
      "covariance factor: 0.8739296178079365\n",
      "batch size factor: 0.9492417216202731\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012377083>\n",
      "Epoch: 10 / 10 Bootstrap training step: 5 / 10 loss:  7.51519\n",
      "covariance factor: 0.871550515959336\n",
      "batch size factor: 0.9490137088289687\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012331844>\n",
      "Epoch: 10 / 10 Bootstrap training step: 6 / 10 loss:  7.0416174\n",
      "covariance factor: 0.8901226039831468\n",
      "batch size factor: 0.9485590777598691\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012571142>\n",
      "Epoch: 10 / 10 Bootstrap training step: 7 / 10 loss:  7.2376013\n",
      "covariance factor: 0.8792793572528663\n",
      "batch size factor: 0.9483324559601058\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012406452>\n",
      "Epoch: 10 / 10 Bootstrap training step: 8 / 10 loss:  6.9732895\n",
      "covariance factor: 0.883696783028713\n",
      "batch size factor: 0.9476553445719804\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012434142>\n",
      "Epoch: 10 / 10 Bootstrap training step: 9 / 10 loss:  7.497525\n",
      "covariance factor: 0.880233598958049\n",
      "batch size factor: 0.9467588911961404\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.00012339841>\n",
      "Epoch: 10 / 10 Bootstrap training step: 10 / 10 loss:  7.3829603\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from math import exp, sqrt, log\n",
    "def covariance_function(h, phi=0.5):\n",
    "    return exp(-h/phi)\n",
    "\n",
    "def distance_function(loc1, loc2):\n",
    "    return sqrt((loc1[0] - loc2[0])**2 + (loc1[1] - loc2[1])**2)\n",
    "\n",
    "def beta_function(meta_rate, batch_locations, seen_locations, covariance_function, distance_function):\n",
    "    batch_size = len(batch_locations)\n",
    "    seen_size = len(seen_locations.items())\n",
    "    if seen_size == 0:\n",
    "        return meta_rate\n",
    "    temp = 0\n",
    "    for b_loc in batch_locations:\n",
    "        for s_loc, n in seen_locations.items():\n",
    "            cov = covariance_function(distance_function(b_loc, s_loc))\n",
    "            temp += cov * (1 + log(n))\n",
    "    mean_cov = temp/(batch_size*sum(list(seen_locations.values())))\n",
    "    cov_factor = exp(-mean_cov)\n",
    "    bsize_factor = exp((batch_size/seen_size)**0.5)-1\n",
    "    print('covariance factor:', cov_factor)\n",
    "    print('batch size factor:', exp((batch_size/seen_size)**0.1)-1)\n",
    "    lr = meta_rate*bsize_factor*cov_factor\n",
    "    return lr\n",
    "\n",
    "# meta train with beta\n",
    "meta_history = meta_learner.meta_fit(10, batch_size=10, basic_train=True, bootstrap_train=True, use_test_for_meta=True, randomize=True,\n",
    "                                    beta_function=beta_function, covariance_function=covariance_function, distance_function=distance_function)\n",
    "plt.plot(meta_history)\n",
    "plt.title('Meta Training with Beta History')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 10  Basic training step:  1 / 8 loss:  33.434742\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 10  Basic training step:  2 / 8 loss:  33.213722\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 10  Basic training step:  3 / 8 loss:  29.951319\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 10  Basic training step:  4 / 8 loss:  30.026714\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 10  Basic training step:  5 / 8 loss:  31.6845\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 10  Basic training step:  6 / 8 loss:  25.54113\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 10  Basic training step:  7 / 8 loss:  25.593716\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 10  Basic training step:  8 / 8 loss:  22.469603\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 10 Bootstrap training step: 1 / 10 loss:  19.13652\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 10 Bootstrap training step: 2 / 10 loss:  21.656738\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 10 Bootstrap training step: 3 / 10 loss:  20.857126\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 10 Bootstrap training step: 4 / 10 loss:  22.425863\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 10 Bootstrap training step: 5 / 10 loss:  19.754923\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 10 Bootstrap training step: 6 / 10 loss:  20.470453\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 10 Bootstrap training step: 7 / 10 loss:  19.644949\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 10 Bootstrap training step: 8 / 10 loss:  18.107426\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 10 Bootstrap training step: 9 / 10 loss:  16.406824\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 10 Bootstrap training step: 10 / 10 loss:  17.774519\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 2 / 10  Basic training step:  1 / 8 loss:  16.575842\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 2 / 10  Basic training step:  2 / 8 loss:  16.851442\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 2 / 10  Basic training step:  3 / 8 loss:  16.372837\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 2 / 10  Basic training step:  4 / 8 loss:  17.101572\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 2 / 10  Basic training step:  5 / 8 loss:  18.26019\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 2 / 10  Basic training step:  6 / 8 loss:  16.50798\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 2 / 10  Basic training step:  7 / 8 loss:  16.114544\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 2 / 10  Basic training step:  8 / 8 loss:  14.349815\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 2 / 10 Bootstrap training step: 1 / 10 loss:  14.914301\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 2 / 10 Bootstrap training step: 2 / 10 loss:  14.560631\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 2 / 10 Bootstrap training step: 3 / 10 loss:  14.150479\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 2 / 10 Bootstrap training step: 4 / 10 loss:  15.365039\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 2 / 10 Bootstrap training step: 5 / 10 loss:  14.608961\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 2 / 10 Bootstrap training step: 6 / 10 loss:  13.04382\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 2 / 10 Bootstrap training step: 7 / 10 loss:  13.988101\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 2 / 10 Bootstrap training step: 8 / 10 loss:  12.360151\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 2 / 10 Bootstrap training step: 9 / 10 loss:  13.644211\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 2 / 10 Bootstrap training step: 10 / 10 loss:  13.493948\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 3 / 10  Basic training step:  1 / 8 loss:  12.861052\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 3 / 10  Basic training step:  2 / 8 loss:  12.887213\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 3 / 10  Basic training step:  3 / 8 loss:  13.159094\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 3 / 10  Basic training step:  4 / 8 loss:  13.060591\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 3 / 10  Basic training step:  5 / 8 loss:  14.331848\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 3 / 10  Basic training step:  6 / 8 loss:  12.928937\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 3 / 10  Basic training step:  7 / 8 loss:  12.596219\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 3 / 10  Basic training step:  8 / 8 loss:  11.73109\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 3 / 10 Bootstrap training step: 1 / 10 loss:  11.952495\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 3 / 10 Bootstrap training step: 2 / 10 loss:  11.950813\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 3 / 10 Bootstrap training step: 3 / 10 loss:  11.489662\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 3 / 10 Bootstrap training step: 4 / 10 loss:  12.238554\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 3 / 10 Bootstrap training step: 5 / 10 loss:  11.7084255\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 3 / 10 Bootstrap training step: 6 / 10 loss:  11.698855\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 3 / 10 Bootstrap training step: 7 / 10 loss:  11.581521\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 3 / 10 Bootstrap training step: 8 / 10 loss:  11.416252\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 3 / 10 Bootstrap training step: 9 / 10 loss:  11.032999\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 3 / 10 Bootstrap training step: 10 / 10 loss:  11.800253\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 4 / 10  Basic training step:  1 / 8 loss:  10.823858\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 4 / 10  Basic training step:  2 / 8 loss:  10.895068\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 4 / 10  Basic training step:  3 / 8 loss:  11.124208\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 4 / 10  Basic training step:  4 / 8 loss:  11.165213\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 4 / 10  Basic training step:  5 / 8 loss:  12.047006\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 4 / 10  Basic training step:  6 / 8 loss:  11.059008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 4 / 10  Basic training step:  7 / 8 loss:  10.926249\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 4 / 10  Basic training step:  8 / 8 loss:  10.303172\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 4 / 10 Bootstrap training step: 1 / 10 loss:  10.372353\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 4 / 10 Bootstrap training step: 2 / 10 loss:  10.152141\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 4 / 10 Bootstrap training step: 3 / 10 loss:  10.60841\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 4 / 10 Bootstrap training step: 4 / 10 loss:  10.358205\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 4 / 10 Bootstrap training step: 5 / 10 loss:  10.833624\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 4 / 10 Bootstrap training step: 6 / 10 loss:  10.640739\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 4 / 10 Bootstrap training step: 7 / 10 loss:  10.239675\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 4 / 10 Bootstrap training step: 8 / 10 loss:  10.652456\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 4 / 10 Bootstrap training step: 9 / 10 loss:  10.010732\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 4 / 10 Bootstrap training step: 10 / 10 loss:  9.672663\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 5 / 10  Basic training step:  1 / 8 loss:  9.827105\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 5 / 10  Basic training step:  2 / 8 loss:  9.726404\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 5 / 10  Basic training step:  3 / 8 loss:  10.038406\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 5 / 10  Basic training step:  4 / 8 loss:  10.060038\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 5 / 10  Basic training step:  5 / 8 loss:  10.8896885\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 5 / 10  Basic training step:  6 / 8 loss:  10.0740185\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 5 / 10  Basic training step:  7 / 8 loss:  9.848954\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 5 / 10  Basic training step:  8 / 8 loss:  9.336676\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 5 / 10 Bootstrap training step: 1 / 10 loss:  9.796608\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 5 / 10 Bootstrap training step: 2 / 10 loss:  9.169538\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 5 / 10 Bootstrap training step: 3 / 10 loss:  9.463442\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 5 / 10 Bootstrap training step: 4 / 10 loss:  9.467055\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 5 / 10 Bootstrap training step: 5 / 10 loss:  9.643458\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 5 / 10 Bootstrap training step: 6 / 10 loss:  9.756254\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 5 / 10 Bootstrap training step: 7 / 10 loss:  9.48288\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 5 / 10 Bootstrap training step: 8 / 10 loss:  9.466362\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 5 / 10 Bootstrap training step: 9 / 10 loss:  9.295145\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 5 / 10 Bootstrap training step: 10 / 10 loss:  9.310046\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 6 / 10  Basic training step:  1 / 8 loss:  9.137926\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 6 / 10  Basic training step:  2 / 8 loss:  9.193415\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 6 / 10  Basic training step:  3 / 8 loss:  9.263948\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 6 / 10  Basic training step:  4 / 8 loss:  9.179237\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 6 / 10  Basic training step:  5 / 8 loss:  9.874602\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 6 / 10  Basic training step:  6 / 8 loss:  9.1659775\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 6 / 10  Basic training step:  7 / 8 loss:  9.296546\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 6 / 10  Basic training step:  8 / 8 loss:  8.701983\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 6 / 10 Bootstrap training step: 1 / 10 loss:  8.775746\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 6 / 10 Bootstrap training step: 2 / 10 loss:  8.830195\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 6 / 10 Bootstrap training step: 3 / 10 loss:  9.02239\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 6 / 10 Bootstrap training step: 4 / 10 loss:  8.985197\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 6 / 10 Bootstrap training step: 5 / 10 loss:  8.718241\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 6 / 10 Bootstrap training step: 6 / 10 loss:  9.208824\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 6 / 10 Bootstrap training step: 7 / 10 loss:  8.943029\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 6 / 10 Bootstrap training step: 8 / 10 loss:  8.966156\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 6 / 10 Bootstrap training step: 9 / 10 loss:  8.701836\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 6 / 10 Bootstrap training step: 10 / 10 loss:  8.442561\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 7 / 10  Basic training step:  1 / 8 loss:  8.64667\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 7 / 10  Basic training step:  2 / 8 loss:  8.557823\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 7 / 10  Basic training step:  3 / 8 loss:  8.642229\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 7 / 10  Basic training step:  4 / 8 loss:  8.654683\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 7 / 10  Basic training step:  5 / 8 loss:  9.2083435\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 7 / 10  Basic training step:  6 / 8 loss:  8.64813\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 7 / 10  Basic training step:  7 / 8 loss:  8.733041\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 7 / 10  Basic training step:  8 / 8 loss:  8.282037\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 7 / 10 Bootstrap training step: 1 / 10 loss:  8.196215\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 7 / 10 Bootstrap training step: 2 / 10 loss:  8.104622\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 7 / 10 Bootstrap training step: 3 / 10 loss:  8.422345\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 7 / 10 Bootstrap training step: 4 / 10 loss:  8.46076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 7 / 10 Bootstrap training step: 5 / 10 loss:  8.719534\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 7 / 10 Bootstrap training step: 6 / 10 loss:  8.721205\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 7 / 10 Bootstrap training step: 7 / 10 loss:  8.338217\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 7 / 10 Bootstrap training step: 8 / 10 loss:  8.155735\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 7 / 10 Bootstrap training step: 9 / 10 loss:  8.515142\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 7 / 10 Bootstrap training step: 10 / 10 loss:  8.222095\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 8 / 10  Basic training step:  1 / 8 loss:  8.19908\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 8 / 10  Basic training step:  2 / 8 loss:  8.102743\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 8 / 10  Basic training step:  3 / 8 loss:  8.211493\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 8 / 10  Basic training step:  4 / 8 loss:  8.200884\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 8 / 10  Basic training step:  5 / 8 loss:  8.60582\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 8 / 10  Basic training step:  6 / 8 loss:  8.301689\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 8 / 10  Basic training step:  7 / 8 loss:  8.392217\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 8 / 10  Basic training step:  8 / 8 loss:  7.854959\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 8 / 10 Bootstrap training step: 1 / 10 loss:  8.019711\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 8 / 10 Bootstrap training step: 2 / 10 loss:  8.016188\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 8 / 10 Bootstrap training step: 3 / 10 loss:  8.22861\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 8 / 10 Bootstrap training step: 4 / 10 loss:  8.331417\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 8 / 10 Bootstrap training step: 5 / 10 loss:  8.008603\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 8 / 10 Bootstrap training step: 6 / 10 loss:  7.892761\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 8 / 10 Bootstrap training step: 7 / 10 loss:  7.953906\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 8 / 10 Bootstrap training step: 8 / 10 loss:  8.046926\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 8 / 10 Bootstrap training step: 9 / 10 loss:  7.998374\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 8 / 10 Bootstrap training step: 10 / 10 loss:  8.208735\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 9 / 10  Basic training step:  1 / 8 loss:  7.8545103\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 9 / 10  Basic training step:  2 / 8 loss:  7.752434\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 9 / 10  Basic training step:  3 / 8 loss:  7.9084015\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 9 / 10  Basic training step:  4 / 8 loss:  7.88148\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 9 / 10  Basic training step:  5 / 8 loss:  8.33216\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 9 / 10  Basic training step:  6 / 8 loss:  7.9020796\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 9 / 10  Basic training step:  7 / 8 loss:  7.912921\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 9 / 10  Basic training step:  8 / 8 loss:  7.580827\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 9 / 10 Bootstrap training step: 1 / 10 loss:  7.517296\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 9 / 10 Bootstrap training step: 2 / 10 loss:  7.7982864\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 9 / 10 Bootstrap training step: 3 / 10 loss:  7.8930006\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 9 / 10 Bootstrap training step: 4 / 10 loss:  7.9081445\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 9 / 10 Bootstrap training step: 5 / 10 loss:  7.5774064\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 9 / 10 Bootstrap training step: 6 / 10 loss:  7.7479806\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 9 / 10 Bootstrap training step: 7 / 10 loss:  8.027395\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 9 / 10 Bootstrap training step: 8 / 10 loss:  7.6097994\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 9 / 10 Bootstrap training step: 9 / 10 loss:  7.5098343\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 9 / 10 Bootstrap training step: 10 / 10 loss:  7.6140685\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 10 / 10  Basic training step:  1 / 8 loss:  7.5867033\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 10 / 10  Basic training step:  2 / 8 loss:  7.5358744\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 10 / 10  Basic training step:  3 / 8 loss:  7.5876145\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 10 / 10  Basic training step:  4 / 8 loss:  7.60464\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 10 / 10  Basic training step:  5 / 8 loss:  8.030029\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 10 / 10  Basic training step:  6 / 8 loss:  7.644536\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 10 / 10  Basic training step:  7 / 8 loss:  7.6958275\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 10 / 10  Basic training step:  8 / 8 loss:  7.3607664\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 10 / 10 Bootstrap training step: 1 / 10 loss:  7.740178\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 10 / 10 Bootstrap training step: 2 / 10 loss:  8.068184\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 10 / 10 Bootstrap training step: 3 / 10 loss:  7.29062\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 10 / 10 Bootstrap training step: 4 / 10 loss:  7.4216337\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 10 / 10 Bootstrap training step: 5 / 10 loss:  7.28958\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 10 / 10 Bootstrap training step: 6 / 10 loss:  7.3893356\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 10 / 10 Bootstrap training step: 7 / 10 loss:  7.5527205\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 10 / 10 Bootstrap training step: 8 / 10 loss:  7.3292036\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 10 / 10 Bootstrap training step: 9 / 10 loss:  7.436531\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 10 / 10 Bootstrap training step: 10 / 10 loss:  7.3289757\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MDN_model_wo_beta = model_generator()\n",
    "inner_optimizer_wob = tf.keras.optimizers.Adam(0.0001)\n",
    "meta_optimizer_wob = tf.keras.optimizers.Adam(0.0001)\n",
    "meta_learner_wo_beta = MetaSGD(MDN_model_wo_beta, gamma_loss,  meta_optimizer_wob, inner_step, inner_optimizer_wob, taskextractor)\n",
    "# meta train\n",
    "meta_history_wob = meta_learner_wo_beta.meta_fit(10, batch_size=10, basic_train=True, bootstrap_train=True, use_test_for_meta=True, randomize=True)\n",
    "plt.plot(meta_history_wob, \"-b\", label=\"without beta\")\n",
    "plt.title('Meta Training Without Beta History ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(meta_history_wob, \"-b\", label=\"without beta\")\n",
    "plt.plot(meta_history, \"-r\", label=\"with beta\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.title('Meta Training History Compare')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learner.meta_model.set_weights(meta_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 12s 97ms/step - loss: 5.9748 - val_loss: 6.7861\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 5.9655 - val_loss: 6.4503\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 6.0707 - val_loss: 6.3228\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 6.0438 - val_loss: nan\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 5.9490 - val_loss: nan\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 5.9490 - val_loss: nan\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 5.9713 - val_loss: nan\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 5.9675 - val_loss: nan\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 5.9840 - val_loss: nan\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 5.9684 - val_loss: nan\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 5.9785 - val_loss: nan\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 5.9973 - val_loss: nan\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 5.9683 - val_loss: nan\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 5.9822 - val_loss: nan\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 5.9136 - val_loss: 5.9033\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 5.9798 - val_loss: nan\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 5.9974 - val_loss: 5.9042\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 5.9552 - val_loss: 5.9137\n",
      "Epoch 19/30\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 6.0024 - val_loss: nan\n",
      "Epoch 20/30\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 6.0074 - val_loss: 5.9306\n",
      "Epoch 21/30\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 5.9268 - val_loss: 5.9150\n",
      "Epoch 22/30\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 5.9522 - val_loss: 5.9259\n",
      "Epoch 23/30\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 5.9727 - val_loss: nan\n",
      "Epoch 24/30\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 5.9368 - val_loss: nan\n",
      "Epoch 25/30\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 5.9643 - val_loss: nan\n",
      "Epoch 26/30\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.0477 - val_loss: 5.9134\n",
      "Epoch 27/30\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.0202 - val_loss: 5.9105\n",
      "Epoch 28/30\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 5.9434 - val_loss: 5.9153\n",
      "Epoch 29/30\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 5.9525 - val_loss: 5.9225\n",
      "Epoch 30/30\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 5.9238 - val_loss: 5.9204\n"
     ]
    }
   ],
   "source": [
    "meta_weights = meta_learner.meta_model.get_weights()\n",
    "trained_meta_model = meta_learner.meta_model\n",
    "optimizer = tf.keras.optimizers.Adam(0.000001)\n",
    "trained_meta_model.compile(optimizer=optimizer, loss=gamma_loss)\n",
    "meta_history_fine_tune = trained_meta_model.fit(train_x, train_y, epochs=30, validation_data=[test_x, test_y])\n",
    "meta_learner.meta_model.set_weights(meta_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(meta_history_fine_tune, 'fine tune history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_meta_model = meta_learner.meta_model\n",
    "untrainded_weights = trained_meta_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc1 = [1, 1]\n",
    "loc2 = [2, 2]\n",
    "(loc1[0] - loc2[0])**2 + (loc1[1] - loc2[1])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 1\n",
      "b 2\n"
     ]
    }
   ],
   "source": [
    "for i, j in a.items():\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Meta Training History')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(meta_history)\n",
    "plt.title('Meta Training History')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_24\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_148 (InputLayer)         [(None, 10, 1, 3, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv_lstm2d_72 (ConvLSTM2D)    (None, 10, 1, 2, 20  3760        ['input_148[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_lstm2d_73 (ConvLSTM2D)    (None, 10, 1, 1, 20  6480        ['conv_lstm2d_72[1][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_lstm2d_74 (ConvLSTM2D)    (None, 1, 1, 20)     3280        ['conv_lstm2d_73[1][0]']         \n",
      "                                                                                                  \n",
      " flatten_48 (Flatten)           (None, 20)           0           ['conv_lstm2d_74[1][0]']         \n",
      "                                                                                                  \n",
      " dense_200 (Dense)              (None, 512)          10752       ['flatten_48[1][0]']             \n",
      "                                                                                                  \n",
      " input_149 (InputLayer)         [(None, 3, 3, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " input_150 (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " batch_normalization_195 (Batch  (None, 512)         2048        ['dense_200[1][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 2, 2, 20)     100         ['input_149[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_196 (Batch  (None, 1)           4           ['input_150[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dense_201 (Dense)              (None, 300)          153900      ['batch_normalization_195[1][0]']\n",
      "                                                                                                  \n",
      " flatten_49 (Flatten)           (None, 80)           0           ['conv2d_24[1][0]']              \n",
      "                                                                                                  \n",
      " dense_202 (Dense)              (None, 30)           60          ['batch_normalization_196[1][0]']\n",
      "                                                                                                  \n",
      " concatenate_48 (Concatenate)   (None, 410)          0           ['dense_201[1][0]',              \n",
      "                                                                  'flatten_49[1][0]',             \n",
      "                                                                  'dense_202[1][0]']              \n",
      "                                                                                                  \n",
      " dense_203 (Dense)              (None, 128)          52608       ['concatenate_48[1][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_197 (Batch  (None, 128)         512         ['dense_203[1][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dense_204 (Dense)              (None, 128)          16512       ['batch_normalization_197[1][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_198 (Batch  (None, 128)         512         ['dense_204[1][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dense_205 (Dense)              (None, 128)          16512       ['batch_normalization_198[1][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_199 (Batch  (None, 128)         512         ['dense_205[1][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dense_206 (Dense)              (None, 9000)         1161000     ['batch_normalization_199[1][0]']\n",
      "                                                                                                  \n",
      " dense_207 (Dense)              (None, 9000)         1161000     ['batch_normalization_199[1][0]']\n",
      "                                                                                                  \n",
      " sigmas (Dense)                 (None, 9000)         1161000     ['batch_normalization_199[1][0]']\n",
      "                                                                                                  \n",
      " concatenate_49 (Concatenate)   (None, 27000)        0           ['dense_206[1][0]',              \n",
      "                                                                  'dense_207[1][0]',              \n",
      "                                                                  'sigmas[1][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,750,552\n",
      "Trainable params: 3,748,758\n",
      "Non-trainable params: 1,794\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trained_meta_model = meta_learner.meta_model\n",
    "optimizer = tf.keras.optimizers.Adam(0.0000001)\n",
    "trained_meta_model.compile(optimizer=optimizer, loss=gamma_loss)\n",
    "trained_meta_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 5.7476\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 5.7670\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 5.7426\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 5.8128\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 5.7806\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 5.8076\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 5.8419\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 5.8233\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 5.8088\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 5.7748\n"
     ]
    }
   ],
   "source": [
    "meta_history_fine_tune = trained_meta_model.fit(train_x, train_y, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Debug Downscaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(probdownscale.Downscaler)\n",
    "from probdownscale.Downscaler import Downscaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "21/21 [==============================] - 12s 70ms/step - loss: 7.0227\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 1s 70ms/step - loss: 6.8977\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 75ms/step - loss: 6.9414\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 86ms/step - loss: 6.9062\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 86ms/step - loss: 6.9783\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.9534\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 86ms/step - loss: 6.9184\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 86ms/step - loss: 6.8386\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 91ms/step - loss: 6.9550\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 89ms/step - loss: 6.9486\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 88ms/step - loss: 6.9090\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 86ms/step - loss: 6.9085\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.8420\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.8798\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.8199\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.7807\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 86ms/step - loss: 6.8661\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.8275\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.8760\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 93ms/step - loss: 6.7920\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.8467\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.8083\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 92ms/step - loss: 6.7965\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 86ms/step - loss: 6.9823\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 93ms/step - loss: 6.9751\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 86ms/step - loss: 6.7908\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 87ms/step - loss: 6.8178\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.8679\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 86ms/step - loss: 6.8454\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 86ms/step - loss: 6.8493\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 90ms/step - loss: 6.8860\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 92ms/step - loss: 6.7613\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 90ms/step - loss: 6.8079\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 90ms/step - loss: 6.8172\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 91ms/step - loss: 6.9387\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.8046\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 88ms/step - loss: 6.8190\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.7263\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.7847\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 7.2282\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7636\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 86ms/step - loss: 6.7760\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 86ms/step - loss: 6.8128\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 87ms/step - loss: 6.8632\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 88ms/step - loss: 6.8173\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.6627\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 90ms/step - loss: 6.8947\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 89ms/step - loss: 6.7368\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.8502\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 92ms/step - loss: 6.7721\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 86ms/step - loss: 6.9774\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.7378\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 93ms/step - loss: 6.7411\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 93ms/step - loss: 6.7898\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.8268\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.6007\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.7115\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.6846\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7254\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7541\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.9475\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7618\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7915\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 91ms/step - loss: 6.9382\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.7937\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8516\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.9789\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.9063\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7999\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8707\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8268\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.6846\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8782\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7250\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7611\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 86ms/step - loss: 6.7461\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8922\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8315\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 82ms/step - loss: 6.8321\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8715\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 7.0592\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8056\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7613\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8793\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8918\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7540\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.9507\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 7.0169\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8520\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 7.0762\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 82ms/step - loss: 6.8236\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.9195\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.8950\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 86ms/step - loss: 6.8614\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.9783\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8376\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 7.0829\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9702\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7777\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8984\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.9382\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 82ms/step - loss: 6.9020\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8016\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8873\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8483\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 82ms/step - loss: 6.8673\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8840\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8985\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 82ms/step - loss: 6.8960\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.9356\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.9812\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 7.1719\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.9410\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 82ms/step - loss: 6.9571\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.9956\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7870\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 82ms/step - loss: 7.0030\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 82ms/step - loss: 6.9507\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8050\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8833\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 82ms/step - loss: 6.9511\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.9787\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 86ms/step - loss: 6.9510\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.9106\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 7.0389\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.9688\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 7.0412\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8790\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.9603\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 7.0178\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9610\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 7.1300\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 88ms/step - loss: 6.8530\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7473\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9665\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9271\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8530\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8299\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8482\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9085\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.9829\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8710\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8019\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8679\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8140\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7774\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8367\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 86ms/step - loss: 7.0124\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 7.3923\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9621\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 82ms/step - loss: 6.8526\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7828\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 89ms/step - loss: 6.7635\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9409\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9586\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8645\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.9090\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 7.3077\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.9050\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8134\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8224\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.9408\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.8352\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.9665\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.9588\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.6514\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 7.0177\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8529\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 7.0416\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8159\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7229\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8390\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7166\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7034\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9132\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7671\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8635\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.9049\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 86ms/step - loss: 6.9448\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8253\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.9460\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 86ms/step - loss: 6.8474\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.9673\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8008\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 7.0256\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 88ms/step - loss: 6.9385\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 89ms/step - loss: 6.9539\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 89ms/step - loss: 6.9278\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 88ms/step - loss: 6.9634\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8782\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.8264\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 7.1649\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 7.0393\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.7706\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8390\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8287\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8469\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8876\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8852\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 7.0151\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8213\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 7.0190\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9905\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.9435\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 82ms/step - loss: 6.8508\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.9873\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8902\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7896\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.8500\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 86ms/step - loss: 6.8534\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 82ms/step - loss: 6.7637\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 89ms/step - loss: 6.6975\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7411\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8505\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8355\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 82ms/step - loss: 6.8849\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 82ms/step - loss: 6.6710\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7377\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7238\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7463\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 7.7942\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7552\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8592\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7582\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.9584\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 86ms/step - loss: 6.6478\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7459\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8348\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.6936\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7958\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.6855\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7343\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.6044\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7798\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.6599\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7923\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.6881\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.6862\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.6494\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 7.0296\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 7.0040\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 86ms/step - loss: 6.9007\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.8461\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.9827\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8521\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8223\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.8269\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9436\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8509\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8679\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 7.0066\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 86ms/step - loss: 6.7868\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9799\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 7.0382\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.8450\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8623\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7696\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 86ms/step - loss: 7.0153\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9811\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.8777\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8739\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8398\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7914\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8204\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.9013\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 86ms/step - loss: 6.8178\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 86ms/step - loss: 6.8333\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.8716\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 7.1469\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8063\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 88ms/step - loss: 6.8774\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9004\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.8531\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9064\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9523\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8776\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.7881\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.9506\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 91ms/step - loss: 6.7966\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.9062\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.8492\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8158\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 7.0228\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7173\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.8857\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.6007\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 86ms/step - loss: 6.8492\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7962\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9018\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8907\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.9904\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.9699\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 86ms/step - loss: 7.0641\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.7901\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7578\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8772\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8164\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.9524\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7942\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9063\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8438\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.9019\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7713\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9354\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8355\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7456\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7140\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8292\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9030\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 87ms/step - loss: 6.7671\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7951\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8759\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7974\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7018\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7022\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7003\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.6906\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8801\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.8908\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7540\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 92ms/step - loss: 6.7119\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6782\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.8496\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 91ms/step - loss: 6.7818\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 90ms/step - loss: 6.8101\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7573\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 89ms/step - loss: 6.8315\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 89ms/step - loss: 6.7876\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 90ms/step - loss: 6.9333\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 91ms/step - loss: 6.6721\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 82ms/step - loss: 6.9447\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8979\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8132\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8730\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 86ms/step - loss: 6.7414\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9229\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.9487\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.7495\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7650\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8940\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9038\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8469\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8471\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8770\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7269\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7613\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.8832\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.7642\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.9087\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8121\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8047\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7925\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7588\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8394\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.8266\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.8224\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7835\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.7461\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7428\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.7740\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 82ms/step - loss: 6.7589\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9058\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.5837\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 7.0218\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7250\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8569\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 86ms/step - loss: 6.7104\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8068\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7934\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8780\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.7317\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.7708\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7355\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 87ms/step - loss: 6.8667\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8399\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.9258\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.7031\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.6759\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7769\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8870\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9305\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 86ms/step - loss: 6.7994\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7605\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 7.0622\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8259\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7653\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.6729\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7395\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7213\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8403\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7985\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9421\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 7.0363\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.8578\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.9685\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8198\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9597\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.7489\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9123\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8729\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 7.1219\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 86ms/step - loss: 6.9669\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.8620\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9152\n",
      "Epoch 15/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8563\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7874\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7972\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7755\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8277\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9009\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.7628\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8096\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8575\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8298\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8247\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8462\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7589\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7730\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 7.0389\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.9292\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 88ms/step - loss: 6.7869\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.8037\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8859\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8030\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 7.0768\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.9643\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8419\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9674\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.9486\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7927\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8909\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9106\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8382\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.9504\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.9607\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 7.0203\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 7.0067\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 86ms/step - loss: 6.8239\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9020\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.8328\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 7.0535\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.9020\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7808\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9759\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8755\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8677\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7048\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8168\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 82ms/step - loss: 6.8586\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 87ms/step - loss: 6.9279\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 82ms/step - loss: 7.0160\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9552\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 7.0051\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 7.0511\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.8983\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 7.0300\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.9032\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 7.0501\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 7.0588\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 7.0164\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 82ms/step - loss: 6.8555\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 7.0928\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 7.3182\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 7.1465\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.9609\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9618\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 7.1494\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.9513\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9976\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.9179\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9307\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9483\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 91ms/step - loss: 6.9028\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 86ms/step - loss: 6.9987\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 7.3352\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 7.0586\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8724\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9112\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 88ms/step - loss: 6.8523\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.9864\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8137\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7336\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8954\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.8755\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7341\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7619\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9582\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9607\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.8515\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7665\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7117\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7663\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7847\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 7.0180\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.8185\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8097\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8440\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 86ms/step - loss: 6.8290\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8426\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8661\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7111\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8937\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.8450\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7892\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7734\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7200\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8441\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7926\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 88ms/step - loss: 6.7157\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7636\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8506\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7923\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.7661\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7915\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8205\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.9714\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8048\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.9368\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8594\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8556\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7785\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7958\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8338\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.6286\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7556\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.8914\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7698\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7603\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8180\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8213\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.9402\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7836\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.6707\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7696\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7175\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 6.7742\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 85ms/step - loss: 6.8365\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.7852\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 88ms/step - loss: 6.8632\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 84ms/step - loss: 6.8214\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7915\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8938\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7443\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8392\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7980\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8546\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7282\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.6903\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8847\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.8501\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7484\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6805\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.8383\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7939\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6974\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8380\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7789\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.7576\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7087\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7195\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.8931\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7240\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7178\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7303\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6798\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8399\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6479\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8661\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8308\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6668\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6369\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7442\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7194\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6826\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7284\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7371\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5554\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6536\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5818\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7174\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6211\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6789\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.6951\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5497\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6046\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6714\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6091\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7202\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5653\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6850\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6065\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6799\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7125\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6149\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7212\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6712\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6941\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.7631\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 107ms/step - loss: 6.6330\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 104ms/step - loss: 6.7799\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.6239\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8223\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6752\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7586\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6964\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7632\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6485\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.6711\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.7515\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 104ms/step - loss: 6.6153\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.8107\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6196\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6304\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8068\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7083\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6269\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6286\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5991\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6879\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8084\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7665\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6634\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6003\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6884\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.5748\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6634\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7072\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7465\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6798\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6353\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7687\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6887\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.6433\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6645\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6025\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6597\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7911\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7026\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6310\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6950\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7793\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7899\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7046\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6878\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6862\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6747\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 106ms/step - loss: 6.6408\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6079\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7705\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6418\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.7638\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7652\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6498\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6188\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5708\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.8143\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7016\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7734\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6011\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5644\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6554\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7770\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8684\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7685\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7742\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7453\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6507\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.8520\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7722\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6389\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.8051\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7914\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7391\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8723\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8636\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7272\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8294\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7748\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.7510\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.6799\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6493\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7134\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5461\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8528\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7812\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6557\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8842\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.8456\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.6780\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.8527\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.8748\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.8875\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.7561\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.8014\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7608\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8385\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6888\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.8048\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.8417\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.6930\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7129\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7300\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7465\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7344\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 3s 151ms/step - loss: 6.7037\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 3s 118ms/step - loss: 6.8008\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.6400\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7284\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7178\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6630\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7728\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.7483\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5799\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8105\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7016\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6596\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6275\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7705\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6597\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6953\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.8101\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6783\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8003\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.9702\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7718\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.9792\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7316\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7472\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7228\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.9920\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7019\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.9855\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.8600\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7548\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7699\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7676\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.8857\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.7188\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7795\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8178\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.8230\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.8073\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6596\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7771\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.9184\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7818\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.8790\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7536\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7083\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7454\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7500\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6798\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.8183\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6640\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6889\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8502\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7927\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7952\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8786\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7721\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7262\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6811\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.7742\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8532\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8653\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.8116\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7234\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.9001\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7435\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.8279\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.8198\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7694\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6946\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7722\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.8360\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7273\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7355\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6814\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6576\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6678\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.8492\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6196\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.6122\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6638\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5697\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7535\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6083\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.6559\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8072\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6766\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7247\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5478\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7474\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5355\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.8458\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7182\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5855\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5933\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6990\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7523\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7560\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7647\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5597\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.5695\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7908\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7024\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6830\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5015\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6531\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6686\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5871\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6895\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 114ms/step - loss: 6.5290\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 105ms/step - loss: 6.5247\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7003\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5961\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6194\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6243\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6296\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6291\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7172\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7339\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6202\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6379\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.4851\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7381\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7788\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6414\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5582\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6175\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7608\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6428\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5631\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5853\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5568\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7064\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6509\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.4223\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5746\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5150\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.9041\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6277\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.7200\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6854\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7832\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6118\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6824\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7935\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7136\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.7815\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 107ms/step - loss: 6.6546\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 106ms/step - loss: 6.8848\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 105ms/step - loss: 6.6275\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 105ms/step - loss: 6.7107\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 105ms/step - loss: 6.6218\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 110ms/step - loss: 6.8001\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 115ms/step - loss: 6.7281\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6971\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7198\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5910\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7093\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6941\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7190\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7171\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6274\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6983\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5914\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.7690\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7126\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8075\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.6895\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6482\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6564\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6056\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6571\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6481\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5371\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5279\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5989\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5391\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6928\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7014\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6786\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6981\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6391\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6951\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.8256\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6609\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8477\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7724\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5764\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.6406\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6886\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7212\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5771\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6228\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6842\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5911\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.9491\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6915\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.7427\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7544\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6789\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7052\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6795\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5859\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7518\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7211\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7002\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7048\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7158\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6995\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.8064\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7121\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7112\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5614\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7127\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.7617\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6010\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 7.0340\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7738\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6694\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.9365\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6520\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6184\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6447\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6736\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7758\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6787\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5605\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 94ms/step - loss: 6.7294\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7290\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6524\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6207\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5087\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6802\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6533\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7544\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6333\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6649\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.7098\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7485\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.7597\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6491\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6793\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6803\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6791\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6251\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5769\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6676\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8147\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6705\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6867\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7228\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6062\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6483\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.6306\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6666\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6195\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6535\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.8751\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6331\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6017\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6750\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7787\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.9049\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7691\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7061\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.5759\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7296\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6587\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6446\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7163\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6603\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6366\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6803\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7067\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7764\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5970\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7153\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8841\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7212\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8694\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6732\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7307\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7107\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7001\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6824\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7066\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 7.0395\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.9157\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7806\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 105ms/step - loss: 6.9293\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 108ms/step - loss: 6.7279\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7940\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8200\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7188\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.8151\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8518\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.8691\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 7.0327\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7502\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7401\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7854\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6619\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 7.0076\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.8437\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.8491\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.9330\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8258\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 2s 96ms/step - loss: 6.8289\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.8809\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6907\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8984\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7678\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.9762\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.8849\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8757\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8232\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.8361\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.7140\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.8068\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.8568\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7561\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.9499\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8611\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.9016\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8018\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8299\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8183\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.8790\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7657\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.9793\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6737\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7766\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.8679\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.7024\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6943\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7789\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7357\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.8001\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8967\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7102\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7590\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.8417\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7568\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8064\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.9046\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.8245\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8962\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.5736\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6436\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6270\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5757\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6950\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5678\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.6542\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6656\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6350\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5685\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5390\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5265\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6665\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5163\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5516\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5552\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6281\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5571\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6154\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5400\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 117ms/step - loss: 6.5663\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 106ms/step - loss: 6.6961\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 105ms/step - loss: 6.6997\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.5185\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5999\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5498\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5281\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6308\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4691\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5261\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6458\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6365\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5416\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6379\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5595\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6919\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7371\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.9424\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6567\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6820\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6134\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6637\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6112\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6497\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6741\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6636\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8170\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6346\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.6423\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6462\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5971\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5791\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5904\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6477\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6541\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6110\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7594\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 114ms/step - loss: 6.5675\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 116ms/step - loss: 6.6966\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 106ms/step - loss: 6.6576\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6623\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.7251\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6266\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.4901\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6672\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6058\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7782\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7397\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7527\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6179\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5328\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7836\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6026\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.7573\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7093\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5556\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5694\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5632\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5671\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7013\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6525\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5966\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7365\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.5897\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5002\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6853\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6686\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6881\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5689\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5921\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6888\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7216\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7504\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6135\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7445\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7154\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8733\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6443\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.7376\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.7526\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5943\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6760\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6726\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7624\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.9431\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7618\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7321\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6716\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6645\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6813\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6663\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7269\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7835\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 108ms/step - loss: 6.5829\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 3s 120ms/step - loss: 6.6283\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 118ms/step - loss: 6.7293\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 3s 120ms/step - loss: 6.6929\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 3s 123ms/step - loss: 6.6776\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 3s 119ms/step - loss: 6.5589\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 110ms/step - loss: 6.5490\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 112ms/step - loss: 6.4889\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 109ms/step - loss: 6.5836\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 112ms/step - loss: 6.4502\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 110ms/step - loss: 6.5276\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 107ms/step - loss: 6.4506\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 108ms/step - loss: 6.6062\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 108ms/step - loss: 6.4584\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 107ms/step - loss: 6.4171\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 107ms/step - loss: 6.5011\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 110ms/step - loss: 6.5382\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 109ms/step - loss: 6.4108\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 110ms/step - loss: 6.5086\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 108ms/step - loss: 6.5105\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 111ms/step - loss: 6.5205\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 111ms/step - loss: 6.4918\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 109ms/step - loss: 6.5819\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 111ms/step - loss: 6.3958\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 109ms/step - loss: 6.4212\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 107ms/step - loss: 6.6043\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 108ms/step - loss: 6.4400\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 109ms/step - loss: 6.3825\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 115ms/step - loss: 6.4386\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.5019\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5223\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6206\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3917\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.4557\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.4172\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3881\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4440\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.8636\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8357\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8190\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.7023\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.8816\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7651\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6607\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.9397\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7028\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8575\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8306\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7785\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 2s 96ms/step - loss: 6.9262\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8093\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8368\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7053\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8119\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8337\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.9215\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7626\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7700\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7794\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.7941\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6734\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7783\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8595\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6756\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6523\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.8353\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.9080\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.7036\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8347\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8489\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 104ms/step - loss: 6.7653\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7808\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8185\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7006\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7675\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.6233\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7830\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7831\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6373\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6771\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7391\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 7.0041\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7193\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6905\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.9160\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.8460\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7848\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6738\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6530\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6607\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7485\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6645\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5931\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6567\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6229\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6012\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6855\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.7093\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.8037\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7180\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6854\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7566\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7342\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6913\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7494\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.8728\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7924\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.8067\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.9281\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.8387\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.9391\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7201\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7180\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5690\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6953\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7454\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7056\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6063\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7648\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7807\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6500\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.9058\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7940\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6842\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.9891\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 105ms/step - loss: 6.7500\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6727\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.8054\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7478\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8390\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7434\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6762\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6976\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7823\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7662\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.8633\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 104ms/step - loss: 6.7010\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.8502\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8023\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8171\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7027\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8886\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6937\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.9228\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8367\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.7621\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7762\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7578\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7372\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6577\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7323\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.8284\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.6772\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.8630\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6244\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7193\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6465\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.7904\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6941\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6486\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 3s 127ms/step - loss: 6.6693\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 3s 120ms/step - loss: 6.6998\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.6709\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7289\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7671\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6932\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7508\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7828\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6414\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7305\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6343\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7331\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7734\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.8304\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7742\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6945\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6304\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7582\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.6233\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7424\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7296\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5880\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.9137\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6543\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6309\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5746\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6678\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5131\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 105ms/step - loss: 6.5448\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 108ms/step - loss: 6.5634\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 112ms/step - loss: 6.6900\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 112ms/step - loss: 6.5897\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 109ms/step - loss: 6.5829\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 109ms/step - loss: 6.5301\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 109ms/step - loss: 6.5408\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 107ms/step - loss: 6.7226\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 110ms/step - loss: 6.5088\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 110ms/step - loss: 6.6064\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.5052\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.5958\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.6716\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.4431\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.5296\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.6935\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.5430\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.5654\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.5119\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.6418\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.5784\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.5465\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.5431\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.6821\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.6221\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.5025\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 105ms/step - loss: 6.5701\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.7254\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.4890\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5141\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.5063\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.5810\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.5046\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.5247\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.5749\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.4906\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.6588\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.6954\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.5958\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.5344\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.5476\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.5153\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.4848\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.5520\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.5187\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.6214\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5782\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.6276\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.5321\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.5879\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 106ms/step - loss: 6.5673\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.5570\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.5370\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.5497\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.4674\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5086\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.5105\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.5219\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.5606\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.3863\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.5866\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.4858\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.4847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4791\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4530\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5080\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5040\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.4554\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4345\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4791\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3637\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4124\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4851\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5740\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4421\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.4329\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4652\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3718\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3977\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.4725\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5161\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.3856\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.3379\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.3486\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.4536\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4642\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5820\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4315\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4352\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.4065\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5310\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.4740\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 116ms/step - loss: 6.5553\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 107ms/step - loss: 6.4657\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5017\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.4903\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4089\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5192\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5211\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5935\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.5670\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4811\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5096\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5717\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5365\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.4193\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 107ms/step - loss: 6.4702\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.5378\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4432\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4666\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4096\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5677\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 3s 169ms/step - loss: 6.4838\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.4952\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5485\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4964\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4187\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4338\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4074\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6241\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 105ms/step - loss: 6.4715\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.4864\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.6028\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4876\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.5682\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.4131\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4359\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5739\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.4756\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4882\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4671\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4592\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4326\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 3s 121ms/step - loss: 6.3900\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.6350\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5698\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4426\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4283\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.4408\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.4816\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4509\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4330\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4322\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5128\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5222\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4765\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4967\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4756\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4756\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.6280\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7386\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7645\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6747\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7113\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7176\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.7785\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.6896\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7529\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7487\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7693\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.7287\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 7.0404\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7333\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7249\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6669\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7489\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7888\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7235\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.8386\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7569\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7433\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6678\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7027\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7659\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7483\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6607\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6620\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6910\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.7276\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7522\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5577\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6917\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6625\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6947\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5345\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4820\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5592\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6428\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5333\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6143\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6283\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6039\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5992\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5557\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5556\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5111\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6651\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7752\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5607\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5615\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5614\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6594\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5120\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.7535\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5865\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4874\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6426\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5841\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7616\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5075\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5840\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7305\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6610\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7093\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6699\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6705\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6380\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6526\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.6361\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6428\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7594\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5810\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6873\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8110\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.8282\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.8053\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7184\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6200\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.6236\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6351\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7003\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5304\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4489\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8076\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5666\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.5404\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 106ms/step - loss: 6.5755\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6856\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5508\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5779\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5538\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5154\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5977\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5583\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5678\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6272\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6587\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6198\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5974\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4576\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5143\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5409\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6244\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.6194\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.4636\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 107ms/step - loss: 6.6931\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 109ms/step - loss: 6.6178\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 106ms/step - loss: 6.6200\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 108ms/step - loss: 6.5132\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 106ms/step - loss: 6.5292\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 107ms/step - loss: 6.5789\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 109ms/step - loss: 6.4796\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.5250\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5328\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.5519\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5609\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4259\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.4353\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4475\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6090\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6123\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7081\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6464\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5214\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6349\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5889\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5293\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6012\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.5291\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5968\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6393\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5107\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5271\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4635\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6846\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6063\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.8112\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5793\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4523\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5511\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5332\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5870\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6232\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5788\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5465\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5386\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5302\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5643\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5530\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.4884\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4918\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5281\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6175\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 104ms/step - loss: 6.5743\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4852\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4834\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5660\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.4608\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5463\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4866\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5095\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4833\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.5921\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5159\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5295\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4288\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5705\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5971\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4611\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4741\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5388\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4829\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.8532\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4742\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4941\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6516\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5239\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4893\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5558\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5244\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4172\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5418\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4024\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.4219\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5649\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4429\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4709\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.4512\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4814\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5714\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5362\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5015\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6376\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5413\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4761\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 104ms/step - loss: 6.5066\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4311\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4626\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4380\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.4244\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.4828\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4935\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4706\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4690\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6391\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4730\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4372\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.3931\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.4863\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 105ms/step - loss: 6.4124\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 110ms/step - loss: 6.3477\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.3719\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4749\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4276\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4256\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3358\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4218\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.4594\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3677\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3100\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3900\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4438\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.2865\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3916\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3810\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3453\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4400\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.2519\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4710\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3649\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3394\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3251\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.2695\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3969\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4103\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3825\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3391\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4705\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3334\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.4747\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5611\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4138\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.3841\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5338\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4894\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.4252\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4740\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5021\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4125\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5133\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4020\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5001\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4266\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.4996\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3643\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4472\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3529\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5188\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.4186\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3526\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3791\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6340\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.4204\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3632\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.3634\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4489\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4232\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4436\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3063\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3930\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6187\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5287\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4595\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4301\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4628\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5063\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4952\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3424\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4751\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4203\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4009\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4274\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4288\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.4062\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5539\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4373\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3981\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4688\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4101\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4794\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.4103\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4391\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.3725\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4072\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4586\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3975\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3926\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4029\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5549\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7858\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7894\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7485\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.6649\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6942\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7112\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7505\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7084\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6532\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.6867\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7463\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.7335\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7157\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7133\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6663\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7359\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6966\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7050\n",
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6256\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6377\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6797\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6062\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7216\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6883\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 108ms/step - loss: 6.6139\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 107ms/step - loss: 6.6890\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7117\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7930\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6857\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6890\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.7027\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7606\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6103\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6132\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.5895\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6263\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7024\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6630\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6408\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7358\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.6616\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6234\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5623\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6265\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.8376\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5786\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6158\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6990\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6849\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6207\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6722\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5851\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5199\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6031\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5560\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 105ms/step - loss: 6.6442\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 105ms/step - loss: 6.6493\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5318\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5333\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6317\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 110ms/step - loss: 6.7284\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 108ms/step - loss: 6.6278\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.4564\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6990\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5468\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7250\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5670\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5872\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6475\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6623\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6714\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5149\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6391\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5998\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.6408\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6111\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5525\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4792\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6051\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6032\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5673\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5951\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5877\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4973\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5317\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5757\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5202\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.5358\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5114\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6203\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5520\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5532\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7198\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6689\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5223\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5457\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5515\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5012\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6044\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5813\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5923\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5910\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5572\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5380\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4822\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6082\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5218\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5858\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5089\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5992\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5770\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5515\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 104ms/step - loss: 6.4816\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.5880\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5079\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4111\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5800\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3675\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4704\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4736\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5638\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5391\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4838\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6202\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5127\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5644\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5984\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5491\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5533\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6413\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4985\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4659\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5678\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5131\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4809\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7608\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5426\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.5016\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5564\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4603\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4057\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5811\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4839\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5468\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5380\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5364\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6019\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6471\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4840\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5368\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5865\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.6272\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5209\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5503\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5066\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4076\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5943\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5194\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5585\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4885\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4433\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5064\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.4820\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.4706\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5315\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5575\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4804\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4170\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3994\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3871\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5517\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4942\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4092\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4921\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4915\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5579\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5137\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4345\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7287\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6548\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.4949\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4769\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5853\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4683\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.5255\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5799\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4989\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4274\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.4485\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.4633\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4489\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4638\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.4170\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4346\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6218\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4472\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5629\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.3344\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.4999\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.3765\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4928\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5931\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5794\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3874\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4003\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4007\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.4009\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4074\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4236\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.4571\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3818\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.2934\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.4566\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 104ms/step - loss: 6.3817\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4842\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4010\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3966\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.4178\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4645\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4243\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4851\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4124\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3989\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3256\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3388\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3820\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3881\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4598\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3920\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4376\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4535\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5493\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4387\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.2622\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4671\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4757\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5014\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4580\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4886\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3515\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.3877\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4904\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3722\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4244\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3932\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4344\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4202\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.2978\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4890\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4332\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4108\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3380\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3654\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4107\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5025\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3567\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3901\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3953\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4321\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4686\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3609\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.4462\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4251\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4249\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4492\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4959\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.3754\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.3696\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.4234\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3287\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.4176\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4056\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4290\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3829\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3577\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 105ms/step - loss: 6.3352\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4630\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3785\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3175\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4101\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5201\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.3305\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3862\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3356\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3665\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3763\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.2806\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3233\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3119\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3633\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3784\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3056\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.3706\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.3361\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4452\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3370\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.3322\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.3266\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.2311\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.3495\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7631\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8166\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.8819\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.8107\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6977\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8297\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6676\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7475\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8024\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6634\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7904\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.6393\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.6337\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 108ms/step - loss: 6.7491\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 105ms/step - loss: 6.7102\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 107ms/step - loss: 6.7425\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 106ms/step - loss: 6.7252\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 111ms/step - loss: 6.7137\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 108ms/step - loss: 6.7853\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 110ms/step - loss: 6.7497\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.6208\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6762\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7353\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5466\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6075\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6528\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6604\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5812\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7555\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6479\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5960\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6969\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5867\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6404\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5927\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5965\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6826\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6394\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5989\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6782\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7184\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.6751\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.6893\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5911\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7539\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5715\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5401\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6325\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6408\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6545\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6818\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7190\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5404\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5998\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5809\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4983\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5381\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 7.3967\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.4959\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6060\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6939\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6670\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7207\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6368\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.8010\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5201\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6677\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.7761\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6566\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7328\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5451\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.7385\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6952\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6861\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6412\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7267\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5475\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6475\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6699\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6965\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7582\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6230\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6928\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5690\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6239\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6197\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6772\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6001\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6163\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5949\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6441\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6599\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.5287\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5986\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.9437\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5643\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6302\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6475\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6019\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6738\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6978\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6584\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 107ms/step - loss: 6.5654\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 114ms/step - loss: 6.6211\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.5794\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6990\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6016\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6308\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.5066\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.7080\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.6833\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5485\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5906\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5995\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6354\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6129\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5288\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.6708\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.6391\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5639\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5603\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5051\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5827\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.6328\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.6145\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5082\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5270\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5518\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3992\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5685\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4431\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5687\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5121\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4910\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.5457\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 104ms/step - loss: 6.4962\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.4985\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5226\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5502\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5049\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5644\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4666\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5156\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5250\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4126\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.5349\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.4558\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5436\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6524\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5684\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5060\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6431\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4972\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4769\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4410\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5454\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5165\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4532\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6018\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4065\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4387\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5257\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4090\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4490\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5148\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4900\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.4526\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.4541\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5053\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3697\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.5111\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4267\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6631\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5915\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4507\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3873\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5833\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5328\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5053\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4612\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.5113\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5366\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4742\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4629\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4246\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5988\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.4927\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4081\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4989\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4083\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.4699\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4731\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5162\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3965\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4516\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 106ms/step - loss: 6.5327\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3965\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.4269\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3861\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5487\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.4449\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4952\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4150\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4438\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4234\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 104ms/step - loss: 6.5555\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.4044\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.4369\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.2496\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4408\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5572\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5219\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5061\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.4245\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4174\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4919\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.5747\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4781\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4339\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3704\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 105ms/step - loss: 6.4564\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4711\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3686\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4630\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4356\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4075\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4607\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5234\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4216\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 109ms/step - loss: 6.4265\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.5087\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.3521\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3691\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4501\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5023\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4069\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4004\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4466\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4104\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5130\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.3341\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3505\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3930\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5317\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3773\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.3321\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3471\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3801\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3500\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4546\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 104ms/step - loss: 6.4253\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5130\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3850\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5822\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3747\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3734\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3706\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3492\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4146\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3520\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.2839\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4604\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.2885\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3829\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3250\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4729\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 104ms/step - loss: 6.3047\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 110ms/step - loss: 6.3575\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 104ms/step - loss: 6.3838\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 106ms/step - loss: 6.3471\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.3597\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3370\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.2999\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.2962\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.3007\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3517\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3065\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.3298\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3304\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.3989\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3792\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3007\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3001\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3606\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.2840\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.2675\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3220\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3017\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.2600\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.2997\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.2937\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.2636\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3180\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.2602\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3117\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.2876\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.2349\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.2854\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.2560\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.3001\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5895\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.8139\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7850\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6915\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7905\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6970\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7099\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.9035\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.8692\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6242\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7046\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.8630\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7638\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7508\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6455\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6230\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6171\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7113\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.6337\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.7298\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.7355\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6171\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6883\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7433\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 2s 103ms/step - loss: 6.7847\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.8149\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6020\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.7317\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5175\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6021\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.6417\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5846\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7230\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6437\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5707\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7322\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6758\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5241\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5756\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.7024\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5962\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5547\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5888\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6020\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7423\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6277\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6037\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6636\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7264\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.8046\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.6779\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5329\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6127\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5981\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6548\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6321\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.4696\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 110ms/step - loss: 6.5529\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 107ms/step - loss: 6.5348\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7497\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.7632\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5005\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6085\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5901\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6520\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5709\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5219\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.5914\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.6274\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6390\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6239\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5244\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.7157\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6154\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.6237\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5795\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.9389\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5329\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5988\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5745\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5589\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5229\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5897\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4487\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5949\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5134\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5539\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6092\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6085\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5194\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6855\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6213\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6401\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.7886\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5857\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7789\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6382\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5957\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5743\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.5811\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.8109\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6595\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5593\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6702\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6129\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5938\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6350\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6515\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5244\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5967\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6045\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6100\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.7315\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5727\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6468\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6368\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6897\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6103\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5785\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5839\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5796\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5649\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6359\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5331\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.6067\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5072\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5157\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6671\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5904\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6599\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6991\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5617\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5726\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6163\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5745\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5494\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5731\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5682\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5569\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5266\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.5522\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5636\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5531\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.5227\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4844\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4941\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4987\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4976\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6149\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4791\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5507\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5107\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5358\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5757\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4782\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4700\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4318\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5923\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5967\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5571\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4240\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4362\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5580\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4290\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3752\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4410\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.4590\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.4315\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4078\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3987\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.2726\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.5287\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.3962\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5271\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5938\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6168\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4505\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4841\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4034\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.3864\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 104ms/step - loss: 6.3807\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5438\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3827\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4915\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5468\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4115\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4680\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3844\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4608\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5207\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5882\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3623\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5190\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4935\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5172\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.3684\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4703\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4716\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4209\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3705\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3665\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3695\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3706\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3715\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.4954\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.3977\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4196\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3609\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3295\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3940\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4423\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4834\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4246\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4859\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3629\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.3461\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 105ms/step - loss: 6.3952\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 113ms/step - loss: 6.4366\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 116ms/step - loss: 6.4383\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 109ms/step - loss: 6.4129\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 107ms/step - loss: 6.6406\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 106ms/step - loss: 6.4903\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 105ms/step - loss: 6.4532\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 108ms/step - loss: 6.3596\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 107ms/step - loss: 6.4523\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3319\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 2s 99ms/step - loss: 6.3644\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3818\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.3846\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4347\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3777\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4943\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4582\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3646\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5810\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3439\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.3246\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3826\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.3417\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4901\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.4801\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3949\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4087\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4043\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.3755\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3543\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.4202\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3746\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.3809\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3811\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4634\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4644\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3982\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.4154\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5147\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4023\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4470\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4190\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4576\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4592\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4428\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5208\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3712\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5817\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3717\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.2527\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3884\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 104ms/step - loss: 6.4353\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4403\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3361\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.3469\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3808\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.2979\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3793\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3245\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3492\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.2747\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3203\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.3408\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.3770\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4153\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.2895\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.2665\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3768\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3272\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3477\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.2954\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3194\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 107ms/step - loss: 6.3562\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 104ms/step - loss: 6.2456\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 106ms/step - loss: 6.2570\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 105ms/step - loss: 6.3027\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 105ms/step - loss: 6.3102\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.1738\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.2711\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.2604\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.2909\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 110ms/step - loss: 6.2936\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 115ms/step - loss: 6.3848\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.2669\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.5826\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5625\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5622\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.5046\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5403\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5101\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5391\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5686\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5016\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6058\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5178\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6956\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5749\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5882\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6462\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5232\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5118\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5145\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4902\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5924\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6892\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5208\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5284\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5486\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5554\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6385\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5571\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.6849\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4891\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6746\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.7532\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.6811\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 3s 129ms/step - loss: 6.5888\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 3s 131ms/step - loss: 6.7349\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 118ms/step - loss: 6.6471\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 114ms/step - loss: 6.7537\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 109ms/step - loss: 6.5476\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 109ms/step - loss: 6.6588\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.7360\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.6364\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.6927\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.5893\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.6109\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.5664\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 3s 133ms/step - loss: 6.6165\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 104ms/step - loss: 6.6915\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 3s 122ms/step - loss: 6.5550\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.6758\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5171\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 119ms/step - loss: 6.6011\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.5533\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 105ms/step - loss: 6.5228\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.6940\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.6414\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5629\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 105ms/step - loss: 6.5518\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.6052\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.6776\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.6050\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.6048\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4591\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.5264\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5634\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.5148\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.6736\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.6876\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.6196\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.5788\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.5752\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.5158\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.5425\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.6318\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.6770\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.5541\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.6377\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.5578\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.6871\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.5791\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.4633\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 105ms/step - loss: 6.5986\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.6280\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 4s 198ms/step - loss: 6.6099\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 3s 138ms/step - loss: 6.5943\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 114ms/step - loss: 6.6821\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 3s 132ms/step - loss: 6.6225\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 112ms/step - loss: 6.7150\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 110ms/step - loss: 6.4266\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 109ms/step - loss: 6.5510\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 110ms/step - loss: 6.6838\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 109ms/step - loss: 6.4705\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 3s 149ms/step - loss: 6.5122\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 3s 143ms/step - loss: 6.5485\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 108ms/step - loss: 6.5840\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 107ms/step - loss: 6.4972\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 107ms/step - loss: 6.6075\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 106ms/step - loss: 6.5296\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 107ms/step - loss: 6.6489\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 3s 125ms/step - loss: 6.5521\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 4s 172ms/step - loss: 6.5558\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 3s 129ms/step - loss: 6.5150\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 3s 126ms/step - loss: 6.6098\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 3s 156ms/step - loss: 6.7012\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 3s 149ms/step - loss: 6.5585\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 3s 119ms/step - loss: 6.5146\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 118ms/step - loss: 6.5688\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 117ms/step - loss: 6.5759\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 110ms/step - loss: 6.4755\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 109ms/step - loss: 6.5262\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 109ms/step - loss: 6.5426\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 108ms/step - loss: 6.4452\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 108ms/step - loss: 6.4792\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 109ms/step - loss: 6.5477\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 111ms/step - loss: 6.4581\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 110ms/step - loss: 6.5345\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 110ms/step - loss: 6.4687\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 111ms/step - loss: 6.5512\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 3s 124ms/step - loss: 6.4519\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 114ms/step - loss: 6.5208\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 117ms/step - loss: 6.5427\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 110ms/step - loss: 6.4341\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4963\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4371\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.3136\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6358\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.6088\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.4494\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.4076\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 2s 103ms/step - loss: 6.5328\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 94ms/step - loss: 6.4151\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.5300\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 94ms/step - loss: 6.4497\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.4424\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.4149\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.4610\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.3533\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.4430\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.5303\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.4751\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 94ms/step - loss: 6.4000\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.3518\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4705\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4565\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 106ms/step - loss: 6.4782\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 109ms/step - loss: 6.3395\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 117ms/step - loss: 6.4337\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 104ms/step - loss: 6.4098\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 108ms/step - loss: 6.4292\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.6278\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 113ms/step - loss: 6.4416\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.3408\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.5679\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 116ms/step - loss: 6.5068\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 3s 133ms/step - loss: 6.5097\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 108ms/step - loss: 6.5105\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 3s 137ms/step - loss: 6.3803\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 3s 122ms/step - loss: 6.4884\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 3s 141ms/step - loss: 6.5736\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 3s 144ms/step - loss: 6.5634\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 111ms/step - loss: 6.4280\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 3s 150ms/step - loss: 6.3497\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 3s 133ms/step - loss: 6.4907\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 107ms/step - loss: 6.4524\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 105ms/step - loss: 6.5431\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.5636\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.5214\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.4326\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.3331\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 110ms/step - loss: 6.5004\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 3s 143ms/step - loss: 6.4990\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 3s 134ms/step - loss: 6.4360\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4293\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.4531\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.4747\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4712\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 3s 130ms/step - loss: 6.4787\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 3s 122ms/step - loss: 6.5795\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4548\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 3s 122ms/step - loss: 6.4607\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 119ms/step - loss: 6.5369\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 3s 142ms/step - loss: 6.3650\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 105ms/step - loss: 6.4034\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 115ms/step - loss: 6.4861\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 106ms/step - loss: 6.5586\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 3s 149ms/step - loss: 6.4407\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 3s 149ms/step - loss: 6.5947\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 3s 138ms/step - loss: 6.4448\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 105ms/step - loss: 6.4755\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 3s 164ms/step - loss: 6.4305\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 3s 145ms/step - loss: 6.5169\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 117ms/step - loss: 6.4590\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 110ms/step - loss: 6.4244\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 109ms/step - loss: 6.3995\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 119ms/step - loss: 6.4944\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 114ms/step - loss: 6.4524\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 3s 120ms/step - loss: 6.4220\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 3s 160ms/step - loss: 6.4905\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 115ms/step - loss: 6.4487\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 119ms/step - loss: 6.5119\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 3s 133ms/step - loss: 6.4789\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 115ms/step - loss: 6.5376\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 3s 124ms/step - loss: 6.4645\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 3s 131ms/step - loss: 6.4056\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 3s 127ms/step - loss: 6.5554\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 110ms/step - loss: 6.4447\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 110ms/step - loss: 6.4780\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 3s 134ms/step - loss: 6.4885\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 3s 140ms/step - loss: 6.5167\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.4692\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 3s 122ms/step - loss: 6.4205\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 3s 134ms/step - loss: 6.3856\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.4584\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 104ms/step - loss: 6.3757\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 3s 144ms/step - loss: 6.4316\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 109ms/step - loss: 6.4547\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 108ms/step - loss: 6.5425\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.3562\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 107ms/step - loss: 6.4417\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3451\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.3698\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 119ms/step - loss: 6.4062\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 113ms/step - loss: 6.3532\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 118ms/step - loss: 6.3028\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 113ms/step - loss: 6.3667\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 3s 125ms/step - loss: 6.2838\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 116ms/step - loss: 6.3830\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 105ms/step - loss: 6.4917\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 114ms/step - loss: 6.3253\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.2787\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.4751\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 104ms/step - loss: 6.3976\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 3s 121ms/step - loss: 6.3302\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 93ms/step - loss: 6.4303\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.3871\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 3s 168ms/step - loss: 6.3403\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 106ms/step - loss: 6.4495\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 3s 127ms/step - loss: 6.4425\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.3455\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.3521\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 3s 133ms/step - loss: 6.3982\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.2905\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 3s 164ms/step - loss: 6.4870\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.5240\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 104ms/step - loss: 6.5112\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 104ms/step - loss: 6.4399\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 107ms/step - loss: 6.4730\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 100ms/step - loss: 6.3970\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 4s 212ms/step - loss: 6.4265\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 3s 119ms/step - loss: 6.4892\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 103ms/step - loss: 6.4323\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.4935\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.3243\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4811\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 108ms/step - loss: 6.4925\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 116ms/step - loss: 6.4388\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4351\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.3867\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 105ms/step - loss: 6.4082\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 116ms/step - loss: 6.2794\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 105ms/step - loss: 6.4412\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.4880\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.4485\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 99ms/step - loss: 6.3646\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3820\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 112ms/step - loss: 6.3975\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 3s 135ms/step - loss: 6.4636\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 108ms/step - loss: 6.4228\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 104ms/step - loss: 6.4432\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 94ms/step - loss: 6.3244\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.3525\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 97ms/step - loss: 6.4739\n",
      "Epoch 1/30\n",
      "21/21 [==============================] - 2s 91ms/step - loss: 6.2424\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.3338\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 2s 94ms/step - loss: 6.3345\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 2s 102ms/step - loss: 6.2638\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 2s 101ms/step - loss: 6.3944\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 2s 94ms/step - loss: 6.2746\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.4202\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 2s 94ms/step - loss: 6.2744\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 2s 98ms/step - loss: 6.3444\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.2759\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 2s 94ms/step - loss: 6.2400\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 2s 94ms/step - loss: 6.2739\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 2s 94ms/step - loss: 6.3218\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 2s 94ms/step - loss: 6.2857\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.3719\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 2s 95ms/step - loss: 6.1759\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 2s 94ms/step - loss: 6.2997\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 2s 94ms/step - loss: 6.3346\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 2s 94ms/step - loss: 6.2724\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 2s 94ms/step - loss: 6.2453\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 2s 94ms/step - loss: 6.3071\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 2s 94ms/step - loss: 6.2749\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 2s 94ms/step - loss: 6.2493\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 2s 96ms/step - loss: 6.2226\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 2s 94ms/step - loss: 6.2814\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 2s 94ms/step - loss: 6.2684\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 2s 93ms/step - loss: 6.2747\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 2s 93ms/step - loss: 6.2388\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 2s 94ms/step - loss: 6.1893\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 2s 93ms/step - loss: 6.2088\n"
     ]
    }
   ],
   "source": [
    "downscaler = Downscaler(meta_learner, components, test_m_data)\n",
    "optimizer = tf.keras.optimizers.Adam(0.0000001)\n",
    "downscaled_data = downscaler.downscale(30, optimizer, n_sample=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x15627e46608>]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def point_evaluate(pred_data, true_data):\n",
    "    if pred_data.shape != true_data.shape:\n",
    "        print('Please check data consistency!')\n",
    "        raise ValueError\n",
    "    RMSE_out = np.zeros(pred_data.shape[1:])\n",
    "    #R2_out = np.zeros(pred_data.shape[1:])\n",
    "    for i in range(pred_data.shape[1]):\n",
    "        for j in range(pred_data.shape[2]):\n",
    "            if np.isnan(true_data[0, i, j]):\n",
    "                RMSE_out[i, j] = float(\"nan\")\n",
    "                #R2_out[i, j] = float(\"nan\")\n",
    "            else:\n",
    "                RMSE_out[i ,j] = np.square(pred_data[: ,i ,j] - true_data[: ,i ,j]).mean()\n",
    "                #R2_out[i ,j], _ = nc_process.rsquared(pred_data[: ,i ,j], true_data[: ,i ,j])\n",
    "    return RMSE_out\n",
    "\n",
    "\n",
    "def image_evaluate(pred_data, true_data):\n",
    "    if pred_data.shape != true_data.shape:\n",
    "        print('Please check data consistency!')\n",
    "        raise ValueError\n",
    "    length = np.prod(pred_data.shape[1:])\n",
    "    r2_list = np.zeros(pred_data.shape[0])\n",
    "    rmse_list = np.zeros(pred_data.shape[0])\n",
    "    filter = ~np.isnan(pred_data[0].reshape(length))\n",
    "    for i in range(pred_data.shape[0]):\n",
    "        r2_list[i],_ = nc_process.rsquared(pred_data[i].reshape(length)[filter], true_data[i].reshape(length)[filter])\n",
    "        rmse_list[i] = np.nanmean(np.square(pred_data[i] - true_data[i]))\n",
    "    return rmse_list, r2_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.45737791, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 4.86772442, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 4.90784502, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 4.9520936 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 4.96188164,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       4.77881289, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 5.15625381, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        ])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downscaled_data[:, 14, 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.9375,\n",
       " 11.125,\n",
       " 11.3125,\n",
       " 11.5,\n",
       " 11.6875,\n",
       " 11.875,\n",
       " 12.0625,\n",
       " 12.25,\n",
       " 12.4375,\n",
       " 12.625]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[meta_learner.task_extractor.h_lats[int(i*meta_learner.task_extractor.task_dim[0])] for i in range(int(len(meta_learner.task_extractor.h_lats)//meta_learner.task_extractor.task_dim[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 3)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init[0][0, -3:, 0, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Downscale_env",
   "language": "python",
   "name": "downscale_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
