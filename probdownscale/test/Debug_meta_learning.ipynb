{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import os\n",
    "import sys\n",
    "from importlib import reload\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import probdownscale\n",
    "reload(probdownscale.TaskExtractor)\n",
    "reload(probdownscale.MetaTrain)\n",
    "from probdownscale.MetaTrain import MetaSGD\n",
    "\n",
    "from probdownscale.TaskExtractor import TaskExtractor\n",
    "import math\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow_probability import distributions as tfd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Debug TaskExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\96349\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\96349\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \n",
      "C:\\Users\\96349\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\96349\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "C:\\Users\\96349\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\ipykernel_launcher.py:21: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "C:\\Users\\96349\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\ipykernel_launcher.py:22: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    }
   ],
   "source": [
    "file_path_g_05 = r'C:\\Users\\96349\\Documents\\Downscale_data\\MERRA2\\G5NR_aerosol_variables_over_MiddleEast_daily_20050516-20060515.nc'\n",
    "file_path_g_06 =  r'C:\\Users\\96349\\Documents\\Downscale_data\\MERRA2\\G5NR_aerosol_variables_over_MiddleEast_daily_20060516-20070515.nc'\n",
    "file_path_m = r'C:\\Users\\96349\\Documents\\Downscale_data\\MERRA2\\MERRA2_aerosol_variables_over_MiddleEast_daily_20000516-20180515.nc'\n",
    "target_var = 'BCSMASS'\n",
    "\n",
    "# read data\n",
    "g05_data = nc.Dataset(file_path_g_05)\n",
    "g06_data = nc.Dataset(file_path_g_06)\n",
    "m_data_nc = nc.Dataset(file_path_m)\n",
    "\n",
    "# define lat&lon of MERRA, G5NR and mete\n",
    "M_lons = m_data_nc.variables['lon'][:15]\n",
    "# self.M_lons = (M_lons-M_lons.mean())/M_lons.std()\n",
    "M_lats = m_data_nc.variables['lat'][:15]\n",
    "# self.M_lats = (M_lats-M_lats.mean())/M_lats.std()\n",
    "G_lons = g05_data.variables['lon'][:30]\n",
    "# self.G_lons = (G_lons-G_lons.mean())/G_lons.std()\n",
    "G_lats = g05_data.variables['lat'][:30]\n",
    "\n",
    "# extract target data\n",
    "g_data = np.concatenate((g05_data.variables[target_var][:, :30, :30], g06_data.variables[target_var][:, :30, :30]), axis=0)\n",
    "m_data = m_data_nc.variables[target_var][5*365:7*365, :15, :15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [g_data, m_data]\n",
    "lats_lons = [G_lats, G_lons, M_lats, M_lons]\n",
    "task_dim = 3\n",
    "test_proportion = 0.3\n",
    "n_lag = 10\n",
    "taskextractor = TaskExtractor(data, lats_lons, task_dim, test_proportion, n_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y, location = taskextractor._get_random_task()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = taskextractor.get_grid_locations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y, locations = taskextractor.get_random_tasks(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y, locations = taskextractor.get_random_tasks(locations=locations[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 1, 4, 2]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import sample\n",
    "sample([1,2,3,4], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10//3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow_probability import distributions as tfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the last channel is the comonents\n",
    "alpha = np.random.rand(3,2,5)\n",
    "alpha = alpha/alpha.sum()\n",
    "mu = np.random.rand(3, 2, 5)\n",
    "mu = np.abs(mu)\n",
    "test_md = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=alpha),\n",
    "        components_distribution=tfd.Gamma(concentration=mu, rate=mu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float64, numpy=\n",
       "array([[nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan]])>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_like = test_md.log_prob(np.ones((3,2))*-0.001)\n",
    "#-tf.reduce_mean(log_like, axis=-1)\n",
    "log_like\n",
    "\n",
    "# when the Y is really small, log_prob return a positive log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float64, numpy=\n",
       "array([[0.15880819, 0.10569395],\n",
       "       [0.17997603, 0.15908541],\n",
       "       [0.20016422, 0.19627221]])>"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_md.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float64, numpy=\n",
       "array([[-1.07151844, -1.96976935],\n",
       "       [-0.88054633, -1.06112697],\n",
       "       [-1.63395563, -0.41498473]])>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =  np.random.rand(3,3,3)\n",
    "#a = (a - a.min())/(a.max() - a.min())\n",
    "a = a/a.sum()\n",
    "a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define necessary tool functions\n",
    "components = 100\n",
    "no_parameters = 2\n",
    "\n",
    "def nnelu(input):\n",
    "    return tf.add(tf.constant(1, dtype=tf.float32), tf.nn.elu(input))\n",
    "\n",
    "def slice_parameter_vectors(parameter_vector, no_parameters):\n",
    "    return [parameter_vector[:, i * task_dim*task_dim*components:(i + 1) *task_dim*task_dim*components] for i in range(no_parameters)]\n",
    "\n",
    "def gamma_loss(y, parameter_vector):\n",
    "    alpha, mu, sigma = slice_parameter_vectors(parameter_vector, 3)  # Unpack parameter vectors\n",
    "    #print(alpha.shape, mu.shape)\n",
    "    alpha1 = tf.reshape(alpha, (tf.shape(alpha)[0], task_dim, task_dim, components))\n",
    "    mu1 = tf.reshape(mu, (tf.shape(mu)[0], task_dim, task_dim, components))\n",
    "    sigma1 = tf.reshape(sigma,  (tf.shape(sigma)[0], task_dim, task_dim, components))\n",
    "    #print(alpha1.shape, mu1.shape)\n",
    "    gm = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=alpha1),\n",
    "        components_distribution=tfd.Gamma(\n",
    "        concentration=mu1, rate=sigma1)\n",
    "    )\n",
    "\n",
    "    log_likelihood = gm.log_prob(y)  # Evaluate log-probability of y\n",
    "    #print(log_likelihood)\n",
    "    return -tf.reduce_mean(log_likelihood, axis=-1)\n",
    "\n",
    "def exponential_loss(y, parameter_vector):\n",
    "    alpha, mu = slice_parameter_vectors(parameter_vector, 2)  # Unpack parameter vectors\n",
    "    #print(alpha.shape, mu.shape)\n",
    "    alpha1 = tf.reshape(alpha, (tf.shape(alpha)[0], task_dim, task_dim, components))\n",
    "    mu1 = tf.reshape(mu, (tf.shape(mu)[0], task_dim, task_dim, components))\n",
    "    #print(alpha1.shape, mu1.shape)\n",
    "    gm = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=alpha1),\n",
    "        components_distribution=tfd.Exponential(\n",
    "        rate=mu1)\n",
    "    )\n",
    "\n",
    "    log_likelihood = gm.log_prob(y)  # Evaluate log-probability of y\n",
    "    #print(log_likelihood)\n",
    "    return -tf.reduce_mean(log_likelihood, axis=-1)\n",
    "\n",
    "def gamma_mean_loss(y, parameter_vector):\n",
    "    alpha, mu, sigma = slice_parameter_vectors(parameter_vector, 3)  # Unpack parameter vectors\n",
    "    #print(alpha.shape, mu.shape)\n",
    "    alpha1 = tf.reshape(alpha, (tf.shape(alpha)[0], task_dim, task_dim, components))\n",
    "    mu1 = tf.reshape(mu, (tf.shape(mu)[0], task_dim, task_dim, components))\n",
    "    sigma1 = tf.reshape(sigma,  (tf.shape(sigma)[0], task_dim, task_dim, components))\n",
    "    #print(alpha1.shape, mu1.shape)\n",
    "    gm = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=alpha1),\n",
    "        components_distribution=tfd.Gamma(\n",
    "        concentration=mu1, rate=sigma1)\n",
    "    )\n",
    "    mae = tf.keras.losses.MeanAbsoluteError()\n",
    "    return mae(gm.mean(), y) \n",
    "\n",
    "\n",
    "tf.keras.utils.get_custom_objects().update({'nnelu': layers.Activation(nnelu)})\n",
    "\n",
    "def plot_history(history, title):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(title)\n",
    "    \n",
    "def model_generator(n_para=2):\n",
    "    # define MDN Exponentialmodel\n",
    "    # input dim (time, channel, rows, cols)\n",
    "    input1 = layers.Input(shape=(n_lag, 1, task_dim, task_dim)) \n",
    "    input1 = layers.BatchNormalization()(input1)\n",
    "    input2 = layers.Input(shape=(task_dim, task_dim, 1))\n",
    "    input2 = layers.BatchNormalization()(input2)\n",
    "    input3 = layers.Input(shape=(1))\n",
    "    input3 = layers.BatchNormalization()(input3)\n",
    "\n",
    "    X = layers.ConvLSTM2D(filters=20, kernel_size=(1,2), activation='tanh', return_sequences=True)(input1)\n",
    "    X = layers.ConvLSTM2D(filters=20, kernel_size=(1,2), activation='relu', return_sequences=True)(X)\n",
    "    X = layers.ConvLSTM2D(filters=20, kernel_size=(1,1), activation='relu')(X)\n",
    "    X = layers.Flatten()(X)\n",
    "    X = layers.Dense(512, activation='relu')(X)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    X = layers.Dense(300, activation='relu')(X)\n",
    "\n",
    "    X1 = layers.Conv2D(20, (2,2), activation='tanh')(input2)\n",
    "    X1 = layers.Flatten()(X1)\n",
    "    X2 = layers.BatchNormalization()(input3)\n",
    "    X2 = layers.Dense(30, activation='relu')(X2)\n",
    "\n",
    "    X = layers.Concatenate()([X, X1, X2])\n",
    "    X = layers.Dense(128, activation='relu')(X)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    X = layers.Dense(128, activation='relu')(X)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    X = layers.Dense(128, activation='relu')(X)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    if n_para ==2:\n",
    "        alphas = layers.Dense(components*task_dim*task_dim, activation=\"softmax\")(X)\n",
    "        #alphas = layers.Reshape((task_dim, task_dim, components), name=\"alphas\")(alphas)\n",
    "        mus = layers.Dense(components*task_dim*task_dim, activation='nnelu')(X)\n",
    "        #mus = layers.Reshape((task_dim, task_dim, components) ,name=\"mus\")(mus)\n",
    "        output = layers.Concatenate()([alphas, mus])\n",
    "        model = Model([input1, input2, input3], output)\n",
    "    else:\n",
    "        alphas = layers.Dense(components*task_dim*task_dim, activation=\"softmax\")(X)\n",
    "        #alphas = layers.Reshape((task_dim, task_dim, components), name=\"alphas\")(alphas)\n",
    "        mus = layers.Dense(components*task_dim*task_dim, activation='nnelu')(X)\n",
    "        #mus = layers.Reshape((task_dim, task_dim, components) ,name=\"mus\")(mus)\n",
    "        sigmas = layers.Dense(components*task_dim*task_dim, activation='nnelu')(X)\n",
    "        output = layers.Concatenate()([alphas, mus, sigmas])\n",
    "        model = Model([input1, input2, input3], output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "16/16 [==============================] - 11s 81ms/step - loss: 63.6274 - val_loss: 180.0322\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 53.1406 - val_loss: 177.8877\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 46.0620 - val_loss: 169.7674\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 39.4769 - val_loss: 160.2716\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 34.9523 - val_loss: 151.1875\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 30.2382 - val_loss: 142.3384\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 27.2024 - val_loss: 134.6487\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 23.7246 - val_loss: 127.2671\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 21.3722 - val_loss: 120.6002\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 19.2162 - val_loss: 114.7047\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 17.3013 - val_loss: 108.2620\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 16.1567 - val_loss: 103.0195\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 14.3149 - val_loss: 98.0942\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 13.3553 - val_loss: 93.9857\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 12.4746 - val_loss: 88.4963\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 11.3025 - val_loss: 83.3771\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 10.8080 - val_loss: 79.5837\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 10.1491 - val_loss: 75.5517\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 9.7220 - val_loss: 70.4741\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 9.1967 - val_loss: 65.1685\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 8.5862 - val_loss: 61.5112\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 8.3966 - val_loss: 56.7313\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 8.2442 - val_loss: 51.4130\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 7.9034 - val_loss: 47.2480\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 7.6604 - val_loss: 39.9342\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 7.5802 - val_loss: 35.0066\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 7.4077 - val_loss: 30.9455\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 7.1777 - val_loss: 29.5128\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 7.0681 - val_loss: 25.7485\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 7.0100 - val_loss: 22.4617\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 7.0185 - val_loss: 21.6588\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.8944 - val_loss: 18.5676\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.7906 - val_loss: 17.6841\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.6776 - val_loss: 16.1030\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.5826 - val_loss: 13.8371\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.8951 - val_loss: 14.0558\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.6504 - val_loss: 13.7178\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.6240 - val_loss: 11.9969\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.4451 - val_loss: 10.6729\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.3634 - val_loss: 10.0085\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.6359 - val_loss: 9.2518\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.4191 - val_loss: 10.5888\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.3876 - val_loss: 8.7122\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.5029 - val_loss: 7.6102\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.3226 - val_loss: 7.7581\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 6.3069 - val_loss: 8.2971\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.3227 - val_loss: 7.4179\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.3197 - val_loss: 7.4460\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 6.2515 - val_loss: 7.9300\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.2799 - val_loss: 7.7476\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.2809 - val_loss: 8.2633\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.2849 - val_loss: 9.2250\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 6.3573 - val_loss: 8.8843\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 6.1629 - val_loss: 8.5135\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.1821 - val_loss: 7.8533\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 6.1950 - val_loss: 6.8539\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 6.1493 - val_loss: 6.7851\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 6.1200 - val_loss: 8.0015\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 6.1834 - val_loss: 8.3243\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.0945 - val_loss: 7.6476\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 6.1101 - val_loss: 7.9676\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.1198 - val_loss: 7.8631\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 6.0860 - val_loss: 7.4177\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 6.0436 - val_loss: 6.8158\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.0188 - val_loss: 6.8564\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 6.1828 - val_loss: 6.7424\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.0934 - val_loss: 7.2085\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.0657 - val_loss: 7.6859\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.0193 - val_loss: 8.6973\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 6.1641 - val_loss: 7.4777\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 6.0192 - val_loss: 7.4784\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.0655 - val_loss: 8.6142\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 5.9809 - val_loss: 8.3894\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 5.9853 - val_loss: 7.7592\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 5.9811 - val_loss: 7.6568\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 6.1481 - val_loss: 6.8906\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.0033 - val_loss: 7.6178\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.0139 - val_loss: 9.0226\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.0389 - val_loss: 9.8512\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.9761 - val_loss: 9.4871\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 38ms/step - loss: 5.9477 - val_loss: 9.8291\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.9836 - val_loss: 9.1511\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 5.9647 - val_loss: 8.6237\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.9122 - val_loss: 7.8641\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.0365 - val_loss: 8.7960\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.9587 - val_loss: 8.2464\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.0859 - val_loss: 10.2512\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.9441 - val_loss: 10.5882\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.0136 - val_loss: 11.6988\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 5.8771 - val_loss: 11.8996\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.9144 - val_loss: 11.2712\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 5.9340 - val_loss: 11.6704\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.8855 - val_loss: 10.3692\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 5.9157 - val_loss: 8.9089\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.9763 - val_loss: 8.1468\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.9848 - val_loss: 8.5089\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.9089 - val_loss: 8.3958\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.9221 - val_loss: 8.1030\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 5.8661 - val_loss: 8.4739\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.8750 - val_loss: 9.1268\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 5.8878 - val_loss: 10.0180\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.8592 - val_loss: 9.0338\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 5.8952 - val_loss: 8.4178\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.8755 - val_loss: 10.2414\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.9194 - val_loss: 9.7914\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.8921 - val_loss: 9.0418\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 5.9009 - val_loss: 9.0297\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.8758 - val_loss: 8.6418\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 5.9236 - val_loss: 9.9924\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 5.8559 - val_loss: 10.3295\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 5.8329 - val_loss: 8.0674\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 5.8885 - val_loss: 9.2419\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 5.8936 - val_loss: 8.3580\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 5.7953 - val_loss: 9.1100\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 5.8244 - val_loss: 7.7902\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 5.8800 - val_loss: 7.2942\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 5.8219 - val_loss: 7.6837\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 5.8014 - val_loss: 10.2219\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.8520 - val_loss: 9.0195\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.7812 - val_loss: 8.1149\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.8622 - val_loss: 7.5123\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.7900 - val_loss: 7.6782\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.8150 - val_loss: 7.7742\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.7882 - val_loss: 7.9278\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 5.8113 - val_loss: 7.9501\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.7748 - val_loss: 8.3127\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.8046 - val_loss: 9.3460\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 5.8061 - val_loss: 10.3572\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 5.8243 - val_loss: 8.6602\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 5.7809 - val_loss: 9.7519\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 5.8236 - val_loss: 9.8200\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 5.8494 - val_loss: 10.3021\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 5.7299 - val_loss: 11.6226\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 5.7749 - val_loss: 10.8382\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 5.8435 - val_loss: 10.0432\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 5.8573 - val_loss: 10.2327\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 5.8253 - val_loss: 10.4389\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 5.7487 - val_loss: 7.8913\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 5.8418 - val_loss: 8.1324\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 5.7722 - val_loss: 7.8989\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 5.7747 - val_loss: 8.7832\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 5.7133 - val_loss: 9.2839\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 5.7342 - val_loss: 12.1620\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 5.7946 - val_loss: 11.8032\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 5.8435 - val_loss: 11.2929\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 5.8109 - val_loss: 10.3346\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 5.8018 - val_loss: 9.0751\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 5.7627 - val_loss: 9.0714\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 5.7207 - val_loss: 8.9505\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 5.7646 - val_loss: 10.2945\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 5.7542 - val_loss: 13.8526\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 5.7007 - val_loss: 15.5730\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 5.7453 - val_loss: 14.2538\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 5.6924 - val_loss: 12.6902\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 5.7638 - val_loss: 10.4304\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 5.7656 - val_loss: 9.5448\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 5.7449 - val_loss: 9.3258\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 5.7925 - val_loss: 8.3894\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 5.7159 - val_loss: 8.9385\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 5.7390 - val_loss: 10.1181\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 35ms/step - loss: 5.7126 - val_loss: 9.7208\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.7358 - val_loss: 10.0010\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 5.7024 - val_loss: 9.2736\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 5.6855 - val_loss: 8.8124\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 5.7003 - val_loss: 9.3322\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.6734 - val_loss: 9.8821\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 5.6842 - val_loss: 9.0222\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 5.6814 - val_loss: 9.7263\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.6761 - val_loss: 9.0082\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.6666 - val_loss: 8.6532\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.7185 - val_loss: 7.8078\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.6749 - val_loss: 8.6766\n",
      "Epoch 173/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 5.7457 - val_loss: 8.8883\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.7840 - val_loss: 7.9100\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 5.7266 - val_loss: 8.0735\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.6906 - val_loss: 8.7113\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.7412 - val_loss: 8.5337\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.7445 - val_loss: 9.4634\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.6602 - val_loss: 9.5201\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.6797 - val_loss: 9.1650\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.6990 - val_loss: 8.8752\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 5.7065 - val_loss: 8.3580\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.6752 - val_loss: 7.7853\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 5.6492 - val_loss: 7.6376\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 5.6693 - val_loss: 8.0627\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 5.7258 - val_loss: 8.7452\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 5.6501 - val_loss: 9.3144\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 5.6530 - val_loss: 9.9129\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 5.6478 - val_loss: 9.5388\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 5.7353 - val_loss: 8.6469\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 5.6864 - val_loss: 8.5088\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 5.6290 - val_loss: 8.5420\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 5.6107 - val_loss: 8.1722\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 5.6067 - val_loss: 8.2381\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 5.6641 - val_loss: 7.6805\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 1s 44ms/step - loss: 5.6174 - val_loss: 7.8528\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 5.6630 - val_loss: 9.0397\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 5.6039 - val_loss: 9.9361\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 5.6544 - val_loss: 10.2872\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 5.6602 - val_loss: 9.0026\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define gamma model\n",
    "MDN_model_ref_gamma = model_generator(n_para=3)\n",
    "MDN_model_ref_gamma.compile(optimizer=tf.keras.optimizers.Adam(0.0001), loss=gamma_loss)\n",
    "#MDN_model_ref_gamma.summary()\n",
    "history_gamma = MDN_model_ref_gamma.fit(train_x, train_y, epochs=200, validation_data=[test_x, test_y])\n",
    "plot_history(history_gamma, 'Regular Training, Gamma MDN, Likelihood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "16/16 [==============================] - 11s 81ms/step - loss: 199.0508 - val_loss: 204.0836\n",
      "Epoch 2/80\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 199.0134 - val_loss: 204.0834\n",
      "Epoch 3/80\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 198.8674 - val_loss: 204.0824\n",
      "Epoch 4/80\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 198.8008 - val_loss: 204.0806\n",
      "Epoch 5/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 198.7091 - val_loss: 204.0780\n",
      "Epoch 6/80\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 198.3481 - val_loss: 204.0742\n",
      "Epoch 7/80\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 197.6625 - val_loss: 204.0688\n",
      "Epoch 8/80\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 196.7148 - val_loss: 204.0617\n",
      "Epoch 9/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 194.7108 - val_loss: 204.0524\n",
      "Epoch 10/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 193.2623 - val_loss: 204.0403\n",
      "Epoch 11/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 189.3877 - val_loss: 204.0230\n",
      "Epoch 12/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 187.3024 - val_loss: 204.0000\n",
      "Epoch 13/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 180.2406 - val_loss: 203.9681\n",
      "Epoch 14/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 173.3111 - val_loss: 203.9115\n",
      "Epoch 15/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 165.0778 - val_loss: 203.8067\n",
      "Epoch 16/80\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 151.0415 - val_loss: 203.7129\n",
      "Epoch 17/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 136.0800 - val_loss: 203.4527\n",
      "Epoch 18/80\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 124.8568 - val_loss: 203.2299\n",
      "Epoch 19/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 118.0519 - val_loss: 202.6435\n",
      "Epoch 20/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 116.7302 - val_loss: 202.3383\n",
      "Epoch 21/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 110.7194 - val_loss: 201.2722\n",
      "Epoch 22/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 106.0071 - val_loss: 200.0372\n",
      "Epoch 23/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 104.6385 - val_loss: 197.9877\n",
      "Epoch 24/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 108.2146 - val_loss: 197.6676\n",
      "Epoch 25/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 99.7894 - val_loss: 193.7443\n",
      "Epoch 26/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 91.3851 - val_loss: 190.4097\n",
      "Epoch 27/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 91.2706 - val_loss: 184.8065\n",
      "Epoch 28/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 91.3480 - val_loss: 184.5976\n",
      "Epoch 29/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 85.5882 - val_loss: 179.1317\n",
      "Epoch 30/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 94.2629 - val_loss: 181.8022\n",
      "Epoch 31/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 82.1387 - val_loss: 181.6522\n",
      "Epoch 32/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 83.8327 - val_loss: 180.6383\n",
      "Epoch 33/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 83.9834 - val_loss: 175.6572\n",
      "Epoch 34/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 84.4004 - val_loss: 177.6387\n",
      "Epoch 35/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 79.9775 - val_loss: 174.9171\n",
      "Epoch 36/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 79.0573 - val_loss: 175.4850\n",
      "Epoch 37/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 79.8089 - val_loss: 170.8452\n",
      "Epoch 38/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 82.9563 - val_loss: 172.6571\n",
      "Epoch 39/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 73.8726 - val_loss: 182.2621\n",
      "Epoch 40/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 76.9779 - val_loss: 185.1517\n",
      "Epoch 41/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 71.4150 - val_loss: 187.8950\n",
      "Epoch 42/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 78.0032 - val_loss: 191.2340\n",
      "Epoch 43/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 74.4184 - val_loss: 187.3640\n",
      "Epoch 44/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 71.5035 - val_loss: 183.0294\n",
      "Epoch 45/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 72.8803 - val_loss: 174.5212\n",
      "Epoch 46/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 75.6587 - val_loss: 183.4924\n",
      "Epoch 47/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 75.4433 - val_loss: 178.2094\n",
      "Epoch 48/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 74.8092 - val_loss: 170.6925\n",
      "Epoch 49/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 69.6511 - val_loss: 164.0108\n",
      "Epoch 50/80\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 70.8749 - val_loss: 171.5886\n",
      "Epoch 51/80\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 73.7552 - val_loss: 157.9875\n",
      "Epoch 52/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 74.7622 - val_loss: 150.5840\n",
      "Epoch 53/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 70.2043 - val_loss: 154.1671\n",
      "Epoch 54/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 71.3373 - val_loss: 152.0017\n",
      "Epoch 55/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 64.5776 - val_loss: 154.7435\n",
      "Epoch 56/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 71.8911 - val_loss: 165.6083\n",
      "Epoch 57/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 65.9628 - val_loss: 160.4375\n",
      "Epoch 58/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 65.5137 - val_loss: 144.2306\n",
      "Epoch 59/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 66.3581 - val_loss: 135.9258\n",
      "Epoch 60/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 66.1108 - val_loss: 154.1718\n",
      "Epoch 61/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 70.7209 - val_loss: 146.5769\n",
      "Epoch 62/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 65.2733 - val_loss: 125.1457\n",
      "Epoch 63/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 68.8953 - val_loss: 129.2919\n",
      "Epoch 64/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 67.9559 - val_loss: 115.3501\n",
      "Epoch 65/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 69.0139 - val_loss: 119.2241\n",
      "Epoch 66/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 64.8392 - val_loss: 120.8046\n",
      "Epoch 67/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 67.5861 - val_loss: 133.7345\n",
      "Epoch 68/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 69.0632 - val_loss: 123.7424\n",
      "Epoch 69/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 66.1617 - val_loss: 142.3206\n",
      "Epoch 70/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 64.2255 - val_loss: 147.5771\n",
      "Epoch 71/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 69.0975 - val_loss: 160.7994\n",
      "Epoch 72/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 62.6745 - val_loss: 137.9376\n",
      "Epoch 73/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 67.1258 - val_loss: 161.2673\n",
      "Epoch 74/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 64.7339 - val_loss: 151.5736\n",
      "Epoch 75/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 64.5173 - val_loss: 134.6384\n",
      "Epoch 76/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 61.0530 - val_loss: 149.2237\n",
      "Epoch 77/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 65.3801 - val_loss: 220.2211\n",
      "Epoch 78/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 63.5830 - val_loss: 155.5474\n",
      "Epoch 79/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 62.2006 - val_loss: 163.2845\n",
      "Epoch 80/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 27ms/step - loss: 63.1434 - val_loss: 146.8180\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define MDN Gamma Mean model\n",
    "MDN_model_ref_gamma_mean = model_generator(n_para=3)\n",
    "MDN_model_ref_gamma_mean.compile(optimizer=tf.keras.optimizers.Adam(0.0001), loss=gamma_mean_loss)\n",
    "history_gamma_mean = MDN_model_ref_gamma_mean.fit(train_x, train_y, epochs=80, validation_data=[test_x, test_y])\n",
    "plot_history(history_gamma_mean, 'Regular Training, Gamma MDN, Mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "16/16 [==============================] - 12s 100ms/step - loss: 62.5850 - val_loss: 165.7774\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 53.1651 - val_loss: 166.4678\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 45.8832 - val_loss: 160.6608\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 39.7374 - val_loss: 154.2601\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 34.3650 - val_loss: 147.1115\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 30.6276 - val_loss: 139.9658\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 27.1943 - val_loss: 133.1129\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 24.5809 - val_loss: 126.7268\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 21.9697 - val_loss: 121.3874\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 19.7469 - val_loss: 115.7959\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 18.5416 - val_loss: 109.7711\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 17.0823 - val_loss: 104.7965\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 15.7231 - val_loss: 99.9289\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 14.7437 - val_loss: 96.0820\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 13.9295 - val_loss: 91.5142\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 13.0078 - val_loss: 86.6114\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 12.5275 - val_loss: 81.4776\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 11.7764 - val_loss: 74.9445\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 11.3556 - val_loss: 68.8137\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 10.8481 - val_loss: 64.3833\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 10.3452 - val_loss: 59.0142\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 10.0550 - val_loss: 54.1462\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 9.7055 - val_loss: 49.0115\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 9.3824 - val_loss: 44.0658\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 9.0454 - val_loss: 41.1914\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 8.9486 - val_loss: 37.1306\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 8.6226 - val_loss: 33.3561\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 8.4663 - val_loss: 29.2278\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 8.2817 - val_loss: 25.7573\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 8.1138 - val_loss: 24.4140\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 8.0875 - val_loss: 23.7046\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 7.8408 - val_loss: 20.2186\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 7.8681 - val_loss: 18.8261\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 7.6309 - val_loss: 17.9323\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 7.5510 - val_loss: 17.5060\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 7.4715 - val_loss: 14.6634\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 7.4138 - val_loss: 13.4154\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 7.3431 - val_loss: 11.9695\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 7.2240 - val_loss: 11.1076\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 7.2418 - val_loss: 10.3974\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 7.1553 - val_loss: 10.1356\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 7.1064 - val_loss: 10.3202\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 7.0635 - val_loss: 10.2547\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 6.9760 - val_loss: 10.2323\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.9576 - val_loss: 9.1654\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.9279 - val_loss: 7.8602\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 6.8878 - val_loss: 7.5688\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.9174 - val_loss: 8.7219\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 6.8420 - val_loss: 8.7246\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.7761 - val_loss: 8.7443\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.7602 - val_loss: 8.5701\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.8073 - val_loss: 8.6944\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.7645 - val_loss: 9.0998\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.6848 - val_loss: 8.6405\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.8173 - val_loss: 8.5816\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.6549 - val_loss: 8.1975\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.6093 - val_loss: 7.3537\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 6.6750 - val_loss: 7.3043\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.6149 - val_loss: 7.1716\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 6.5870 - val_loss: 7.2602\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 6.5758 - val_loss: 7.7315\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 6.6193 - val_loss: 7.3886\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.5519 - val_loss: 7.4137\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 6.6087 - val_loss: 7.5898\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.5528 - val_loss: 7.7438\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.5279 - val_loss: 8.3654\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.5445 - val_loss: 8.4943\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.5252 - val_loss: 7.6869\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.5621 - val_loss: 7.9406\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.5241 - val_loss: 7.6641\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.4981 - val_loss: 7.8875\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.5174 - val_loss: 7.5881\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.5019 - val_loss: 7.8673\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 6.5165 - val_loss: 7.3889\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.4994 - val_loss: 9.3725\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.4807 - val_loss: 10.2038\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 6.4575 - val_loss: 9.9656\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.4750 - val_loss: 9.4409\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 6.4589 - val_loss: 9.1882\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.4841 - val_loss: 8.2936\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 35ms/step - loss: 6.4815 - val_loss: 7.4623\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.4426 - val_loss: 6.8944\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.4333 - val_loss: 6.7733\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 6.4956 - val_loss: 6.6814\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 6.4909 - val_loss: 6.8926\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.4886 - val_loss: 7.4573\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.4401 - val_loss: 7.2678\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 6.4318 - val_loss: 7.3283\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.4863 - val_loss: 7.0196\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.4686 - val_loss: 6.8070\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 6.4331 - val_loss: 6.9608\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 6.4645 - val_loss: 6.9273\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 6.4267 - val_loss: 7.0962\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.4321 - val_loss: 7.1785\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.4663 - val_loss: 6.9852\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.4529 - val_loss: 7.8083\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.5436 - val_loss: 7.7478\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.5070 - val_loss: 7.7521\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.4535 - val_loss: 7.3263\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 6.4588 - val_loss: 6.8920\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 6.4297 - val_loss: 6.7623\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 6.4287 - val_loss: 6.6668\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 6.4412 - val_loss: 6.8473\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 6.4587 - val_loss: 6.8195\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 6.3858 - val_loss: 6.7614\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.4023 - val_loss: 6.6953\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.4182 - val_loss: 6.6167\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.3976 - val_loss: 6.7051\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 6.4288 - val_loss: 6.8092\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.4418 - val_loss: 6.7904\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 6.3851 - val_loss: 6.8542\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.4108 - val_loss: 6.6774\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.4056 - val_loss: 6.8222\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.3812 - val_loss: 7.0165\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.3916 - val_loss: 7.5773\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.4004 - val_loss: 7.1586\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 6.3787 - val_loss: 7.2015\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.3607 - val_loss: 7.0325\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.3773 - val_loss: 7.0360\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.4041 - val_loss: 7.1695\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.3994 - val_loss: 7.1140\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.3944 - val_loss: 6.8499\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 6.3892 - val_loss: 6.7044\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.4035 - val_loss: 6.6460\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.3663 - val_loss: 6.6253\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.3872 - val_loss: 6.6102\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.3927 - val_loss: 6.6471\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.3829 - val_loss: 6.6823\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.3635 - val_loss: 6.6028\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.3792 - val_loss: 6.6871\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.4167 - val_loss: 6.8471\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.3827 - val_loss: 6.8505\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.4288 - val_loss: 7.5574\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.4338 - val_loss: 7.1866\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.4031 - val_loss: 7.1277\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.3758 - val_loss: 6.9698\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 6.3672 - val_loss: 6.6341\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 6.4117 - val_loss: 6.7070\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 6.3884 - val_loss: 6.7365\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 6.3933 - val_loss: 6.6902\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 6.4026 - val_loss: 6.5948\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 6.3628 - val_loss: 6.5952\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.3828 - val_loss: 6.7869\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.3705 - val_loss: 6.9005\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.3985 - val_loss: 7.2202\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.3706 - val_loss: 6.8687\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.3755 - val_loss: 6.7878\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.3411 - val_loss: 6.7990\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.3700 - val_loss: 6.6929\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.3555 - val_loss: 6.7095\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.3701 - val_loss: 6.7425\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.3519 - val_loss: 6.5914\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.3576 - val_loss: 6.5838\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.3701 - val_loss: 6.6012\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.3661 - val_loss: 6.6887\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.3770 - val_loss: 6.8251\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.3706 - val_loss: 7.1590\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.3639 - val_loss: 7.4775\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.3592 - val_loss: 8.1331\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.3510 - val_loss: 8.1921\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 37ms/step - loss: 6.3449 - val_loss: 7.7996\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.3529 - val_loss: 7.4890\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.3679 - val_loss: 7.3364\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.3836 - val_loss: 7.4411\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 6.3841 - val_loss: 8.2016\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 6.3912 - val_loss: 8.0978\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 6.3787 - val_loss: 8.2480\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 6.3383 - val_loss: 7.8294\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 6.3614 - val_loss: 7.4916\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.3533 - val_loss: 7.5388\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.3463 - val_loss: 7.9062\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.3478 - val_loss: 7.3497\n",
      "Epoch 173/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3401 - val_loss: 7.2393\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3483 - val_loss: 7.2896\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.3419 - val_loss: 7.5400\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3476 - val_loss: 7.8890\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3289 - val_loss: 7.7041\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 6.3390 - val_loss: 7.6812\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.3571 - val_loss: 7.1220\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3452 - val_loss: 7.0874\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3494 - val_loss: 6.8593\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3581 - val_loss: 6.7186\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3508 - val_loss: 6.6806\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 6.3637 - val_loss: 6.7519\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3633 - val_loss: 7.1467\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3385 - val_loss: 7.2738\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3250 - val_loss: 7.4529\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3303 - val_loss: 9.2516\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3484 - val_loss: 7.3631\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 6.3479 - val_loss: 7.0081\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3383 - val_loss: 7.0682\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3486 - val_loss: 6.7820\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3342 - val_loss: 7.1753\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3483 - val_loss: 7.0631\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3398 - val_loss: 7.2043\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3270 - val_loss: 8.7720\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3326 - val_loss: 9.0416\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 6.3321 - val_loss: 8.3647\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3348 - val_loss: 7.5308\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3146 - val_loss: 7.0416\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define MDN Exponentialmodel\n",
    "MDN_model_ref_exponential = model_generator(n_para=2)\n",
    "MDN_model_ref_exponential.compile(optimizer=tf.keras.optimizers.Adam(0.0001), loss=exponential_loss)\n",
    "history_exponential = MDN_model_ref_exponential.fit(train_x, train_y, epochs=200, validation_data=[test_x, test_y])\n",
    "plot_history(history_exponential, 'Regular Training, Exponential MDN, Likelihood')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MAE between mean of MD and Y is not a stable loss to track."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Debug Meta Learning Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define necessary tool functions\n",
    "components = 100\n",
    "no_parameters = 3\n",
    "data = [g_data, m_data]\n",
    "lats_lons = [G_lats, G_lons, M_lats, M_lons]\n",
    "task_dim = 3\n",
    "test_proportion = 0.5\n",
    "n_lag = 10\n",
    "\n",
    "# define MDN model\n",
    "# input dim (time, channel, rows, cols)\n",
    "input1 = layers.Input(shape=(n_lag, 1, task_dim, task_dim)) \n",
    "input1 = layers.BatchNormalization()(input1)\n",
    "input2 = layers.Input(shape=(task_dim, task_dim, 1))\n",
    "input2 = layers.BatchNormalization()(input2)\n",
    "input3 = layers.Input(shape=(1))\n",
    "input3 = layers.BatchNormalization()(input3)\n",
    "\n",
    "X = layers.ConvLSTM2D(filters=20, kernel_size=(1,2), activation='tanh', return_sequences=True)(input1)\n",
    "X = layers.ConvLSTM2D(filters=20, kernel_size=(1,2), activation='relu', return_sequences=True)(X)\n",
    "X = layers.ConvLSTM2D(filters=20, kernel_size=(1,1), activation='relu')(X)\n",
    "X = layers.Flatten()(X)\n",
    "X = layers.Dense(512, activation='relu')(X)\n",
    "X = layers.BatchNormalization()(X)\n",
    "X = layers.Dense(300, activation='relu')(X)\n",
    "\n",
    "X1 = layers.Conv2D(20, (2,2), activation='tanh')(input2)\n",
    "X1 = layers.Flatten()(X1)\n",
    "X2 = layers.BatchNormalization()(input3)\n",
    "X2 = layers.Dense(30, activation='relu')(X2)\n",
    "\n",
    "X = layers.Concatenate()([X, X1, X2])\n",
    "X = layers.Dense(128, activation='tanh')(X)\n",
    "X = layers.BatchNormalization()(X)\n",
    "X = layers.Dense(128, activation='relu')(X)\n",
    "X = layers.BatchNormalization()(X)\n",
    "X = layers.Dense(128, activation='tanh')(X)\n",
    "X = layers.BatchNormalization()(X)\n",
    "alphas = layers.Dense(components*task_dim*task_dim, activation=\"softmax\")(X)\n",
    "#alphas = layers.Reshape((task_dim, task_dim, components), name=\"alphas\")(alphas)\n",
    "mus = layers.Dense(components*task_dim*task_dim, activation='nnelu')(X)\n",
    "#mus = layers.Reshape((task_dim, task_dim, components) ,name=\"mus\")(mus)\n",
    "sigmas = layers.Dense(components*task_dim*task_dim, activation=\"nnelu\", name=\"sigmas\")(X)\n",
    "output = layers.Concatenate()([alphas, mus, sigmas])\n",
    "MDN_model = Model([input1, input2, input3], output)\n",
    "\n",
    "# define TaskExtractor\n",
    "\n",
    "taskextractor = TaskExtractor(data, lats_lons, task_dim, test_proportion, n_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(probdownscale.MetaTrain)\n",
    "from probdownscale.MetaTrain import MetaSGD\n",
    "# define meta learner\n",
    "meta_optimizer = tf.keras.optimizers.Adam(0.0001)\n",
    "inner_step = 1\n",
    "inner_optimizer = tf.keras.optimizers.Adam(0.0001)\n",
    "\n",
    "meta_learner = MetaSGD(MDN_model, gamma_loss,  meta_optimizer, inner_step, inner_optimizer, taskextractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 20  Basic training step:  1 / 8 loss:  72.336075\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 20  Basic training step:  2 / 8 loss:  69.37856\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 20  Basic training step:  3 / 8 loss:  67.95126\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 20  Basic training step:  4 / 8 loss:  62.241722\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 20  Basic training step:  5 / 8 loss:  67.81808\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 20  Basic training step:  6 / 8 loss:  62.390392\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 20  Basic training step:  7 / 8 loss:  62.08769\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 20  Basic training step:  8 / 8 loss:  62.299694\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 20 Bootstrap training step: 1 / 10 loss:  55.515236\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 20 Bootstrap training step: 2 / 10 loss:  62.304626\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 20 Bootstrap training step: 3 / 10 loss:  58.641502\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 20 Bootstrap training step: 4 / 10 loss:  60.092518\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 20 Bootstrap training step: 5 / 10 loss:  51.282143\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 20 Bootstrap training step: 6 / 10 loss:  52.35673\n"
     ]
    }
   ],
   "source": [
    "# meta train\n",
    "meta_history = meta_learner.meta_fit(20, batch_size=10, basic_train=True, bootstrap_train=True, use_test_for_meta=True, randomize=True)\n",
    "plt.plot(meta_history)\n",
    "plt.title('Meta Training History')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_meta_model = meta_learner.meta_model\n",
    "optimizer = tf.keras.optimizers.Adam(0.0000001)\n",
    "trained_meta_model.compile(optimizer=optimizer, loss=gamma_loss)\n",
    "meta_history_fine_tune = trained_meta_model.fit(train_x, train_y, epochs=5, validation_data=[test_x, test_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inner_rate_f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-be7e5f71bb24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mbatch_dist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdistance_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcenter\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlocat\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch_locations\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0minner_rate_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'inner_rate_f' is not defined"
     ]
    }
   ],
   "source": [
    "def inner_rate_function(inner_rate, batch_size, inner_step):\n",
    "    return inner_rate/inner_step*math.log(batch_size, 20)\n",
    "\n",
    "def meta_rate_function(meta_rate, batch_locations, seen_locations, covariance_function, distance_function):\n",
    "    batch_size = len(batch_location)\n",
    "    center = np.average(list(seen_locations.keys()), weights=list(seen_locations.values()), axis=0)\n",
    "    batch_dist = np.mean([distance_function(locat, center) for locat in batch_locations])\n",
    "    \n",
    "inner_rate_f(0.01, 100, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Meta Training History')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(meta_history)\n",
    "plt.title('Meta Training History')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_24\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_148 (InputLayer)         [(None, 10, 1, 3, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv_lstm2d_72 (ConvLSTM2D)    (None, 10, 1, 2, 20  3760        ['input_148[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_lstm2d_73 (ConvLSTM2D)    (None, 10, 1, 1, 20  6480        ['conv_lstm2d_72[1][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_lstm2d_74 (ConvLSTM2D)    (None, 1, 1, 20)     3280        ['conv_lstm2d_73[1][0]']         \n",
      "                                                                                                  \n",
      " flatten_48 (Flatten)           (None, 20)           0           ['conv_lstm2d_74[1][0]']         \n",
      "                                                                                                  \n",
      " dense_200 (Dense)              (None, 512)          10752       ['flatten_48[1][0]']             \n",
      "                                                                                                  \n",
      " input_149 (InputLayer)         [(None, 3, 3, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " input_150 (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " batch_normalization_195 (Batch  (None, 512)         2048        ['dense_200[1][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 2, 2, 20)     100         ['input_149[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_196 (Batch  (None, 1)           4           ['input_150[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dense_201 (Dense)              (None, 300)          153900      ['batch_normalization_195[1][0]']\n",
      "                                                                                                  \n",
      " flatten_49 (Flatten)           (None, 80)           0           ['conv2d_24[1][0]']              \n",
      "                                                                                                  \n",
      " dense_202 (Dense)              (None, 30)           60          ['batch_normalization_196[1][0]']\n",
      "                                                                                                  \n",
      " concatenate_48 (Concatenate)   (None, 410)          0           ['dense_201[1][0]',              \n",
      "                                                                  'flatten_49[1][0]',             \n",
      "                                                                  'dense_202[1][0]']              \n",
      "                                                                                                  \n",
      " dense_203 (Dense)              (None, 128)          52608       ['concatenate_48[1][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_197 (Batch  (None, 128)         512         ['dense_203[1][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dense_204 (Dense)              (None, 128)          16512       ['batch_normalization_197[1][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_198 (Batch  (None, 128)         512         ['dense_204[1][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dense_205 (Dense)              (None, 128)          16512       ['batch_normalization_198[1][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_199 (Batch  (None, 128)         512         ['dense_205[1][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dense_206 (Dense)              (None, 9000)         1161000     ['batch_normalization_199[1][0]']\n",
      "                                                                                                  \n",
      " dense_207 (Dense)              (None, 9000)         1161000     ['batch_normalization_199[1][0]']\n",
      "                                                                                                  \n",
      " sigmas (Dense)                 (None, 9000)         1161000     ['batch_normalization_199[1][0]']\n",
      "                                                                                                  \n",
      " concatenate_49 (Concatenate)   (None, 27000)        0           ['dense_206[1][0]',              \n",
      "                                                                  'dense_207[1][0]',              \n",
      "                                                                  'sigmas[1][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,750,552\n",
      "Trainable params: 3,748,758\n",
      "Non-trainable params: 1,794\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trained_meta_model = meta_learner.meta_model\n",
    "optimizer = tf.keras.optimizers.Adam(0.0000001)\n",
    "trained_meta_model.compile(optimizer=optimizer, loss=gamma_loss)\n",
    "trained_meta_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16/16 [==============================] - 11s 144ms/step - loss: 7.0205 - val_loss: 100.2038\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 6.9077 - val_loss: 93.4999\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 7.0396 - val_loss: 87.2813\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 7.0445 - val_loss: 82.0647\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 7.2663 - val_loss: 77.1205\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 1s 84ms/step - loss: 6.9881 - val_loss: 73.0638\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 7.2018 - val_loss: 69.7954\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 7.1933 - val_loss: 66.5253\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 6.9173 - val_loss: 63.7211\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 7.1585 - val_loss: 60.7964\n"
     ]
    }
   ],
   "source": [
    "meta_history_fine_tune = trained_meta_model.fit(train_x, train_y, epochs=10, validation_data=[test_x, test_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Downscale_env",
   "language": "python",
   "name": "downscale_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
