{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import os\n",
    "import sys\n",
    "from importlib import reload\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import probdownscale\n",
    "reload(probdownscale.TaskExtractor)\n",
    "reload(probdownscale.MetaTrain)\n",
    "from probdownscale.MetaTrain import MetaSGD\n",
    "\n",
    "from probdownscale.TaskExtractor import TaskExtractor\n",
    "import math\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow_probability import distributions as tfd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Debug TaskExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\96349\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\96349\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \n",
      "C:\\Users\\96349\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\96349\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "C:\\Users\\96349\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\ipykernel_launcher.py:21: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "C:\\Users\\96349\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\ipykernel_launcher.py:22: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    }
   ],
   "source": [
    "file_path_g_05 = r'C:\\Users\\96349\\Documents\\Downscale_data\\MERRA2\\G5NR_aerosol_variables_over_MiddleEast_daily_20050516-20060515.nc'\n",
    "file_path_g_06 =  r'C:\\Users\\96349\\Documents\\Downscale_data\\MERRA2\\G5NR_aerosol_variables_over_MiddleEast_daily_20060516-20070515.nc'\n",
    "file_path_m = r'C:\\Users\\96349\\Documents\\Downscale_data\\MERRA2\\MERRA2_aerosol_variables_over_MiddleEast_daily_20000516-20180515.nc'\n",
    "target_var = 'BCSMASS'\n",
    "\n",
    "# read data\n",
    "g05_data = nc.Dataset(file_path_g_05)\n",
    "g06_data = nc.Dataset(file_path_g_06)\n",
    "m_data_nc = nc.Dataset(file_path_m)\n",
    "\n",
    "# define lat&lon of MERRA, G5NR and mete\n",
    "M_lons = m_data_nc.variables['lon'][:15]\n",
    "# self.M_lons = (M_lons-M_lons.mean())/M_lons.std()\n",
    "M_lats = m_data_nc.variables['lat'][:15]\n",
    "# self.M_lats = (M_lats-M_lats.mean())/M_lats.std()\n",
    "G_lons = g05_data.variables['lon'][:30]\n",
    "# self.G_lons = (G_lons-G_lons.mean())/G_lons.std()\n",
    "G_lats = g05_data.variables['lat'][:30]\n",
    "\n",
    "# extract target data\n",
    "g_data = np.concatenate((g05_data.variables[target_var][:, :30, :30], g06_data.variables[target_var][:, :30, :30]), axis=0)\n",
    "m_data = m_data_nc.variables[target_var][5*365:7*365, :15, :15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_g_data, test_g_data = g_data[:657], g_data[657:]\n",
    "train_m_data, test_m_data = m_data[:657], m_data[657:]\n",
    "data = [train_g_data, train_m_data]\n",
    "lats_lons = [G_lats, G_lons, M_lats, M_lons]\n",
    "task_dim = 3\n",
    "test_proportion = 0.3\n",
    "n_lag = 10\n",
    "taskextractor = TaskExtractor(data, lats_lons, task_dim, test_proportion, n_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y, location, init = taskextractor._get_one_random_task(return_init=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y, locations = taskextractor.get_random_tasks(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y, locations = taskextractor.get_random_tasks(locations=locations[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 1, 4, 2]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import sample\n",
    "sample([1,2,3,4], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(range(10))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 7, 8]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[6:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow_probability import distributions as tfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the last channel is the comonents\n",
    "alpha = np.random.rand(3,2,5)\n",
    "alpha = alpha/alpha.sum()\n",
    "mu = np.random.rand(3, 2, 5)\n",
    "mu = np.abs(mu)\n",
    "test_md = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=alpha),\n",
    "        components_distribution=tfd.Gamma(concentration=mu, rate=mu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99199912, 1.09824118],\n",
       "       [0.9757111 , 0.86317665],\n",
       "       [0.99805722, 0.88828781]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_md.sample(100).numpy().mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float64, numpy=\n",
       "array([[nan, nan],\n",
       "       [nan, nan],\n",
       "       [nan, nan]])>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_like = test_md.log_prob(np.ones((3,2))*-0.001)\n",
    "#-tf.reduce_mean(log_like, axis=-1)\n",
    "log_like\n",
    "\n",
    "# when the Y is really small, log_prob return a positive log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float64, numpy=\n",
       "array([[0.15880819, 0.10569395],\n",
       "       [0.17997603, 0.15908541],\n",
       "       [0.20016422, 0.19627221]])>"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_md.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float64, numpy=\n",
       "array([[-1.07151844, -1.96976935],\n",
       "       [-0.88054633, -1.06112697],\n",
       "       [-1.63395563, -0.41498473]])>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =  np.random.rand(3,3,3)\n",
    "#a = (a - a.min())/(a.max() - a.min())\n",
    "a = a/a.sum()\n",
    "a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define necessary tool functions\n",
    "components = 100\n",
    "no_parameters = 2\n",
    "\n",
    "def nnelu(input):\n",
    "    return tf.add(tf.constant(1, dtype=tf.float32), tf.nn.elu(input))\n",
    "\n",
    "def slice_parameter_vectors(parameter_vector, no_parameters):\n",
    "    return [parameter_vector[:, i * task_dim*task_dim*components:(i + 1) *task_dim*task_dim*components] for i in range(no_parameters)]\n",
    "\n",
    "def gamma_loss(y, parameter_vector):\n",
    "    alpha, mu, sigma = slice_parameter_vectors(parameter_vector, 3)  # Unpack parameter vectors\n",
    "    #print(alpha.shape, mu.shape)\n",
    "    alpha1 = tf.reshape(alpha, (tf.shape(alpha)[0], task_dim, task_dim, components))\n",
    "    mu1 = tf.reshape(mu, (tf.shape(mu)[0], task_dim, task_dim, components))\n",
    "    sigma1 = tf.reshape(sigma,  (tf.shape(sigma)[0], task_dim, task_dim, components))\n",
    "    #print(alpha1.shape, mu1.shape)\n",
    "    gm = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=alpha1),\n",
    "        components_distribution=tfd.Gamma(\n",
    "        concentration=mu1, rate=sigma1)\n",
    "    )\n",
    "\n",
    "    log_likelihood = gm.log_prob(y)  # Evaluate log-probability of y\n",
    "    #print(log_likelihood)\n",
    "    return -tf.reduce_mean(log_likelihood, axis=-1)\n",
    "\n",
    "def exponential_loss(y, parameter_vector):\n",
    "    alpha, mu = slice_parameter_vectors(parameter_vector, 2)  # Unpack parameter vectors\n",
    "    #print(alpha.shape, mu.shape)\n",
    "    alpha1 = tf.reshape(alpha, (tf.shape(alpha)[0], task_dim, task_dim, components))\n",
    "    mu1 = tf.reshape(mu, (tf.shape(mu)[0], task_dim, task_dim, components))\n",
    "    #print(alpha1.shape, mu1.shape)\n",
    "    gm = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=alpha1),\n",
    "        components_distribution=tfd.Exponential(\n",
    "        rate=mu1)\n",
    "    )\n",
    "\n",
    "    log_likelihood = gm.log_prob(y)  # Evaluate log-probability of y\n",
    "    #print(log_likelihood)\n",
    "    return -tf.reduce_mean(log_likelihood, axis=-1)\n",
    "\n",
    "def gamma_mean_loss(y, parameter_vector):\n",
    "    alpha, mu, sigma = slice_parameter_vectors(parameter_vector, 3)  # Unpack parameter vectors\n",
    "    #print(alpha.shape, mu.shape)\n",
    "    alpha1 = tf.reshape(alpha, (tf.shape(alpha)[0], task_dim, task_dim, components))\n",
    "    mu1 = tf.reshape(mu, (tf.shape(mu)[0], task_dim, task_dim, components))\n",
    "    sigma1 = tf.reshape(sigma,  (tf.shape(sigma)[0], task_dim, task_dim, components))\n",
    "    #print(alpha1.shape, mu1.shape)\n",
    "    gm = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=alpha1),\n",
    "        components_distribution=tfd.Gamma(\n",
    "        concentration=mu1, rate=sigma1)\n",
    "    )\n",
    "    mae = tf.keras.losses.MeanAbsoluteError()\n",
    "    return mae(gm.mean(), y) \n",
    "\n",
    "\n",
    "tf.keras.utils.get_custom_objects().update({'nnelu': layers.Activation(nnelu)})\n",
    "\n",
    "def plot_history(history, title):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(title)\n",
    "    \n",
    "def model_generator(n_para=2):\n",
    "    # define MDN Exponentialmodel\n",
    "    # input dim (time, channel, rows, cols)\n",
    "    input1 = layers.Input(shape=(n_lag, 1, task_dim, task_dim)) \n",
    "    input1 = layers.BatchNormalization()(input1)\n",
    "    input2 = layers.Input(shape=(task_dim, task_dim, 1))\n",
    "    input2 = layers.BatchNormalization()(input2)\n",
    "    input3 = layers.Input(shape=(1))\n",
    "    input3 = layers.BatchNormalization()(input3)\n",
    "\n",
    "    X = layers.ConvLSTM2D(filters=20, kernel_size=(1,2), activation='tanh', return_sequences=True)(input1)\n",
    "    X = layers.ConvLSTM2D(filters=20, kernel_size=(1,2), activation='relu', return_sequences=True)(X)\n",
    "    X = layers.ConvLSTM2D(filters=20, kernel_size=(1,1), activation='relu')(X)\n",
    "    X = layers.Flatten()(X)\n",
    "    X = layers.Dense(512, activation='relu')(X)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    X = layers.Dense(300, activation='relu')(X)\n",
    "\n",
    "    X1 = layers.Conv2D(20, (2,2), activation='tanh')(input2)\n",
    "    X1 = layers.Flatten()(X1)\n",
    "    X2 = layers.BatchNormalization()(input3)\n",
    "    X2 = layers.Dense(30, activation='relu')(X2)\n",
    "\n",
    "    X = layers.Concatenate()([X, X1, X2])\n",
    "    X = layers.Dense(128, activation='relu')(X)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    X = layers.Dense(128, activation='relu')(X)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    X = layers.Dense(128, activation='relu')(X)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    X = layers.Concatenate()([X, X1, X2])\n",
    "    X = layers.Dense(128, activation='relu')(X)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    X = layers.Dense(128, activation='relu')(X)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    X = layers.Dense(128, activation='relu')(X)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    X = layers.Concatenate()([X, X1, X2])\n",
    "    X = layers.Dense(128, activation='relu')(X)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    X = layers.Dense(128, activation='relu')(X)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    X = layers.Dense(128, activation='relu')(X)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    X = layers.Concatenate()([X, X1, X2])\n",
    "    X = layers.Dense(128, activation='relu')(X)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    X = layers.Dense(128, activation='relu')(X)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    X = layers.Dense(128, activation='relu')(X)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    X = layers.Concatenate()([X, X1, X2])\n",
    "    X = layers.Dense(128, activation='relu')(X)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    X = layers.Dense(128, activation='relu')(X)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    X = layers.Dense(128, activation='relu')(X)\n",
    "    X = layers.BatchNormalization()(X)\n",
    "    if n_para ==2:\n",
    "        alphas = layers.Dense(components*task_dim*task_dim, activation=\"softmax\")(X)\n",
    "        #alphas = layers.Reshape((task_dim, task_dim, components), name=\"alphas\")(alphas)\n",
    "        mus = layers.Dense(components*task_dim*task_dim, activation='nnelu')(X)\n",
    "        #mus = layers.Reshape((task_dim, task_dim, components) ,name=\"mus\")(mus)\n",
    "        output = layers.Concatenate()([alphas, mus])\n",
    "        model = Model([input1, input2, input3], output)\n",
    "    else:\n",
    "        alphas = layers.Dense(components*task_dim*task_dim, activation=\"softmax\")(X)\n",
    "        #alphas = layers.Reshape((task_dim, task_dim, components), name=\"alphas\")(alphas)\n",
    "        mus = layers.Dense(components*task_dim*task_dim, activation='nnelu')(X)\n",
    "        #mus = layers.Reshape((task_dim, task_dim, components) ,name=\"mus\")(mus)\n",
    "        sigmas = layers.Dense(components*task_dim*task_dim, activation='nnelu')(X)\n",
    "        output = layers.Concatenate()([alphas, mus, sigmas])\n",
    "        model = Model([input1, input2, input3], output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "15/15 [==============================] - 18s 139ms/step - loss: 71.4928 - val_loss: 181.3611\n",
      "Epoch 2/200\n",
      "15/15 [==============================] - 1s 45ms/step - loss: 71.1275 - val_loss: 189.5304\n",
      "Epoch 3/200\n",
      "15/15 [==============================] - 1s 47ms/step - loss: 69.9280 - val_loss: 187.0380\n",
      "Epoch 4/200\n",
      "15/15 [==============================] - 1s 47ms/step - loss: 69.1827 - val_loss: 178.7140\n",
      "Epoch 5/200\n",
      "15/15 [==============================] - 1s 47ms/step - loss: 68.1245 - val_loss: 168.0390\n",
      "Epoch 6/200\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 65.9037 - val_loss: 157.2974\n",
      "Epoch 7/200\n",
      "15/15 [==============================] - 1s 47ms/step - loss: 65.6374 - val_loss: 147.6293\n",
      "Epoch 8/200\n",
      "15/15 [==============================] - 1s 47ms/step - loss: 64.3810 - val_loss: 139.8438\n",
      "Epoch 9/200\n",
      "15/15 [==============================] - 1s 48ms/step - loss: 63.2070 - val_loss: 133.2554\n",
      "Epoch 10/200\n",
      "15/15 [==============================] - 1s 46ms/step - loss: 62.5208 - val_loss: 124.1200\n",
      "Epoch 11/200\n",
      "15/15 [==============================] - 1s 47ms/step - loss: 61.9931 - val_loss: 115.8210\n",
      "Epoch 12/200\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 60.6582 - val_loss: 108.4564\n",
      "Epoch 13/200\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 60.0079 - val_loss: 103.0847\n",
      "Epoch 14/200\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 59.1819 - val_loss: 98.6921\n",
      "Epoch 15/200\n",
      "15/15 [==============================] - 1s 48ms/step - loss: 58.6865 - val_loss: 90.4432\n",
      "Epoch 16/200\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 57.2653 - val_loss: 85.6215\n",
      "Epoch 17/200\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 56.2232 - val_loss: 85.5532\n",
      "Epoch 18/200\n",
      "15/15 [==============================] - 1s 48ms/step - loss: 55.3815 - val_loss: 85.0410\n",
      "Epoch 19/200\n",
      "15/15 [==============================] - 1s 47ms/step - loss: 54.9919 - val_loss: 81.3318\n",
      "Epoch 20/200\n",
      "15/15 [==============================] - 1s 47ms/step - loss: 53.6450 - val_loss: 76.2062\n",
      "Epoch 21/200\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 51.8321 - val_loss: 78.2404\n",
      "Epoch 22/200\n",
      "15/15 [==============================] - 1s 48ms/step - loss: 51.1445 - val_loss: 67.1210\n",
      "Epoch 23/200\n",
      "15/15 [==============================] - 1s 47ms/step - loss: 50.7916 - val_loss: 64.5213\n",
      "Epoch 24/200\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 49.7101 - val_loss: 65.3619\n",
      "Epoch 25/200\n",
      "15/15 [==============================] - 1s 46ms/step - loss: 48.3862 - val_loss: 58.9090\n",
      "Epoch 26/200\n",
      "15/15 [==============================] - 1s 48ms/step - loss: 47.3191 - val_loss: 58.6185\n",
      "Epoch 27/200\n",
      "15/15 [==============================] - 1s 48ms/step - loss: 46.2833 - val_loss: 57.6600\n",
      "Epoch 28/200\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 45.1111 - val_loss: 50.2815\n",
      "Epoch 29/200\n",
      "15/15 [==============================] - 1s 47ms/step - loss: 43.5468 - val_loss: 44.8055\n",
      "Epoch 30/200\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 42.4817 - val_loss: 48.5220\n",
      "Epoch 31/200\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 41.8124 - val_loss: 50.6406\n",
      "Epoch 32/200\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 40.3319 - val_loss: 39.0658\n",
      "Epoch 33/200\n",
      "15/15 [==============================] - 1s 48ms/step - loss: 39.1540 - val_loss: 36.0649\n",
      "Epoch 34/200\n",
      "15/15 [==============================] - 1s 47ms/step - loss: 37.6357 - val_loss: 27.2584\n",
      "Epoch 35/200\n",
      "15/15 [==============================] - 1s 60ms/step - loss: 36.4122 - val_loss: 25.4255\n",
      "Epoch 36/200\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 36.7139 - val_loss: 23.0818\n",
      "Epoch 37/200\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 34.5258 - val_loss: 24.3505\n",
      "Epoch 38/200\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 32.9818 - val_loss: 27.3981\n",
      "Epoch 39/200\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 31.6066 - val_loss: 29.9582\n",
      "Epoch 40/200\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 31.0940 - val_loss: 31.1445\n",
      "Epoch 41/200\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 29.4364 - val_loss: 28.6869\n",
      "Epoch 42/200\n",
      "15/15 [==============================] - 1s 69ms/step - loss: 29.6823 - val_loss: 24.9492\n",
      "Epoch 43/200\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 27.1734 - val_loss: 20.3785\n",
      "Epoch 44/200\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 26.7899 - val_loss: 12.6787\n",
      "Epoch 45/200\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 25.8389 - val_loss: 11.1783\n",
      "Epoch 46/200\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 25.2437 - val_loss: nan\n",
      "Epoch 47/200\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 23.7840 - val_loss: nan\n",
      "Epoch 48/200\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 22.5238 - val_loss: nan\n",
      "Epoch 49/200\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 21.9600 - val_loss: nan\n",
      "Epoch 50/200\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 21.4643 - val_loss: nan\n",
      "Epoch 51/200\n",
      "15/15 [==============================] - 1s 60ms/step - loss: 19.9071 - val_loss: nan\n",
      "Epoch 52/200\n",
      "15/15 [==============================] - 1s 67ms/step - loss: 20.0773 - val_loss: nan\n",
      "Epoch 53/200\n",
      "15/15 [==============================] - 1s 64ms/step - loss: 18.2117 - val_loss: nan\n",
      "Epoch 54/200\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 17.4909 - val_loss: nan\n",
      "Epoch 55/200\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 17.6145 - val_loss: nan\n",
      "Epoch 56/200\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 16.2206 - val_loss: nan\n",
      "Epoch 57/200\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 16.3020 - val_loss: nan\n",
      "Epoch 58/200\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 15.9103 - val_loss: nan\n",
      "Epoch 59/200\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 15.0205 - val_loss: nan\n",
      "Epoch 60/200\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 14.4061 - val_loss: nan\n",
      "Epoch 61/200\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 13.7371 - val_loss: nan\n",
      "Epoch 62/200\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 14.0584 - val_loss: nan\n",
      "Epoch 63/200\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 13.9578 - val_loss: nan\n",
      "Epoch 64/200\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 13.4790 - val_loss: nan\n",
      "Epoch 65/200\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 12.8665 - val_loss: nan\n",
      "Epoch 66/200\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 12.2230 - val_loss: nan\n",
      "Epoch 67/200\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 12.1218 - val_loss: nan\n",
      "Epoch 68/200\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 12.3576 - val_loss: nan\n",
      "Epoch 69/200\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 12.0196 - val_loss: nan\n",
      "Epoch 70/200\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 11.4037 - val_loss: nan\n",
      "Epoch 71/200\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 10.9191 - val_loss: nan\n",
      "Epoch 72/200\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 11.3597 - val_loss: nan\n",
      "Epoch 73/200\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 10.5019 - val_loss: nan\n",
      "Epoch 74/200\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 10.7235 - val_loss: nan\n",
      "Epoch 75/200\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 10.8287 - val_loss: nan\n",
      "Epoch 76/200\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 10.3241 - val_loss: nan\n",
      "Epoch 77/200\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 10.2044 - val_loss: nan\n",
      "Epoch 78/200\n",
      "15/15 [==============================] - 1s 48ms/step - loss: 10.2746 - val_loss: nan\n",
      "Epoch 79/200\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 10.3240 - val_loss: nan\n",
      "Epoch 80/200\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 9.9270 - val_loss: nan\n",
      "Epoch 81/200\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 10.0435 - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/200\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 9.4297 - val_loss: nan\n",
      "Epoch 83/200\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 9.6078 - val_loss: nan\n",
      "Epoch 84/200\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 9.6781 - val_loss: nan\n",
      "Epoch 85/200\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 9.5737 - val_loss: nan\n",
      "Epoch 86/200\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 8.9968 - val_loss: nan\n",
      "Epoch 87/200\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 9.3547 - val_loss: nan\n",
      "Epoch 88/200\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 8.8883 - val_loss: nan\n",
      "Epoch 89/200\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 9.2559 - val_loss: nan\n",
      "Epoch 90/200\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 8.7751 - val_loss: nan\n",
      "Epoch 91/200\n",
      "15/15 [==============================] - 1s 47ms/step - loss: 8.6156 - val_loss: nan\n",
      "Epoch 92/200\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 8.8662 - val_loss: nan\n",
      "Epoch 93/200\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 8.2847 - val_loss: nan\n",
      "Epoch 94/200\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 8.6585 - val_loss: nan\n",
      "Epoch 95/200\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 8.3748 - val_loss: nan\n",
      "Epoch 96/200\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 8.6891 - val_loss: nan\n",
      "Epoch 97/200\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 8.6453 - val_loss: nan\n",
      "Epoch 98/200\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 8.4849 - val_loss: nan\n",
      "Epoch 99/200\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 8.4268 - val_loss: nan\n",
      "Epoch 100/200\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 8.2797 - val_loss: nan\n",
      "Epoch 101/200\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 8.3626 - val_loss: nan\n",
      "Epoch 102/200\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 8.3303 - val_loss: nan\n",
      "Epoch 103/200\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 7.7942 - val_loss: nan\n",
      "Epoch 104/200\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 8.2499 - val_loss: nan\n",
      "Epoch 105/200\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 7.9346 - val_loss: nan\n",
      "Epoch 106/200\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 7.9265 - val_loss: nan\n",
      "Epoch 107/200\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 8.0689 - val_loss: 9.2017\n",
      "Epoch 108/200\n",
      "15/15 [==============================] - 1s 70ms/step - loss: 7.5420 - val_loss: 9.1899\n",
      "Epoch 109/200\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 7.8793 - val_loss: 9.4650\n",
      "Epoch 110/200\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 7.6694 - val_loss: 9.1357\n",
      "Epoch 111/200\n",
      "15/15 [==============================] - 1s 75ms/step - loss: 7.5456 - val_loss: 8.8964\n",
      "Epoch 112/200\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 7.5485 - val_loss: 8.1421\n",
      "Epoch 113/200\n",
      "15/15 [==============================] - 1s 61ms/step - loss: 7.3432 - val_loss: 8.9245\n",
      "Epoch 114/200\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 7.5792 - val_loss: 8.6909\n",
      "Epoch 115/200\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 7.6174 - val_loss: 8.6372\n",
      "Epoch 116/200\n",
      "15/15 [==============================] - 1s 61ms/step - loss: 7.4447 - val_loss: 8.3073\n",
      "Epoch 117/200\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 7.5337 - val_loss: 8.4212\n",
      "Epoch 118/200\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 7.2683 - val_loss: 8.2255\n",
      "Epoch 119/200\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 7.5247 - val_loss: 8.0732\n",
      "Epoch 120/200\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 7.3035 - val_loss: 8.0502\n",
      "Epoch 121/200\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 7.2385 - val_loss: 8.0690\n",
      "Epoch 122/200\n",
      "15/15 [==============================] - 1s 62ms/step - loss: 7.4569 - val_loss: 7.9559\n",
      "Epoch 123/200\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 7.3350 - val_loss: 8.2651\n",
      "Epoch 124/200\n",
      "15/15 [==============================] - 1s 71ms/step - loss: 7.3846 - val_loss: 8.3556\n",
      "Epoch 125/200\n",
      "15/15 [==============================] - 1s 74ms/step - loss: 7.2690 - val_loss: 8.0339\n",
      "Epoch 126/200\n",
      "15/15 [==============================] - 1s 67ms/step - loss: 7.1531 - val_loss: 8.0504\n",
      "Epoch 127/200\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 7.0634 - val_loss: 7.9501\n",
      "Epoch 128/200\n",
      "15/15 [==============================] - 1s 62ms/step - loss: 7.1840 - val_loss: 7.7794\n",
      "Epoch 129/200\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 7.1385 - val_loss: 7.6622\n",
      "Epoch 130/200\n",
      "15/15 [==============================] - 1s 52ms/step - loss: 7.2417 - val_loss: 8.0564\n",
      "Epoch 131/200\n",
      "15/15 [==============================] - 1s 60ms/step - loss: 7.1498 - val_loss: 7.8256\n",
      "Epoch 132/200\n",
      "15/15 [==============================] - 1s 66ms/step - loss: 7.2265 - val_loss: 7.7520\n",
      "Epoch 133/200\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 7.0120 - val_loss: 7.6587\n",
      "Epoch 134/200\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 7.1143 - val_loss: 7.7379\n",
      "Epoch 135/200\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 7.1498 - val_loss: 7.5293\n",
      "Epoch 136/200\n",
      "15/15 [==============================] - 1s 49ms/step - loss: 7.1509 - val_loss: 7.5634\n",
      "Epoch 137/200\n",
      "15/15 [==============================] - 1s 45ms/step - loss: 7.0030 - val_loss: 7.6364\n",
      "Epoch 138/200\n",
      "15/15 [==============================] - 1s 43ms/step - loss: 7.0499 - val_loss: 7.4242\n",
      "Epoch 139/200\n",
      "15/15 [==============================] - 1s 51ms/step - loss: 6.9767 - val_loss: 7.8409\n",
      "Epoch 140/200\n",
      "15/15 [==============================] - 1s 42ms/step - loss: 6.8520 - val_loss: 8.3099\n",
      "Epoch 141/200\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 6.9055 - val_loss: 8.3359\n",
      "Epoch 142/200\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 6.8998 - val_loss: 8.0747\n",
      "Epoch 143/200\n",
      "15/15 [==============================] - 1s 48ms/step - loss: 6.9493 - val_loss: 7.6367\n",
      "Epoch 144/200\n",
      "15/15 [==============================] - 1s 44ms/step - loss: 6.8581 - val_loss: 7.6417\n",
      "Epoch 145/200\n",
      "15/15 [==============================] - 1s 44ms/step - loss: 6.9308 - val_loss: 7.3790\n",
      "Epoch 146/200\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 6.9901 - val_loss: 7.4782\n",
      "Epoch 147/200\n",
      "15/15 [==============================] - 1s 47ms/step - loss: 6.8907 - val_loss: 7.5239\n",
      "Epoch 148/200\n",
      "15/15 [==============================] - 1s 47ms/step - loss: 6.8099 - val_loss: 7.6113\n",
      "Epoch 149/200\n",
      "15/15 [==============================] - 1s 43ms/step - loss: 6.8598 - val_loss: 8.1442\n",
      "Epoch 150/200\n",
      "15/15 [==============================] - 1s 47ms/step - loss: 6.9063 - val_loss: 8.2284\n",
      "Epoch 151/200\n",
      "15/15 [==============================] - 1s 42ms/step - loss: 6.8154 - val_loss: 8.2046\n",
      "Epoch 152/200\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 6.8091 - val_loss: 7.7536\n",
      "Epoch 153/200\n",
      "15/15 [==============================] - 1s 46ms/step - loss: 6.8230 - val_loss: nan\n",
      "Epoch 154/200\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 6.8174 - val_loss: nan\n",
      "Epoch 155/200\n",
      "15/15 [==============================] - 1s 55ms/step - loss: 6.7000 - val_loss: 7.4873\n",
      "Epoch 156/200\n",
      "15/15 [==============================] - 1s 44ms/step - loss: 6.7605 - val_loss: 7.3615\n",
      "Epoch 157/200\n",
      "15/15 [==============================] - 1s 42ms/step - loss: 6.7070 - val_loss: 7.1189\n",
      "Epoch 158/200\n",
      "15/15 [==============================] - 1s 45ms/step - loss: 6.7666 - val_loss: 7.5176\n",
      "Epoch 159/200\n",
      "15/15 [==============================] - 1s 45ms/step - loss: 6.7469 - val_loss: nan\n",
      "Epoch 160/200\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 6.7748 - val_loss: nan\n",
      "Epoch 161/200\n",
      "15/15 [==============================] - 1s 54ms/step - loss: 6.6999 - val_loss: nan\n",
      "Epoch 162/200\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 6.6790 - val_loss: nan\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 40ms/step - loss: 6.6490 - val_loss: nan\n",
      "Epoch 164/200\n",
      "15/15 [==============================] - 1s 56ms/step - loss: 6.7017 - val_loss: nan\n",
      "Epoch 165/200\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 6.7021 - val_loss: nan\n",
      "Epoch 166/200\n",
      "15/15 [==============================] - 1s 47ms/step - loss: 6.7058 - val_loss: nan\n",
      "Epoch 167/200\n",
      "15/15 [==============================] - 1s 47ms/step - loss: 6.7690 - val_loss: nan\n",
      "Epoch 168/200\n",
      "15/15 [==============================] - 1s 53ms/step - loss: 6.5607 - val_loss: nan\n",
      "Epoch 169/200\n",
      "15/15 [==============================] - 1s 46ms/step - loss: 6.6592 - val_loss: nan\n",
      "Epoch 170/200\n",
      "15/15 [==============================] - 1s 48ms/step - loss: 6.5942 - val_loss: nan\n",
      "Epoch 171/200\n",
      "15/15 [==============================] - 1s 45ms/step - loss: 6.6690 - val_loss: nan\n",
      "Epoch 172/200\n",
      "15/15 [==============================] - 1s 62ms/step - loss: 6.6606 - val_loss: 7.3791\n",
      "Epoch 173/200\n",
      "15/15 [==============================] - 1s 50ms/step - loss: 6.5757 - val_loss: 7.2042\n",
      "Epoch 174/200\n",
      "15/15 [==============================] - 1s 42ms/step - loss: 6.6095 - val_loss: 7.1436\n",
      "Epoch 175/200\n",
      "15/15 [==============================] - 1s 45ms/step - loss: 6.6313 - val_loss: 7.2593\n",
      "Epoch 176/200\n",
      "15/15 [==============================] - 1s 45ms/step - loss: 6.6585 - val_loss: 7.8845\n",
      "Epoch 177/200\n",
      "15/15 [==============================] - 1s 42ms/step - loss: 6.6459 - val_loss: 8.1348\n",
      "Epoch 178/200\n",
      "15/15 [==============================] - 1s 43ms/step - loss: 6.5806 - val_loss: 7.9568\n",
      "Epoch 179/200\n",
      "15/15 [==============================] - 1s 42ms/step - loss: 6.5745 - val_loss: 7.4530\n",
      "Epoch 180/200\n",
      "15/15 [==============================] - 1s 45ms/step - loss: 6.6493 - val_loss: 7.3159\n",
      "Epoch 181/200\n",
      "15/15 [==============================] - 1s 42ms/step - loss: 6.5323 - val_loss: 7.6647\n",
      "Epoch 182/200\n",
      "15/15 [==============================] - 1s 47ms/step - loss: 6.5572 - val_loss: 7.4944\n",
      "Epoch 183/200\n",
      "15/15 [==============================] - 1s 43ms/step - loss: 6.5906 - val_loss: 7.3254\n",
      "Epoch 184/200\n",
      "15/15 [==============================] - 1s 44ms/step - loss: 6.5802 - val_loss: 7.1399\n",
      "Epoch 185/200\n",
      "15/15 [==============================] - 1s 44ms/step - loss: 6.4994 - val_loss: 6.9679\n",
      "Epoch 186/200\n",
      "15/15 [==============================] - 1s 48ms/step - loss: 6.6176 - val_loss: 6.9929\n",
      "Epoch 187/200\n",
      "15/15 [==============================] - 1s 42ms/step - loss: 6.5000 - val_loss: 7.1650\n",
      "Epoch 188/200\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 6.5142 - val_loss: nan\n",
      "Epoch 189/200\n",
      "15/15 [==============================] - 1s 44ms/step - loss: 6.5628 - val_loss: 7.2540\n",
      "Epoch 190/200\n",
      "15/15 [==============================] - 1s 44ms/step - loss: 6.5241 - val_loss: nan\n",
      "Epoch 191/200\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 6.5198 - val_loss: 7.3718\n",
      "Epoch 192/200\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 6.5385 - val_loss: 7.2883\n",
      "Epoch 193/200\n",
      "15/15 [==============================] - 1s 47ms/step - loss: 6.4428 - val_loss: 7.2128\n",
      "Epoch 194/200\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 6.4408 - val_loss: 7.2582\n",
      "Epoch 195/200\n",
      "15/15 [==============================] - 1s 42ms/step - loss: 6.4594 - val_loss: 7.7351\n",
      "Epoch 196/200\n",
      "15/15 [==============================] - 1s 43ms/step - loss: 6.4591 - val_loss: 7.9589\n",
      "Epoch 197/200\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 6.5112 - val_loss: 7.7720\n",
      "Epoch 198/200\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 6.4760 - val_loss: 7.8492\n",
      "Epoch 199/200\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 6.4696 - val_loss: 7.5608\n",
      "Epoch 200/200\n",
      "15/15 [==============================] - 1s 40ms/step - loss: 6.5138 - val_loss: 7.3969\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define MDN Gamma model\n",
    "MDN_model_ref_gamma = model_generator(n_para=3)\n",
    "#MDN_model_ref_gamma.set_weights(meta_learner.meta_model.get_weights())\n",
    "MDN_model_ref_gamma.compile(optimizer=tf.keras.optimizers.Adam(0.0001), loss=gamma_loss)\n",
    "history_gamma = MDN_model_ref_gamma.fit(train_x, train_y, epochs=200, validation_data=[test_x, test_y])\n",
    "plot_history(history_gamma, 'Regular Training, Gamma MDN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "16/16 [==============================] - 11s 81ms/step - loss: 199.0508 - val_loss: 204.0836\n",
      "Epoch 2/80\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 199.0134 - val_loss: 204.0834\n",
      "Epoch 3/80\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 198.8674 - val_loss: 204.0824\n",
      "Epoch 4/80\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 198.8008 - val_loss: 204.0806\n",
      "Epoch 5/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 198.7091 - val_loss: 204.0780\n",
      "Epoch 6/80\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 198.3481 - val_loss: 204.0742\n",
      "Epoch 7/80\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 197.6625 - val_loss: 204.0688\n",
      "Epoch 8/80\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 196.7148 - val_loss: 204.0617\n",
      "Epoch 9/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 194.7108 - val_loss: 204.0524\n",
      "Epoch 10/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 193.2623 - val_loss: 204.0403\n",
      "Epoch 11/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 189.3877 - val_loss: 204.0230\n",
      "Epoch 12/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 187.3024 - val_loss: 204.0000\n",
      "Epoch 13/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 180.2406 - val_loss: 203.9681\n",
      "Epoch 14/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 173.3111 - val_loss: 203.9115\n",
      "Epoch 15/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 165.0778 - val_loss: 203.8067\n",
      "Epoch 16/80\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 151.0415 - val_loss: 203.7129\n",
      "Epoch 17/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 136.0800 - val_loss: 203.4527\n",
      "Epoch 18/80\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 124.8568 - val_loss: 203.2299\n",
      "Epoch 19/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 118.0519 - val_loss: 202.6435\n",
      "Epoch 20/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 116.7302 - val_loss: 202.3383\n",
      "Epoch 21/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 110.7194 - val_loss: 201.2722\n",
      "Epoch 22/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 106.0071 - val_loss: 200.0372\n",
      "Epoch 23/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 104.6385 - val_loss: 197.9877\n",
      "Epoch 24/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 108.2146 - val_loss: 197.6676\n",
      "Epoch 25/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 99.7894 - val_loss: 193.7443\n",
      "Epoch 26/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 91.3851 - val_loss: 190.4097\n",
      "Epoch 27/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 91.2706 - val_loss: 184.8065\n",
      "Epoch 28/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 91.3480 - val_loss: 184.5976\n",
      "Epoch 29/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 85.5882 - val_loss: 179.1317\n",
      "Epoch 30/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 94.2629 - val_loss: 181.8022\n",
      "Epoch 31/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 82.1387 - val_loss: 181.6522\n",
      "Epoch 32/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 83.8327 - val_loss: 180.6383\n",
      "Epoch 33/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 83.9834 - val_loss: 175.6572\n",
      "Epoch 34/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 84.4004 - val_loss: 177.6387\n",
      "Epoch 35/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 79.9775 - val_loss: 174.9171\n",
      "Epoch 36/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 79.0573 - val_loss: 175.4850\n",
      "Epoch 37/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 79.8089 - val_loss: 170.8452\n",
      "Epoch 38/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 82.9563 - val_loss: 172.6571\n",
      "Epoch 39/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 73.8726 - val_loss: 182.2621\n",
      "Epoch 40/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 76.9779 - val_loss: 185.1517\n",
      "Epoch 41/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 71.4150 - val_loss: 187.8950\n",
      "Epoch 42/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 78.0032 - val_loss: 191.2340\n",
      "Epoch 43/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 74.4184 - val_loss: 187.3640\n",
      "Epoch 44/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 71.5035 - val_loss: 183.0294\n",
      "Epoch 45/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 72.8803 - val_loss: 174.5212\n",
      "Epoch 46/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 75.6587 - val_loss: 183.4924\n",
      "Epoch 47/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 75.4433 - val_loss: 178.2094\n",
      "Epoch 48/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 74.8092 - val_loss: 170.6925\n",
      "Epoch 49/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 69.6511 - val_loss: 164.0108\n",
      "Epoch 50/80\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 70.8749 - val_loss: 171.5886\n",
      "Epoch 51/80\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 73.7552 - val_loss: 157.9875\n",
      "Epoch 52/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 74.7622 - val_loss: 150.5840\n",
      "Epoch 53/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 70.2043 - val_loss: 154.1671\n",
      "Epoch 54/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 71.3373 - val_loss: 152.0017\n",
      "Epoch 55/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 64.5776 - val_loss: 154.7435\n",
      "Epoch 56/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 71.8911 - val_loss: 165.6083\n",
      "Epoch 57/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 65.9628 - val_loss: 160.4375\n",
      "Epoch 58/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 65.5137 - val_loss: 144.2306\n",
      "Epoch 59/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 66.3581 - val_loss: 135.9258\n",
      "Epoch 60/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 66.1108 - val_loss: 154.1718\n",
      "Epoch 61/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 70.7209 - val_loss: 146.5769\n",
      "Epoch 62/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 65.2733 - val_loss: 125.1457\n",
      "Epoch 63/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 68.8953 - val_loss: 129.2919\n",
      "Epoch 64/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 67.9559 - val_loss: 115.3501\n",
      "Epoch 65/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 69.0139 - val_loss: 119.2241\n",
      "Epoch 66/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 64.8392 - val_loss: 120.8046\n",
      "Epoch 67/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 67.5861 - val_loss: 133.7345\n",
      "Epoch 68/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 69.0632 - val_loss: 123.7424\n",
      "Epoch 69/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 66.1617 - val_loss: 142.3206\n",
      "Epoch 70/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 64.2255 - val_loss: 147.5771\n",
      "Epoch 71/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 69.0975 - val_loss: 160.7994\n",
      "Epoch 72/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 62.6745 - val_loss: 137.9376\n",
      "Epoch 73/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 67.1258 - val_loss: 161.2673\n",
      "Epoch 74/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 64.7339 - val_loss: 151.5736\n",
      "Epoch 75/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 64.5173 - val_loss: 134.6384\n",
      "Epoch 76/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 61.0530 - val_loss: 149.2237\n",
      "Epoch 77/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 65.3801 - val_loss: 220.2211\n",
      "Epoch 78/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 63.5830 - val_loss: 155.5474\n",
      "Epoch 79/80\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 62.2006 - val_loss: 163.2845\n",
      "Epoch 80/80\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 63.1434 - val_loss: 146.8180\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define MDN Gamma Mean model\n",
    "MDN_model_ref_gamma_mean = model_generator(n_para=3)\n",
    "MDN_model_ref_gamma_mean.compile(optimizer=tf.keras.optimizers.Adam(0.0001), loss=gamma_mean_loss)\n",
    "history_gamma_mean = MDN_model_ref_gamma_mean.fit(train_x, train_y, epochs=80, validation_data=[test_x, test_y])\n",
    "plot_history(history_gamma_mean, 'Regular Training, Gamma MDN, Mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "16/16 [==============================] - 12s 100ms/step - loss: 62.5850 - val_loss: 165.7774\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 53.1651 - val_loss: 166.4678\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 45.8832 - val_loss: 160.6608\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 39.7374 - val_loss: 154.2601\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 34.3650 - val_loss: 147.1115\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 30.6276 - val_loss: 139.9658\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 27.1943 - val_loss: 133.1129\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 24.5809 - val_loss: 126.7268\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 21.9697 - val_loss: 121.3874\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 19.7469 - val_loss: 115.7959\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 18.5416 - val_loss: 109.7711\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 17.0823 - val_loss: 104.7965\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 15.7231 - val_loss: 99.9289\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 14.7437 - val_loss: 96.0820\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 13.9295 - val_loss: 91.5142\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 13.0078 - val_loss: 86.6114\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 12.5275 - val_loss: 81.4776\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 11.7764 - val_loss: 74.9445\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 11.3556 - val_loss: 68.8137\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 10.8481 - val_loss: 64.3833\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 10.3452 - val_loss: 59.0142\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 10.0550 - val_loss: 54.1462\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 9.7055 - val_loss: 49.0115\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 9.3824 - val_loss: 44.0658\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 9.0454 - val_loss: 41.1914\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 8.9486 - val_loss: 37.1306\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 8.6226 - val_loss: 33.3561\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 8.4663 - val_loss: 29.2278\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 8.2817 - val_loss: 25.7573\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 8.1138 - val_loss: 24.4140\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 8.0875 - val_loss: 23.7046\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 7.8408 - val_loss: 20.2186\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 7.8681 - val_loss: 18.8261\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 7.6309 - val_loss: 17.9323\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 7.5510 - val_loss: 17.5060\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 7.4715 - val_loss: 14.6634\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 7.4138 - val_loss: 13.4154\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 7.3431 - val_loss: 11.9695\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 7.2240 - val_loss: 11.1076\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 7.2418 - val_loss: 10.3974\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 7.1553 - val_loss: 10.1356\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 7.1064 - val_loss: 10.3202\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 7.0635 - val_loss: 10.2547\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 6.9760 - val_loss: 10.2323\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.9576 - val_loss: 9.1654\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.9279 - val_loss: 7.8602\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 6.8878 - val_loss: 7.5688\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.9174 - val_loss: 8.7219\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 6.8420 - val_loss: 8.7246\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.7761 - val_loss: 8.7443\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.7602 - val_loss: 8.5701\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.8073 - val_loss: 8.6944\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.7645 - val_loss: 9.0998\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.6848 - val_loss: 8.6405\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.8173 - val_loss: 8.5816\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.6549 - val_loss: 8.1975\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.6093 - val_loss: 7.3537\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 1s 45ms/step - loss: 6.6750 - val_loss: 7.3043\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.6149 - val_loss: 7.1716\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 6.5870 - val_loss: 7.2602\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 6.5758 - val_loss: 7.7315\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 6.6193 - val_loss: 7.3886\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.5519 - val_loss: 7.4137\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 6.6087 - val_loss: 7.5898\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.5528 - val_loss: 7.7438\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.5279 - val_loss: 8.3654\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.5445 - val_loss: 8.4943\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.5252 - val_loss: 7.6869\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.5621 - val_loss: 7.9406\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.5241 - val_loss: 7.6641\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.4981 - val_loss: 7.8875\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.5174 - val_loss: 7.5881\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.5019 - val_loss: 7.8673\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 6.5165 - val_loss: 7.3889\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.4994 - val_loss: 9.3725\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.4807 - val_loss: 10.2038\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 6.4575 - val_loss: 9.9656\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.4750 - val_loss: 9.4409\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 6.4589 - val_loss: 9.1882\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.4841 - val_loss: 8.2936\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 6.4815 - val_loss: 7.4623\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.4426 - val_loss: 6.8944\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.4333 - val_loss: 6.7733\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 6.4956 - val_loss: 6.6814\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 6.4909 - val_loss: 6.8926\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.4886 - val_loss: 7.4573\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.4401 - val_loss: 7.2678\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 6.4318 - val_loss: 7.3283\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.4863 - val_loss: 7.0196\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.4686 - val_loss: 6.8070\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 6.4331 - val_loss: 6.9608\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 6.4645 - val_loss: 6.9273\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 6.4267 - val_loss: 7.0962\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.4321 - val_loss: 7.1785\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.4663 - val_loss: 6.9852\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.4529 - val_loss: 7.8083\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.5436 - val_loss: 7.7478\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.5070 - val_loss: 7.7521\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.4535 - val_loss: 7.3263\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 6.4588 - val_loss: 6.8920\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 6.4297 - val_loss: 6.7623\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 6.4287 - val_loss: 6.6668\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 6.4412 - val_loss: 6.8473\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 6.4587 - val_loss: 6.8195\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 6.3858 - val_loss: 6.7614\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.4023 - val_loss: 6.6953\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.4182 - val_loss: 6.6167\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.3976 - val_loss: 6.7051\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 6.4288 - val_loss: 6.8092\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.4418 - val_loss: 6.7904\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 6.3851 - val_loss: 6.8542\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.4108 - val_loss: 6.6774\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.4056 - val_loss: 6.8222\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.3812 - val_loss: 7.0165\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.3916 - val_loss: 7.5773\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.4004 - val_loss: 7.1586\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 6.3787 - val_loss: 7.2015\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.3607 - val_loss: 7.0325\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.3773 - val_loss: 7.0360\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.4041 - val_loss: 7.1695\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.3994 - val_loss: 7.1140\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.3944 - val_loss: 6.8499\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 6.3892 - val_loss: 6.7044\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.4035 - val_loss: 6.6460\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.3663 - val_loss: 6.6253\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.3872 - val_loss: 6.6102\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.3927 - val_loss: 6.6471\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.3829 - val_loss: 6.6823\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.3635 - val_loss: 6.6028\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.3792 - val_loss: 6.6871\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.4167 - val_loss: 6.8471\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.3827 - val_loss: 6.8505\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.4288 - val_loss: 7.5574\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.4338 - val_loss: 7.1866\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.4031 - val_loss: 7.1277\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.3758 - val_loss: 6.9698\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 6.3672 - val_loss: 6.6341\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 6.4117 - val_loss: 6.7070\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 6.3884 - val_loss: 6.7365\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 6.3933 - val_loss: 6.6902\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 6.4026 - val_loss: 6.5948\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 6.3628 - val_loss: 6.5952\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.3828 - val_loss: 6.7869\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.3705 - val_loss: 6.9005\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.3985 - val_loss: 7.2202\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.3706 - val_loss: 6.8687\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.3755 - val_loss: 6.7878\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.3411 - val_loss: 6.7990\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.3700 - val_loss: 6.6929\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.3555 - val_loss: 6.7095\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.3701 - val_loss: 6.7425\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.3519 - val_loss: 6.5914\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.3576 - val_loss: 6.5838\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.3701 - val_loss: 6.6012\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.3661 - val_loss: 6.6887\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.3770 - val_loss: 6.8251\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.3706 - val_loss: 7.1590\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 6.3639 - val_loss: 7.4775\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.3592 - val_loss: 8.1331\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.3510 - val_loss: 8.1921\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 37ms/step - loss: 6.3449 - val_loss: 7.7996\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.3529 - val_loss: 7.4890\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.3679 - val_loss: 7.3364\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.3836 - val_loss: 7.4411\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 6.3841 - val_loss: 8.2016\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 1s 43ms/step - loss: 6.3912 - val_loss: 8.0978\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 6.3787 - val_loss: 8.2480\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 6.3383 - val_loss: 7.8294\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 6.3614 - val_loss: 7.4916\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 6.3533 - val_loss: 7.5388\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 6.3463 - val_loss: 7.9062\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.3478 - val_loss: 7.3497\n",
      "Epoch 173/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3401 - val_loss: 7.2393\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3483 - val_loss: 7.2896\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.3419 - val_loss: 7.5400\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3476 - val_loss: 7.8890\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3289 - val_loss: 7.7041\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 6.3390 - val_loss: 7.6812\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 6.3571 - val_loss: 7.1220\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3452 - val_loss: 7.0874\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3494 - val_loss: 6.8593\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3581 - val_loss: 6.7186\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3508 - val_loss: 6.6806\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 6.3637 - val_loss: 6.7519\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3633 - val_loss: 7.1467\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3385 - val_loss: 7.2738\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3250 - val_loss: 7.4529\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3303 - val_loss: 9.2516\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3484 - val_loss: 7.3631\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 6.3479 - val_loss: 7.0081\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3383 - val_loss: 7.0682\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3486 - val_loss: 6.7820\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3342 - val_loss: 7.1753\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3483 - val_loss: 7.0631\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3398 - val_loss: 7.2043\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3270 - val_loss: 8.7720\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3326 - val_loss: 9.0416\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 6.3321 - val_loss: 8.3647\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3348 - val_loss: 7.5308\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.3146 - val_loss: 7.0416\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define MDN Exponentialmodel\n",
    "MDN_model_ref_exponential = model_generator(n_para=2)\n",
    "MDN_model_ref_exponential.compile(optimizer=tf.keras.optimizers.Adam(0.0001), loss=exponential_loss)\n",
    "history_exponential = MDN_model_ref_exponential.fit(train_x, train_y, epochs=200, validation_data=[test_x, test_y])\n",
    "plot_history(history_exponential, 'Regular Training, Exponential MDN, Likelihood')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MAE between mean of MD and Y is not a stable loss to track."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Debug Meta Learning Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define necessary tool functions\n",
    "components = 100\n",
    "no_parameters = 3\n",
    "data = [g_data, m_data]\n",
    "lats_lons = [G_lats, G_lons, M_lats, M_lons]\n",
    "task_dim = 3\n",
    "test_proportion = 0.5\n",
    "n_lag = 10\n",
    "\n",
    "MDN_model = model_generator(n_para=no_parameters)\n",
    "\n",
    "# define TaskExtractor\n",
    "\n",
    "taskextractor = TaskExtractor(data, lats_lons, task_dim, test_proportion, n_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(probdownscale.MetaTrain)\n",
    "from probdownscale.MetaTrain import MetaSGD\n",
    "# define meta learner\n",
    "meta_optimizer = tf.keras.optimizers.Adam(0.0001)\n",
    "inner_step = 1\n",
    "inner_optimizer = tf.keras.optimizers.Adam(0.0001)\n",
    "\n",
    "meta_learner = MetaSGD(MDN_model_ref_gamma, gamma_loss,  meta_optimizer, inner_step, inner_optimizer, taskextractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 20  Basic training step:  1 / 8 loss:  6.619729\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 20  Basic training step:  2 / 8 loss:  6.5246787\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 20  Basic training step:  3 / 8 loss:  6.4987016\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 20  Basic training step:  4 / 8 loss:  6.3961782\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 20  Basic training step:  5 / 8 loss:  6.333024\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 20  Basic training step:  6 / 8 loss:  6.316188\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 20  Basic training step:  7 / 8 loss:  6.2540045\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 20  Basic training step:  8 / 8 loss:  6.3044386\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 20 Bootstrap training step: 1 / 10 loss:  6.2032895\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 20 Bootstrap training step: 2 / 10 loss:  6.174578\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 20 Bootstrap training step: 3 / 10 loss:  6.2345\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 20 Bootstrap training step: 4 / 10 loss:  6.1656513\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 20 Bootstrap training step: 5 / 10 loss:  6.0984774\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 20 Bootstrap training step: 6 / 10 loss:  6.178031\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 20 Bootstrap training step: 7 / 10 loss:  6.17578\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 20 Bootstrap training step: 8 / 10 loss:  6.1675024\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 20 Bootstrap training step: 9 / 10 loss:  6.1414495\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 1 / 20 Bootstrap training step: 10 / 10 loss:  6.1831217\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 2 / 20  Basic training step:  1 / 8 loss:  6.1599035\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 2 / 20  Basic training step:  2 / 8 loss:  6.1223326\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 2 / 20  Basic training step:  3 / 8 loss:  6.138431\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 2 / 20  Basic training step:  4 / 8 loss:  6.178168\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 2 / 20  Basic training step:  5 / 8 loss:  6.1177206\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 2 / 20  Basic training step:  6 / 8 loss:  6.099775\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 2 / 20  Basic training step:  7 / 8 loss:  6.12977\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 2 / 20  Basic training step:  8 / 8 loss:  6.149394\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 2 / 20 Bootstrap training step: 1 / 10 loss:  6.060315\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 2 / 20 Bootstrap training step: 2 / 10 loss:  6.119212\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 2 / 20 Bootstrap training step: 3 / 10 loss:  6.1167006\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 2 / 20 Bootstrap training step: 4 / 10 loss:  6.173805\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 2 / 20 Bootstrap training step: 5 / 10 loss:  6.0056887\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 2 / 20 Bootstrap training step: 6 / 10 loss:  6.1168046\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 2 / 20 Bootstrap training step: 7 / 10 loss:  6.055736\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 2 / 20 Bootstrap training step: 8 / 10 loss:  6.084133\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 2 / 20 Bootstrap training step: 9 / 10 loss:  6.086416\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 2 / 20 Bootstrap training step: 10 / 10 loss:  6.0559883\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 3 / 20  Basic training step:  1 / 8 loss:  6.1055555\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 3 / 20  Basic training step:  2 / 8 loss:  6.084421\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 3 / 20  Basic training step:  3 / 8 loss:  6.1250243\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 3 / 20  Basic training step:  4 / 8 loss:  6.1384315\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 3 / 20  Basic training step:  5 / 8 loss:  6.101691\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 3 / 20  Basic training step:  6 / 8 loss:  6.048092\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 3 / 20  Basic training step:  7 / 8 loss:  6.052265\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 3 / 20  Basic training step:  8 / 8 loss:  6.0628304\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 3 / 20 Bootstrap training step: 1 / 10 loss:  5.998023\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 3 / 20 Bootstrap training step: 2 / 10 loss:  6.126237\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 3 / 20 Bootstrap training step: 3 / 10 loss:  6.026951\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 3 / 20 Bootstrap training step: 4 / 10 loss:  6.021344\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 3 / 20 Bootstrap training step: 5 / 10 loss:  6.052909\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 3 / 20 Bootstrap training step: 6 / 10 loss:  6.040908\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 3 / 20 Bootstrap training step: 7 / 10 loss:  6.1044664\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 3 / 20 Bootstrap training step: 8 / 10 loss:  6.0828056\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 3 / 20 Bootstrap training step: 9 / 10 loss:  6.0549955\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 3 / 20 Bootstrap training step: 10 / 10 loss:  6.023281\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 4 / 20  Basic training step:  1 / 8 loss:  6.035886\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 4 / 20  Basic training step:  2 / 8 loss:  6.0749536\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 4 / 20  Basic training step:  3 / 8 loss:  6.079449\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 4 / 20  Basic training step:  4 / 8 loss:  6.102263\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 4 / 20  Basic training step:  5 / 8 loss:  6.0309324\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 4 / 20  Basic training step:  6 / 8 loss:  5.996386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 4 / 20  Basic training step:  7 / 8 loss:  6.076075\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 4 / 20  Basic training step:  8 / 8 loss:  6.0605016\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 4 / 20 Bootstrap training step: 1 / 10 loss:  6.020775\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 4 / 20 Bootstrap training step: 2 / 10 loss:  5.982307\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 4 / 20 Bootstrap training step: 3 / 10 loss:  6.007864\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 4 / 20 Bootstrap training step: 4 / 10 loss:  6.025493\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 4 / 20 Bootstrap training step: 5 / 10 loss:  6.0041146\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 4 / 20 Bootstrap training step: 6 / 10 loss:  6.0236807\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 4 / 20 Bootstrap training step: 7 / 10 loss:  6.0606256\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 4 / 20 Bootstrap training step: 8 / 10 loss:  6.0165777\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 4 / 20 Bootstrap training step: 9 / 10 loss:  5.9859834\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 4 / 20 Bootstrap training step: 10 / 10 loss:  5.9894304\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 5 / 20  Basic training step:  1 / 8 loss:  6.036683\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 5 / 20  Basic training step:  2 / 8 loss:  6.0018296\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 5 / 20  Basic training step:  3 / 8 loss:  5.991347\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 5 / 20  Basic training step:  4 / 8 loss:  6.069484\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 5 / 20  Basic training step:  5 / 8 loss:  6.0381823\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 5 / 20  Basic training step:  6 / 8 loss:  5.9813914\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 5 / 20  Basic training step:  7 / 8 loss:  6.0172796\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 5 / 20  Basic training step:  8 / 8 loss:  6.0194063\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 5 / 20 Bootstrap training step: 1 / 10 loss:  5.9734735\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 5 / 20 Bootstrap training step: 2 / 10 loss:  5.9906235\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 5 / 20 Bootstrap training step: 3 / 10 loss:  6.0297823\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 5 / 20 Bootstrap training step: 4 / 10 loss:  6.041493\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 5 / 20 Bootstrap training step: 5 / 10 loss:  6.0316706\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 5 / 20 Bootstrap training step: 6 / 10 loss:  5.9692144\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 5 / 20 Bootstrap training step: 7 / 10 loss:  5.983445\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 5 / 20 Bootstrap training step: 8 / 10 loss:  5.9551497\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 5 / 20 Bootstrap training step: 9 / 10 loss:  5.9490976\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 5 / 20 Bootstrap training step: 10 / 10 loss:  5.9218397\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 6 / 20  Basic training step:  1 / 8 loss:  5.999715\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 6 / 20  Basic training step:  2 / 8 loss:  5.9968348\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 6 / 20  Basic training step:  3 / 8 loss:  5.98084\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 6 / 20  Basic training step:  4 / 8 loss:  6.0602646\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 6 / 20  Basic training step:  5 / 8 loss:  6.0224924\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 6 / 20  Basic training step:  6 / 8 loss:  5.9482093\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 6 / 20  Basic training step:  7 / 8 loss:  6.021134\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 6 / 20  Basic training step:  8 / 8 loss:  5.996594\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 6 / 20 Bootstrap training step: 1 / 10 loss:  6.069604\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 6 / 20 Bootstrap training step: 2 / 10 loss:  5.966018\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 6 / 20 Bootstrap training step: 3 / 10 loss:  6.0030003\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 6 / 20 Bootstrap training step: 4 / 10 loss:  5.9409866\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 6 / 20 Bootstrap training step: 5 / 10 loss:  5.9863496\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 6 / 20 Bootstrap training step: 6 / 10 loss:  6.015991\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 6 / 20 Bootstrap training step: 7 / 10 loss:  5.9856424\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 6 / 20 Bootstrap training step: 8 / 10 loss:  5.997899\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 6 / 20 Bootstrap training step: 9 / 10 loss:  5.9164205\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 6 / 20 Bootstrap training step: 10 / 10 loss:  5.86753\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 7 / 20  Basic training step:  1 / 8 loss:  5.997257\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 7 / 20  Basic training step:  2 / 8 loss:  6.012009\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 7 / 20  Basic training step:  3 / 8 loss:  6.0099416\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 7 / 20  Basic training step:  4 / 8 loss:  6.0355783\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 7 / 20  Basic training step:  5 / 8 loss:  5.9824605\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 7 / 20  Basic training step:  6 / 8 loss:  5.9050045\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 7 / 20  Basic training step:  7 / 8 loss:  5.994412\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 7 / 20  Basic training step:  8 / 8 loss:  5.983668\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 7 / 20 Bootstrap training step: 1 / 10 loss:  5.9119997\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 7 / 20 Bootstrap training step: 2 / 10 loss:  5.932785\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 7 / 20 Bootstrap training step: 3 / 10 loss:  5.9334435\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 7 / 20 Bootstrap training step: 4 / 10 loss:  6.054778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 7 / 20 Bootstrap training step: 5 / 10 loss:  5.988162\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 7 / 20 Bootstrap training step: 6 / 10 loss:  5.968732\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 7 / 20 Bootstrap training step: 7 / 10 loss:  5.9670806\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 7 / 20 Bootstrap training step: 8 / 10 loss:  5.9179993\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 7 / 20 Bootstrap training step: 9 / 10 loss:  6.06167\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 7 / 20 Bootstrap training step: 10 / 10 loss:  5.973663\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 8 / 20  Basic training step:  1 / 8 loss:  5.967285\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 8 / 20  Basic training step:  2 / 8 loss:  5.961506\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 8 / 20  Basic training step:  3 / 8 loss:  5.972947\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 8 / 20  Basic training step:  4 / 8 loss:  5.9864893\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 8 / 20  Basic training step:  5 / 8 loss:  5.9614906\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 8 / 20  Basic training step:  6 / 8 loss:  5.9570503\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 8 / 20  Basic training step:  7 / 8 loss:  5.9466534\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 8 / 20  Basic training step:  8 / 8 loss:  5.966432\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 8 / 20 Bootstrap training step: 1 / 10 loss:  5.9673576\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 8 / 20 Bootstrap training step: 2 / 10 loss:  5.97017\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 8 / 20 Bootstrap training step: 3 / 10 loss:  5.940217\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 8 / 20 Bootstrap training step: 4 / 10 loss:  5.944125\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 8 / 20 Bootstrap training step: 5 / 10 loss:  5.9262776\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 8 / 20 Bootstrap training step: 6 / 10 loss:  5.9712877\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 8 / 20 Bootstrap training step: 7 / 10 loss:  5.9764123\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 8 / 20 Bootstrap training step: 8 / 10 loss:  5.8658\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 8 / 20 Bootstrap training step: 9 / 10 loss:  5.8813224\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 8 / 20 Bootstrap training step: 10 / 10 loss:  5.9734116\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 9 / 20  Basic training step:  1 / 8 loss:  5.9605775\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 9 / 20  Basic training step:  2 / 8 loss:  5.9236455\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 9 / 20  Basic training step:  3 / 8 loss:  5.960571\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 9 / 20  Basic training step:  4 / 8 loss:  6.0110946\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 9 / 20  Basic training step:  5 / 8 loss:  5.962178\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 9 / 20  Basic training step:  6 / 8 loss:  5.9009595\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 9 / 20  Basic training step:  7 / 8 loss:  5.9543676\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 9 / 20  Basic training step:  8 / 8 loss:  5.9569044\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 9 / 20 Bootstrap training step: 1 / 10 loss:  5.9621153\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 9 / 20 Bootstrap training step: 2 / 10 loss:  5.9152255\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 9 / 20 Bootstrap training step: 3 / 10 loss:  5.9154205\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 9 / 20 Bootstrap training step: 4 / 10 loss:  5.91916\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 9 / 20 Bootstrap training step: 5 / 10 loss:  5.995879\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 9 / 20 Bootstrap training step: 6 / 10 loss:  5.884397\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 9 / 20 Bootstrap training step: 7 / 10 loss:  5.9335604\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 9 / 20 Bootstrap training step: 8 / 10 loss:  5.909176\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 9 / 20 Bootstrap training step: 9 / 10 loss:  5.98648\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 9 / 20 Bootstrap training step: 10 / 10 loss:  5.8967896\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 10 / 20  Basic training step:  1 / 8 loss:  5.9427214\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 10 / 20  Basic training step:  2 / 8 loss:  5.9110346\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 10 / 20  Basic training step:  3 / 8 loss:  5.9258633\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 10 / 20  Basic training step:  4 / 8 loss:  5.9916434\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 10 / 20  Basic training step:  5 / 8 loss:  5.997042\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 10 / 20  Basic training step:  6 / 8 loss:  5.910845\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 10 / 20  Basic training step:  7 / 8 loss:  5.986626\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 10 / 20  Basic training step:  8 / 8 loss:  5.946758\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 10 / 20 Bootstrap training step: 1 / 10 loss:  5.8626924\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 10 / 20 Bootstrap training step: 2 / 10 loss:  5.899894\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 10 / 20 Bootstrap training step: 3 / 10 loss:  5.9124575\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 10 / 20 Bootstrap training step: 4 / 10 loss:  5.861978\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 10 / 20 Bootstrap training step: 5 / 10 loss:  5.9372263\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 10 / 20 Bootstrap training step: 6 / 10 loss:  5.9206686\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 10 / 20 Bootstrap training step: 7 / 10 loss:  5.9482217\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 10 / 20 Bootstrap training step: 8 / 10 loss:  5.915147\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 10 / 20 Bootstrap training step: 9 / 10 loss:  5.922146\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 10 / 20 Bootstrap training step: 10 / 10 loss:  5.9191585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 11 / 20  Basic training step:  1 / 8 loss:  5.9518213\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 11 / 20  Basic training step:  2 / 8 loss:  5.9455957\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 11 / 20  Basic training step:  3 / 8 loss:  5.9173365\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 11 / 20  Basic training step:  4 / 8 loss:  5.982023\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 11 / 20  Basic training step:  5 / 8 loss:  5.953373\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 11 / 20  Basic training step:  6 / 8 loss:  5.860841\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 11 / 20  Basic training step:  7 / 8 loss:  5.922371\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 11 / 20  Basic training step:  8 / 8 loss:  5.9323025\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 11 / 20 Bootstrap training step: 1 / 10 loss:  5.864295\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 11 / 20 Bootstrap training step: 2 / 10 loss:  5.8822956\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 11 / 20 Bootstrap training step: 3 / 10 loss:  5.869512\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 11 / 20 Bootstrap training step: 4 / 10 loss:  5.8686695\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 11 / 20 Bootstrap training step: 5 / 10 loss:  5.847782\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 11 / 20 Bootstrap training step: 6 / 10 loss:  5.883958\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 11 / 20 Bootstrap training step: 7 / 10 loss:  5.996885\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 11 / 20 Bootstrap training step: 8 / 10 loss:  5.8504963\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 11 / 20 Bootstrap training step: 9 / 10 loss:  5.8833847\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 11 / 20 Bootstrap training step: 10 / 10 loss:  5.812777\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 12 / 20  Basic training step:  1 / 8 loss:  5.9578047\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 12 / 20  Basic training step:  2 / 8 loss:  5.9355607\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 12 / 20  Basic training step:  3 / 8 loss:  5.9272423\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 12 / 20  Basic training step:  4 / 8 loss:  5.9503264\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 12 / 20  Basic training step:  5 / 8 loss:  5.949244\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 12 / 20  Basic training step:  6 / 8 loss:  5.8650017\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 12 / 20  Basic training step:  7 / 8 loss:  5.9332666\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 12 / 20  Basic training step:  8 / 8 loss:  5.8980455\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 12 / 20 Bootstrap training step: 1 / 10 loss:  5.917513\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 12 / 20 Bootstrap training step: 2 / 10 loss:  5.9408364\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 12 / 20 Bootstrap training step: 3 / 10 loss:  5.912674\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 12 / 20 Bootstrap training step: 4 / 10 loss:  5.8255997\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 12 / 20 Bootstrap training step: 5 / 10 loss:  5.888141\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 12 / 20 Bootstrap training step: 6 / 10 loss:  5.9767365\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 12 / 20 Bootstrap training step: 7 / 10 loss:  5.919517\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 12 / 20 Bootstrap training step: 8 / 10 loss:  5.9284325\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 12 / 20 Bootstrap training step: 9 / 10 loss:  5.9024887\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 12 / 20 Bootstrap training step: 10 / 10 loss:  5.9246035\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 13 / 20  Basic training step:  1 / 8 loss:  5.930485\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 13 / 20  Basic training step:  2 / 8 loss:  5.8972945\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 13 / 20  Basic training step:  3 / 8 loss:  5.903598\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 13 / 20  Basic training step:  4 / 8 loss:  5.963069\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 13 / 20  Basic training step:  5 / 8 loss:  5.897238\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 13 / 20  Basic training step:  6 / 8 loss:  5.86363\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 13 / 20  Basic training step:  7 / 8 loss:  5.9152822\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 13 / 20  Basic training step:  8 / 8 loss:  5.923444\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 13 / 20 Bootstrap training step: 1 / 10 loss:  5.844489\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 13 / 20 Bootstrap training step: 2 / 10 loss:  5.89507\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 13 / 20 Bootstrap training step: 3 / 10 loss:  5.869216\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 13 / 20 Bootstrap training step: 4 / 10 loss:  5.867676\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 13 / 20 Bootstrap training step: 5 / 10 loss:  5.872739\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 13 / 20 Bootstrap training step: 6 / 10 loss:  5.901272\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 13 / 20 Bootstrap training step: 7 / 10 loss:  5.842928\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 13 / 20 Bootstrap training step: 8 / 10 loss:  5.8711314\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 13 / 20 Bootstrap training step: 9 / 10 loss:  5.8635297\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 13 / 20 Bootstrap training step: 10 / 10 loss:  5.817413\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 14 / 20  Basic training step:  1 / 8 loss:  5.9168625\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 14 / 20  Basic training step:  2 / 8 loss:  5.8796415\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 14 / 20  Basic training step:  3 / 8 loss:  5.9080615\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 14 / 20  Basic training step:  4 / 8 loss:  5.972345\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 14 / 20  Basic training step:  5 / 8 loss:  5.94583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 14 / 20  Basic training step:  6 / 8 loss:  5.8539467\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 14 / 20  Basic training step:  7 / 8 loss:  5.9098096\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 14 / 20  Basic training step:  8 / 8 loss:  5.860016\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 14 / 20 Bootstrap training step: 1 / 10 loss:  5.934077\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 14 / 20 Bootstrap training step: 2 / 10 loss:  5.867397\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 14 / 20 Bootstrap training step: 3 / 10 loss:  5.873061\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 14 / 20 Bootstrap training step: 4 / 10 loss:  5.9441833\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 14 / 20 Bootstrap training step: 5 / 10 loss:  5.8774505\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 14 / 20 Bootstrap training step: 6 / 10 loss:  5.8863816\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 14 / 20 Bootstrap training step: 7 / 10 loss:  5.9423294\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 14 / 20 Bootstrap training step: 8 / 10 loss:  5.87144\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 14 / 20 Bootstrap training step: 9 / 10 loss:  5.89253\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 14 / 20 Bootstrap training step: 10 / 10 loss:  5.8605022\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 15 / 20  Basic training step:  1 / 8 loss:  5.890703\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 15 / 20  Basic training step:  2 / 8 loss:  5.88739\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 15 / 20  Basic training step:  3 / 8 loss:  5.8675904\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 15 / 20  Basic training step:  4 / 8 loss:  5.932869\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 15 / 20  Basic training step:  5 / 8 loss:  5.91274\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 15 / 20  Basic training step:  6 / 8 loss:  5.848621\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 15 / 20  Basic training step:  7 / 8 loss:  5.877402\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 15 / 20  Basic training step:  8 / 8 loss:  5.8741236\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 15 / 20 Bootstrap training step: 1 / 10 loss:  5.852558\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 15 / 20 Bootstrap training step: 2 / 10 loss:  5.8460855\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 15 / 20 Bootstrap training step: 3 / 10 loss:  5.9122624\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 15 / 20 Bootstrap training step: 4 / 10 loss:  5.856735\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 15 / 20 Bootstrap training step: 5 / 10 loss:  5.850764\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 15 / 20 Bootstrap training step: 6 / 10 loss:  5.853673\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 15 / 20 Bootstrap training step: 7 / 10 loss:  5.8880577\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 15 / 20 Bootstrap training step: 8 / 10 loss:  5.929042\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 15 / 20 Bootstrap training step: 9 / 10 loss:  5.8418922\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 15 / 20 Bootstrap training step: 10 / 10 loss:  5.878628\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 16 / 20  Basic training step:  1 / 8 loss:  5.8824744\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 16 / 20  Basic training step:  2 / 8 loss:  5.867439\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 16 / 20  Basic training step:  3 / 8 loss:  5.8885565\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 16 / 20  Basic training step:  4 / 8 loss:  5.9284415\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 16 / 20  Basic training step:  5 / 8 loss:  5.895041\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 16 / 20  Basic training step:  6 / 8 loss:  5.8328953\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 16 / 20  Basic training step:  7 / 8 loss:  5.899282\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 16 / 20  Basic training step:  8 / 8 loss:  5.8955693\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 16 / 20 Bootstrap training step: 1 / 10 loss:  5.8313427\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 16 / 20 Bootstrap training step: 2 / 10 loss:  5.952859\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 16 / 20 Bootstrap training step: 3 / 10 loss:  5.899835\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 16 / 20 Bootstrap training step: 4 / 10 loss:  5.8760276\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 16 / 20 Bootstrap training step: 5 / 10 loss:  5.845856\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 16 / 20 Bootstrap training step: 6 / 10 loss:  5.864747\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 16 / 20 Bootstrap training step: 7 / 10 loss:  5.930114\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 16 / 20 Bootstrap training step: 8 / 10 loss:  5.891126\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 16 / 20 Bootstrap training step: 9 / 10 loss:  5.870493\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 16 / 20 Bootstrap training step: 10 / 10 loss:  5.889467\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 17 / 20  Basic training step:  1 / 8 loss:  5.873516\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 17 / 20  Basic training step:  2 / 8 loss:  5.8668504\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 17 / 20  Basic training step:  3 / 8 loss:  5.8638854\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 17 / 20  Basic training step:  4 / 8 loss:  5.8978653\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 17 / 20  Basic training step:  5 / 8 loss:  5.8957014\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 17 / 20  Basic training step:  6 / 8 loss:  5.8643675\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 17 / 20  Basic training step:  7 / 8 loss:  5.868745\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 17 / 20  Basic training step:  8 / 8 loss:  5.886848\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 17 / 20 Bootstrap training step: 1 / 10 loss:  5.8376284\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 17 / 20 Bootstrap training step: 2 / 10 loss:  5.85427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 17 / 20 Bootstrap training step: 3 / 10 loss:  5.8416934\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 17 / 20 Bootstrap training step: 4 / 10 loss:  5.8162293\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 17 / 20 Bootstrap training step: 5 / 10 loss:  5.846247\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 17 / 20 Bootstrap training step: 6 / 10 loss:  5.8492837\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 17 / 20 Bootstrap training step: 7 / 10 loss:  5.924501\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 17 / 20 Bootstrap training step: 8 / 10 loss:  5.797263\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 17 / 20 Bootstrap training step: 9 / 10 loss:  5.812398\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 17 / 20 Bootstrap training step: 10 / 10 loss:  5.8655996\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 18 / 20  Basic training step:  1 / 8 loss:  5.869881\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 18 / 20  Basic training step:  2 / 8 loss:  5.8612146\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 18 / 20  Basic training step:  3 / 8 loss:  5.8747864\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 18 / 20  Basic training step:  4 / 8 loss:  5.9021087\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 18 / 20  Basic training step:  5 / 8 loss:  5.9071426\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 18 / 20  Basic training step:  6 / 8 loss:  5.809313\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 18 / 20  Basic training step:  7 / 8 loss:  5.84896\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 18 / 20  Basic training step:  8 / 8 loss:  5.8215938\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 18 / 20 Bootstrap training step: 1 / 10 loss:  5.8551664\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 18 / 20 Bootstrap training step: 2 / 10 loss:  5.76418\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 18 / 20 Bootstrap training step: 3 / 10 loss:  5.899165\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 18 / 20 Bootstrap training step: 4 / 10 loss:  5.8591065\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 18 / 20 Bootstrap training step: 5 / 10 loss:  5.8984194\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 18 / 20 Bootstrap training step: 6 / 10 loss:  5.8764296\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 18 / 20 Bootstrap training step: 7 / 10 loss:  5.885261\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 18 / 20 Bootstrap training step: 8 / 10 loss:  5.8438745\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 18 / 20 Bootstrap training step: 9 / 10 loss:  5.770452\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 18 / 20 Bootstrap training step: 10 / 10 loss:  5.8323298\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 19 / 20  Basic training step:  1 / 8 loss:  5.8634596\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 19 / 20  Basic training step:  2 / 8 loss:  5.8478303\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 19 / 20  Basic training step:  3 / 8 loss:  5.8278403\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 19 / 20  Basic training step:  4 / 8 loss:  5.8898067\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 19 / 20  Basic training step:  5 / 8 loss:  5.902072\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 19 / 20  Basic training step:  6 / 8 loss:  5.8352404\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 19 / 20  Basic training step:  7 / 8 loss:  5.859931\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 19 / 20  Basic training step:  8 / 8 loss:  5.86114\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 19 / 20 Bootstrap training step: 1 / 10 loss:  5.948521\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 19 / 20 Bootstrap training step: 2 / 10 loss:  5.8111334\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 19 / 20 Bootstrap training step: 3 / 10 loss:  5.856183\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 19 / 20 Bootstrap training step: 4 / 10 loss:  5.8215866\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 19 / 20 Bootstrap training step: 5 / 10 loss:  5.7949\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 19 / 20 Bootstrap training step: 6 / 10 loss:  5.779219\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 19 / 20 Bootstrap training step: 7 / 10 loss:  5.822379\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 19 / 20 Bootstrap training step: 8 / 10 loss:  5.7659545\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 19 / 20 Bootstrap training step: 9 / 10 loss:  5.906304\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 19 / 20 Bootstrap training step: 10 / 10 loss:  5.8157244\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 20 / 20  Basic training step:  1 / 8 loss:  5.866596\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 20 / 20  Basic training step:  2 / 8 loss:  5.87838\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 20 / 20  Basic training step:  3 / 8 loss:  5.861842\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 20 / 20  Basic training step:  4 / 8 loss:  5.878175\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 20 / 20  Basic training step:  5 / 8 loss:  5.8791986\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 20 / 20  Basic training step:  6 / 8 loss:  5.8054595\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 20 / 20  Basic training step:  7 / 8 loss:  5.8505216\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 20 / 20  Basic training step:  8 / 8 loss:  5.8701005\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 20 / 20 Bootstrap training step: 1 / 10 loss:  5.9555283\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 20 / 20 Bootstrap training step: 2 / 10 loss:  5.8701644\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 20 / 20 Bootstrap training step: 3 / 10 loss:  5.8610954\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 20 / 20 Bootstrap training step: 4 / 10 loss:  5.874542\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 20 / 20 Bootstrap training step: 5 / 10 loss:  5.8061094\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 20 / 20 Bootstrap training step: 6 / 10 loss:  5.9015603\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 20 / 20 Bootstrap training step: 7 / 10 loss:  5.802766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 20 / 20 Bootstrap training step: 8 / 10 loss:  5.7751822\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 20 / 20 Bootstrap training step: 9 / 10 loss:  5.8418617\n",
      "Meta lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-04>\n",
      "Epoch: 20 / 20 Bootstrap training step: 10 / 10 loss:  5.8798213\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# meta train\n",
    "meta_history = meta_learner.meta_fit(20, batch_size=10, basic_train=True, bootstrap_train=True, use_test_for_meta=True, randomize=True)\n",
    "plt.plot(meta_history)\n",
    "plt.title('Meta Training History')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_weights = meta_learner.meta_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learner.meta_model.set_weights(meta_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 12s 97ms/step - loss: 5.9748 - val_loss: 6.7861\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 5.9655 - val_loss: 6.4503\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 6.0707 - val_loss: 6.3228\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 6.0438 - val_loss: nan\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 5.9490 - val_loss: nan\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 5.9490 - val_loss: nan\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 5.9713 - val_loss: nan\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 5.9675 - val_loss: nan\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 5.9840 - val_loss: nan\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 5.9684 - val_loss: nan\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 5.9785 - val_loss: nan\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 5.9973 - val_loss: nan\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 5.9683 - val_loss: nan\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 5.9822 - val_loss: nan\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 5.9136 - val_loss: 5.9033\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 5.9798 - val_loss: nan\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 5.9974 - val_loss: 5.9042\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 5.9552 - val_loss: 5.9137\n",
      "Epoch 19/30\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 6.0024 - val_loss: nan\n",
      "Epoch 20/30\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 6.0074 - val_loss: 5.9306\n",
      "Epoch 21/30\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 5.9268 - val_loss: 5.9150\n",
      "Epoch 22/30\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 5.9522 - val_loss: 5.9259\n",
      "Epoch 23/30\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 5.9727 - val_loss: nan\n",
      "Epoch 24/30\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 5.9368 - val_loss: nan\n",
      "Epoch 25/30\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 5.9643 - val_loss: nan\n",
      "Epoch 26/30\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 6.0477 - val_loss: 5.9134\n",
      "Epoch 27/30\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 6.0202 - val_loss: 5.9105\n",
      "Epoch 28/30\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 5.9434 - val_loss: 5.9153\n",
      "Epoch 29/30\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 5.9525 - val_loss: 5.9225\n",
      "Epoch 30/30\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 5.9238 - val_loss: 5.9204\n"
     ]
    }
   ],
   "source": [
    "meta_weights = meta_learner.meta_model.get_weights()\n",
    "trained_meta_model = meta_learner.meta_model\n",
    "optimizer = tf.keras.optimizers.Adam(0.000001)\n",
    "trained_meta_model.compile(optimizer=optimizer, loss=gamma_loss)\n",
    "meta_history_fine_tune = trained_meta_model.fit(train_x, train_y, epochs=30, validation_data=[test_x, test_y])\n",
    "meta_learner.meta_model.set_weights(meta_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(meta_history_fine_tune, 'fine tune history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_meta_model = meta_learner.meta_model\n",
    "untrainded_weights = trained_meta_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60745"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cum = 0\n",
    "for i in range(len(weights_trained)):\n",
    "    cum += np.sum(meta_learner.meta_model.get_weights()[i] == meta_weights[i])\n",
    "cum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inner_rate_f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-be7e5f71bb24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mbatch_dist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdistance_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcenter\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlocat\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch_locations\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0minner_rate_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'inner_rate_f' is not defined"
     ]
    }
   ],
   "source": [
    "def inner_rate_function(inner_rate, batch_size, inner_step):\n",
    "    return inner_rate/inner_step*math.log(batch_size, 20)\n",
    "\n",
    "def meta_rate_function(meta_rate, batch_locations, seen_locations, covariance_function, distance_function):\n",
    "    batch_size = len(batch_location)\n",
    "    center = np.average(list(seen_locations.keys()), weights=list(seen_locations.values()), axis=0)\n",
    "    batch_dist = np.mean([distance_function(locat, center) for locat in batch_locations])\n",
    "    \n",
    "inner_rate_f(0.01, 100, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Meta Training History')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(meta_history)\n",
    "plt.title('Meta Training History')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_24\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_148 (InputLayer)         [(None, 10, 1, 3, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv_lstm2d_72 (ConvLSTM2D)    (None, 10, 1, 2, 20  3760        ['input_148[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_lstm2d_73 (ConvLSTM2D)    (None, 10, 1, 1, 20  6480        ['conv_lstm2d_72[1][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv_lstm2d_74 (ConvLSTM2D)    (None, 1, 1, 20)     3280        ['conv_lstm2d_73[1][0]']         \n",
      "                                                                                                  \n",
      " flatten_48 (Flatten)           (None, 20)           0           ['conv_lstm2d_74[1][0]']         \n",
      "                                                                                                  \n",
      " dense_200 (Dense)              (None, 512)          10752       ['flatten_48[1][0]']             \n",
      "                                                                                                  \n",
      " input_149 (InputLayer)         [(None, 3, 3, 1)]    0           []                               \n",
      "                                                                                                  \n",
      " input_150 (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " batch_normalization_195 (Batch  (None, 512)         2048        ['dense_200[1][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 2, 2, 20)     100         ['input_149[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_196 (Batch  (None, 1)           4           ['input_150[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dense_201 (Dense)              (None, 300)          153900      ['batch_normalization_195[1][0]']\n",
      "                                                                                                  \n",
      " flatten_49 (Flatten)           (None, 80)           0           ['conv2d_24[1][0]']              \n",
      "                                                                                                  \n",
      " dense_202 (Dense)              (None, 30)           60          ['batch_normalization_196[1][0]']\n",
      "                                                                                                  \n",
      " concatenate_48 (Concatenate)   (None, 410)          0           ['dense_201[1][0]',              \n",
      "                                                                  'flatten_49[1][0]',             \n",
      "                                                                  'dense_202[1][0]']              \n",
      "                                                                                                  \n",
      " dense_203 (Dense)              (None, 128)          52608       ['concatenate_48[1][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_197 (Batch  (None, 128)         512         ['dense_203[1][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dense_204 (Dense)              (None, 128)          16512       ['batch_normalization_197[1][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_198 (Batch  (None, 128)         512         ['dense_204[1][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dense_205 (Dense)              (None, 128)          16512       ['batch_normalization_198[1][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_199 (Batch  (None, 128)         512         ['dense_205[1][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dense_206 (Dense)              (None, 9000)         1161000     ['batch_normalization_199[1][0]']\n",
      "                                                                                                  \n",
      " dense_207 (Dense)              (None, 9000)         1161000     ['batch_normalization_199[1][0]']\n",
      "                                                                                                  \n",
      " sigmas (Dense)                 (None, 9000)         1161000     ['batch_normalization_199[1][0]']\n",
      "                                                                                                  \n",
      " concatenate_49 (Concatenate)   (None, 27000)        0           ['dense_206[1][0]',              \n",
      "                                                                  'dense_207[1][0]',              \n",
      "                                                                  'sigmas[1][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,750,552\n",
      "Trainable params: 3,748,758\n",
      "Non-trainable params: 1,794\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trained_meta_model = meta_learner.meta_model\n",
    "optimizer = tf.keras.optimizers.Adam(0.0000001)\n",
    "trained_meta_model.compile(optimizer=optimizer, loss=gamma_loss)\n",
    "trained_meta_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 5.7476\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 5.7670\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 5.7426\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 5.8128\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 5.7806\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 5.8076\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 5.8419\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 5.8233\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 5.8088\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 5.7748\n"
     ]
    }
   ],
   "source": [
    "meta_history_fine_tune = trained_meta_model.fit(train_x, train_y, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.3410058e-07, 7.9987677e-07, 7.5976692e-07, ..., 1.3756335e+00,\n",
       "        1.0332919e+00, 7.1546888e-01]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_meta_model.predict([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.     ,   0.     ,   0.     , ...,   0.     , 472.80734,\n",
       "        496.06708]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_1, init_3 = init\n",
    "init_2 = np.expand_dims(test_m_data[0, :3, :3], 0)\n",
    "trained_meta_model.predict([init_1, init_2, init_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10, 1, 3, 3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 20, 1, 3, 3)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([init_1, init_1], 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_predict(model, init_data, predict_steps, l_data):\n",
    "    init_1, init_3 = init_data\n",
    "    init_2 = np.expand_dim(l_data[0], 0)\n",
    "    for i in range(predict_steps):\n",
    "        y_hat = model.predict([init_1, init_2, init_3])\n",
    "        alpha_pred, mu_pred= slice_parameter_vectors(y_hat)\n",
    "        MDN_Yhat = tfd.MixtureSameFamily(\n",
    "                mixture_distribution=tfd.Categorical(probs=alpha_pred),\n",
    "                components_distribution=tfd.Exponential(\n",
    "                    rate=mu_pred))\n",
    "        init_data.append(np.asarray(MDN_Yhat.sample())[0])\n",
    "        #print(y_hat[0,0])\n",
    "        \n",
    "    return init_data[n_lag:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array would exceed the maximum number of dimension of 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-237830305d4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msequential_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeta_history\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_prob\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-102-1206e01fc4b8>\u001b[0m in \u001b[0;36msequential_predict\u001b[1;34m(model, init_data, predict_steps, is_prob)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_lag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mtemp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mn_lag\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_prob\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array would exceed the maximum number of dimension of 1."
     ]
    }
   ],
   "source": [
    "sequential_predict(meta_history, init, 3, is_prob=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[225.64253485, 226.47699583, 228.740054  ],\n",
       "          [226.39021189, 226.69729353, 229.72138011],\n",
       "          [226.19661694, 225.8895353 , 228.90027051]]],\n",
       "\n",
       "\n",
       "        [[[251.35415386, 251.11382869, 248.66385126],\n",
       "          [254.17129411, 253.25004879, 250.52636816],\n",
       "          [253.89091522, 254.08450976, 253.41694098]]],\n",
       "\n",
       "\n",
       "        [[[230.24031419, 226.92249735, 226.54865883],\n",
       "          [230.32709773, 226.90914598, 227.75695833],\n",
       "          [228.95190645, 226.99592992, 228.60477068]]],\n",
       "\n",
       "\n",
       "        [[[187.35131558, 188.05893849, 189.74788751],\n",
       "          [190.86940306, 191.41013377, 193.27265067],\n",
       "          [193.51297543, 194.54103136, 196.92425191]]],\n",
       "\n",
       "\n",
       "        [[[203.14151383, 203.20159502, 202.60745881],\n",
       "          [204.66357065, 206.15892472, 206.85319625],\n",
       "          [205.52473438, 208.11490125, 210.13095897]]],\n",
       "\n",
       "\n",
       "        [[[195.85355902, 194.74539444, 194.17128528],\n",
       "          [203.91778949, 201.80827173, 200.39970201],\n",
       "          [211.35450571, 208.32374385, 206.20755041]]],\n",
       "\n",
       "\n",
       "        [[[189.06584828, 189.66332214, 190.70472883],\n",
       "          [190.16066109, 190.15064776, 191.99647585],\n",
       "          [190.80152793, 191.03851464, 193.69210096]]],\n",
       "\n",
       "\n",
       "        [[[374.2527365 , 381.61602138, 398.57226802],\n",
       "          [382.95115853, 389.7603601 , 406.35612041],\n",
       "          [402.04362527, 402.87141178, 425.82242526]]],\n",
       "\n",
       "\n",
       "        [[[380.7394079 , 392.78902359, 403.99750342],\n",
       "          [371.61374266, 379.99840655, 390.15212731],\n",
       "          [359.70431479, 369.44414453, 378.47634973]]],\n",
       "\n",
       "\n",
       "        [[[290.12143352, 276.81678853, 269.27326089],\n",
       "          [305.02156872, 289.70754088, 278.87957606],\n",
       "          [313.49301737, 305.65575947, 295.46198418]]]]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Downscale_env",
   "language": "python",
   "name": "downscale_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
