{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import os\n",
    "import sys\n",
    "from importlib import reload\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import probdownscale\n",
    "reload(probdownscale.TaskExtractor)\n",
    "reload(probdownscale.MetaTrain)\n",
    "from probdownscale.MetaTrain import MetaSGD\n",
    "\n",
    "from probdownscale.TaskExtractor import TaskExtractor\n",
    "import math\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow_probability import distributions as tfd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Debug TaskExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\96349\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\96349\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \n",
      "C:\\Users\\96349\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\96349\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "C:\\Users\\96349\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\ipykernel_launcher.py:21: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "C:\\Users\\96349\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\ipykernel_launcher.py:22: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    }
   ],
   "source": [
    "file_path_g_05 = r'C:\\Users\\96349\\Documents\\Downscale_data\\MERRA2\\G5NR_aerosol_variables_over_MiddleEast_daily_20050516-20060515.nc'\n",
    "file_path_g_06 =  r'C:\\Users\\96349\\Documents\\Downscale_data\\MERRA2\\G5NR_aerosol_variables_over_MiddleEast_daily_20060516-20070515.nc'\n",
    "file_path_m = r'C:\\Users\\96349\\Documents\\Downscale_data\\MERRA2\\MERRA2_aerosol_variables_over_MiddleEast_daily_20000516-20180515.nc'\n",
    "target_var = 'BCSMASS'\n",
    "\n",
    "# read data\n",
    "g05_data = nc.Dataset(file_path_g_05)\n",
    "g06_data = nc.Dataset(file_path_g_06)\n",
    "m_data_nc = nc.Dataset(file_path_m)\n",
    "\n",
    "# define lat&lon of MERRA, G5NR and mete\n",
    "M_lons = m_data_nc.variables['lon'][:]\n",
    "# self.M_lons = (M_lons-M_lons.mean())/M_lons.std()\n",
    "M_lats = m_data_nc.variables['lat'][:]\n",
    "# self.M_lats = (M_lats-M_lats.mean())/M_lats.std()\n",
    "G_lons = g05_data.variables['lon'][:]\n",
    "# self.G_lons = (G_lons-G_lons.mean())/G_lons.std()\n",
    "G_lats = g05_data.variables['lat'][:]\n",
    "\n",
    "# extract target data\n",
    "g_data = np.concatenate((g05_data.variables[target_var][:], g06_data.variables[target_var][:]), axis=0)\n",
    "m_data = m_data_nc.variables[target_var][5*365:7*365]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [g_data, m_data]\n",
    "lats_lons = [G_lats, G_lons, M_lats, M_lons]\n",
    "task_dim = 3\n",
    "test_proportion = 0.3\n",
    "n_lag = 10\n",
    "taskextractor = TaskExtractor(data, lats_lons, task_dim, test_proportion, n_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y, locations = taskextractor.get_random_tasks(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y, location = taskextractor._get_random_task(is_random=False, record=False, lat_lon=(13.5625, 49.375))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = taskextractor.get_grid_locations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y, locations = taskextractor.get_random_tasks(locations=locations[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10//3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow_probability import distributions as tfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the last channel is the comonents\n",
    "alpha = np.random.rand(3,2,5)\n",
    "alpha = alpha/alpha.sum()\n",
    "mu = np.random.rand(3, 2, 5)\n",
    "test_md = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=alpha),\n",
    "        components_distribution=tfd.Exponential(\n",
    "        rate=mu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0.95185266, 1.00110027, 1.33222622])>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_like = test_md.log_prob(tf.reduce_mean(mu, axis=-1))\n",
    "-tf.reduce_mean(log_like, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float64, numpy=\n",
       "array([[0.38051166, 0.57145636],\n",
       "       [0.62442875, 0.36601753],\n",
       "       [0.28161602, 0.40978898]])>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(mu, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =  np.random.rand(3,3,3)\n",
    "#a = (a - a.min())/(a.max() - a.min())\n",
    "a = a/a.sum()\n",
    "a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnelu(input):\n",
    "    return tf.add(tf.constant(1, dtype=tf.float32), tf.nn.elu(input))\n",
    "\n",
    "components = 3\n",
    "no_parameters = 2\n",
    "def slice_parameter_vectors(parameter_vector):\n",
    "    return [parameter_vector[:, i * task_dim*task_dim*components:(i + 1) *task_dim*task_dim*components] for i in range(no_parameters)]\n",
    "\n",
    "def gnll_loss(y, parameter_vector):\n",
    "    alpha, mu = slice_parameter_vectors(parameter_vector)  # Unpack parameter vectors\n",
    "    #print(alpha.shape, mu.shape)\n",
    "    alpha1 = tf.reshape(alpha, (tf.shape(alpha)[0], task_dim, task_dim, components))\n",
    "    mu1 = tf.reshape(mu, (tf.shape(mu)[0], task_dim, task_dim, components))\n",
    "    #print(alpha1.shape, mu1.shape)\n",
    "    gm = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=alpha1),\n",
    "        components_distribution=tfd.Exponential(\n",
    "        rate=mu1)\n",
    "    )\n",
    "\n",
    "    log_likelihood = gm.log_prob(y)  # Evaluate log-probability of y\n",
    "    \n",
    "    return -tf.reduce_mean(log_likelihood, axis=-1)\n",
    "\n",
    "tf.keras.utils.get_custom_objects().update({'nnelu': layers.Activation(nnelu)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 10, 1, 10,   0           []                               \n",
      "                                10)]                                                              \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 10, 10, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " conv_lstm2d_1 (ConvLSTM2D)     (None, 1, 9, 20)     4880        ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 9, 9, 20)     100         ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 1)           4           ['input_6[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 180)          0           ['conv_lstm2d_1[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 1620)         0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 30)           60          ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 1830)         0           ['flatten_2[0][0]',              \n",
      "                                                                  'flatten_3[0][0]',              \n",
      "                                                                  'dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 10000)        18310000    ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 10000)        18310000    ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 20000)        0           ['dense_4[0][0]',                \n",
      "                                                                  'dense_5[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 36,625,044\n",
      "Trainable params: 36,625,042\n",
      "Non-trainable params: 2\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# MDN model\n",
    "# input dim (time, channel, rows, cols)\n",
    "input1 = layers.Input(shape=(n_lag, 1, task_dim, task_dim)) \n",
    "input2 = layers.Input(shape=(task_dim, task_dim, 1))\n",
    "input3 = layers.Input(shape=(1))\n",
    "\n",
    "X = layers.ConvLSTM2D(filters=20, kernel_size=(1,2), activation='tanh', return_sequences=False)(input1)\n",
    "X = layers.Flatten()(X)\n",
    "\n",
    "X1 = layers.Conv2D(20, (2,2), activation='tanh')(input2)\n",
    "X1 = layers.Flatten()(X1)\n",
    "X2 = layers.BatchNormalization()(input3)\n",
    "X2 = layers.Dense(30, activation='relu')(X2)\n",
    "\n",
    "X = layers.Concatenate()([X, X1, X2])\n",
    "\n",
    "alphas = layers.Dense(components*task_dim*task_dim, activation=\"softmax\")(X)\n",
    "#alphas = layers.Reshape((task_dim, task_dim, components), name=\"alphas\")(alphas)\n",
    "mus = layers.Dense(components*task_dim*task_dim, activation=\"nnelu\")(X)\n",
    "#mus = layers.Reshape((task_dim, task_dim, components) ,name=\"mus\")(mus)\n",
    "#sigmas = layers.Dense(components, activation=\"nnelu\", name=\"sigmas\")(X)\n",
    "output = layers.Concatenate()([alphas, mus])\n",
    "MDN_model = Model([input1, input2, input3], output)\n",
    "MDN_model.compile(optimizer='adam', loss=gnll_loss)\n",
    "MDN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 7s 244ms/step - loss: -0.0445\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 4s 257ms/step - loss: -0.4285\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 4s 263ms/step - loss: -1.3516\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 4s 264ms/step - loss: -2.3884\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 4s 264ms/step - loss: -3.0921\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 4s 260ms/step - loss: -3.4926\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 4s 264ms/step - loss: -3.7561\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 4s 262ms/step - loss: -3.9519\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 4s 262ms/step - loss: -4.1115\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 4s 263ms/step - loss: -4.2492\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 4s 280ms/step - loss: -4.3721\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 4s 265ms/step - loss: -4.4835\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 4s 263ms/step - loss: -4.5859\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 4s 262ms/step - loss: -4.6810\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 4s 262ms/step - loss: -4.7697\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 4s 264ms/step - loss: -4.8527\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 4s 263ms/step - loss: -4.9310\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 4s 266ms/step - loss: -5.0049\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 4s 263ms/step - loss: -5.0751\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 4s 262ms/step - loss: -5.1419\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 4s 269ms/step - loss: -5.2057\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 4s 264ms/step - loss: -5.2667\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 4s 265ms/step - loss: -5.3252\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 4s 263ms/step - loss: -5.3812\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 5s 281ms/step - loss: -5.4351\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 4s 269ms/step - loss: -5.4870\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 4s 262ms/step - loss: -5.5369\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 4s 264ms/step - loss: -5.5851\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 4s 261ms/step - loss: -5.6317\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 4s 262ms/step - loss: -5.6767\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 4s 263ms/step - loss: -5.7203\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 4s 261ms/step - loss: -5.7626\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 4s 262ms/step - loss: -5.8035\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 4s 262ms/step - loss: -5.8432\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 4s 264ms/step - loss: -5.8819\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 4s 263ms/step - loss: -5.9193\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 4s 263ms/step - loss: -5.9558\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 4s 264ms/step - loss: -5.9914\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 4s 265ms/step - loss: -6.0260\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 4s 264ms/step - loss: -6.0597\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 4s 270ms/step - loss: -6.0926\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 4s 263ms/step - loss: -6.1247\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 4s 261ms/step - loss: -6.1561\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 4s 264ms/step - loss: -6.1866\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 5s 289ms/step - loss: -6.2166\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 5s 284ms/step - loss: -6.2458\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 4s 274ms/step - loss: -6.2744\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 4s 268ms/step - loss: -6.3025\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 4s 276ms/step - loss: -6.3299\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 4s 271ms/step - loss: -6.3568\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 4s 271ms/step - loss: -6.3831\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 4s 269ms/step - loss: -6.4088\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 5s 300ms/step - loss: -6.4341\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 5s 291ms/step - loss: -6.4590\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 4s 272ms/step - loss: -6.4834\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 4s 280ms/step - loss: -6.5073\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 4s 275ms/step - loss: -6.5308\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 5s 290ms/step - loss: -6.5539\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 4s 263ms/step - loss: -6.5766\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 4s 262ms/step - loss: -6.5989\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 4s 281ms/step - loss: -6.6208\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 4s 270ms/step - loss: -6.6423\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 4s 265ms/step - loss: -6.6637\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 5s 302ms/step - loss: -6.6846\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 5s 301ms/step - loss: -6.7052\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 5s 295ms/step - loss: -6.7254\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 5s 326ms/step - loss: nan\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 5s 340ms/step - loss: nan\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 5s 341ms/step - loss: nan\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 5s 306ms/step - loss: nan\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 5s 311ms/step - loss: nan\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 5s 298ms/step - loss: nan\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 4s 259ms/step - loss: nan\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 4s 255ms/step - loss: nan\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 4s 255ms/step - loss: nan\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 4s 281ms/step - loss: nan\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 4s 264ms/step - loss: nan\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 4s 263ms/step - loss: nan\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 5s 310ms/step - loss: nan\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 4s 265ms/step - loss: nan\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 4s 274ms/step - loss: nan\n",
      "Epoch 82/100\n",
      " 5/16 [========>.....................] - ETA: 3s - loss: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-c6984a06566d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mMDN_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2957\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2959\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1854\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    505\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MDN_model.fit(train_x, train_y, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Debug Meta Learning Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define necessary tool functions\n",
    "components = 5\n",
    "no_parameters = 3\n",
    "data = [g_data, m_data]\n",
    "lats_lons = [G_lats, G_lons, M_lats, M_lons]\n",
    "task_dim = 3\n",
    "test_proportion = 0.5\n",
    "n_lag = 10\n",
    "\n",
    "def nnelu(input):\n",
    "    return tf.add(tf.constant(1, dtype=tf.float32), tf.nn.elu(input))\n",
    "\n",
    "def slice_parameter_vectors(parameter_vector):\n",
    "    return [parameter_vector[:, i * task_dim*task_dim*components:(i + 1) *task_dim*task_dim*components] for i in range(no_parameters)]\n",
    "\n",
    "def gnll_loss(y, parameter_vector):\n",
    "    alpha, mu, sigma = slice_parameter_vectors(parameter_vector)  # Unpack parameter vectors\n",
    "    #print(alpha.shape, mu.shape)\n",
    "    alpha1 = tf.reshape(alpha, (tf.shape(alpha)[0], task_dim, task_dim, components))\n",
    "    mu1 = tf.reshape(mu, (tf.shape(mu)[0], task_dim, task_dim, components))\n",
    "    sigma1 = tf.reshape(sigma,  (tf.shape(sigma)[0], task_dim, task_dim, components))\n",
    "    #print(alpha1.shape, mu1.shape)\n",
    "    gm = tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(probs=alpha1),\n",
    "        components_distribution=tfd.Gamma(\n",
    "        concentration=mu1, rate=sigma1)\n",
    "    )\n",
    "\n",
    "    log_likelihood = gm.log_prob(y)  # Evaluate log-probability of y\n",
    "    #print(log_likelihood)\n",
    "    return -tf.reduce_mean(log_likelihood, axis=-1)\n",
    "\n",
    "tf.keras.utils.get_custom_objects().update({'nnelu': layers.Activation(nnelu)})\n",
    "\n",
    "# define MDN model\n",
    "# input dim (time, channel, rows, cols)\n",
    "input1 = layers.Input(shape=(n_lag, 1, task_dim, task_dim)) \n",
    "input2 = layers.Input(shape=(task_dim, task_dim, 1))\n",
    "input3 = layers.Input(shape=(1))\n",
    "\n",
    "X = layers.ConvLSTM2D(filters=20, kernel_size=(1,2), activation='tanh', return_sequences=True)(input1)\n",
    "#X = layers.ConvLSTM2D(filters=20, kernel_size=(1,2), activation='relu', return_sequences=True)(X)\n",
    "#X = layers.ConvLSTM2D(filters=20, kernel_size=(1,1), activation='relu')(X)\n",
    "X = layers.Flatten()(X)\n",
    "X = layers.Dense(512, activation='relu')(X)\n",
    "X = layers.BatchNormalization()(X)\n",
    "X = layers.Dense(300, activation='relu')(X)\n",
    "\n",
    "X1 = layers.Conv2D(20, (2,2), activation='tanh')(input2)\n",
    "X1 = layers.Flatten()(X1)\n",
    "X2 = layers.BatchNormalization()(input3)\n",
    "X2 = layers.Dense(30, activation='relu')(X2)\n",
    "\n",
    "X = layers.Concatenate()([X, X1, X2])\n",
    "\n",
    "alphas = layers.Dense(components*task_dim*task_dim, activation=\"softmax\")(X)\n",
    "#alphas = layers.Reshape((task_dim, task_dim, components), name=\"alphas\")(alphas)\n",
    "mus = layers.Dense(components*task_dim*task_dim, activation='nnelu')(X)\n",
    "#mus = layers.Reshape((task_dim, task_dim, components) ,name=\"mus\")(mus)\n",
    "sigmas = layers.Dense(components*task_dim*task_dim, activation=\"nnelu\", name=\"sigmas\")(X)\n",
    "output = layers.Concatenate()([alphas, mus, sigmas])\n",
    "MDN_model = Model([input1, input2, input3], output)\n",
    "\n",
    "# define TaskExtractor\n",
    "\n",
    "taskextractor = TaskExtractor(data, lats_lons, task_dim, test_proportion, n_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(probdownscale.MetaTrain)\n",
    "from probdownscale.MetaTrain import MetaSGD\n",
    "# define meta learner\n",
    "meta_step = 10\n",
    "meta_optimizer = tf.keras.optimizers.RMSprop(0.1)\n",
    "inner_step = 2\n",
    "inner_optimizer = tf.keras.optimizers.SGD()\n",
    "\n",
    "meta_learner = MetaSGD(MDN_model, gnll_loss, meta_step, meta_optimizer, inner_step, inner_optimizer, taskextractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003074487147360964"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def inner_rate_function(inner_rate, batch_size, inner_step):\n",
    "    return inner_rate/inner_step*math.log(batch_size, 20)\n",
    "\n",
    "def meta_rate_function(meta_rate, batch_locations, seen_locations, covariance_function, distance_function):\n",
    "    batch_size = len(batch_location)\n",
    "    center = np.average(list(seen_locations.keys()), weights=list(seen_locations.values()), axis=0)\n",
    "    batch_dist = np.mean([distance_function(locat, center) for locat in batch_locations])\n",
    "    \n",
    "inner_rate_f(0.01, 100, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now doing bootstrap training step: 0 / 8646 loss:  -18.561356\n",
      "Now doing bootstrap training step: 1 / 8646 loss:  -17.011003\n",
      "Now doing bootstrap training step: 2 / 8646 loss:  -16.69801\n",
      "Now doing bootstrap training step: 3 / 8646 loss:  -13.284741\n",
      "Now doing bootstrap training step: 4 / 8646 loss:  -18.099634\n",
      "Now doing bootstrap training step: 5 / 8646 loss:  -18.658218\n",
      "Now doing bootstrap training step: 6 / 8646 loss:  -18.285648\n",
      "Now doing bootstrap training step: 7 / 8646 loss:  -18.578285\n",
      "Now doing bootstrap training step: 8 / 8646 loss:  -18.449034\n",
      "Now doing bootstrap training step: 9 / 8646 loss:  -18.393436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-18.561356,\n",
       " -17.011003,\n",
       " -16.69801,\n",
       " -13.284741,\n",
       " -18.099634,\n",
       " -18.658218,\n",
       " -18.285648,\n",
       " -18.578285,\n",
       " -18.449034,\n",
       " -18.393436]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_learner.meta_fit(5, basic_train=False, bootstrap_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origional lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.1>\n",
      "updated lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "(<tf.Tensor: shape=(), dtype=float32, numpy=-1.2884859>, [<tf.Tensor: shape=(), dtype=float32, numpy=-1.3128259>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.3372735>, <tf.Tensor: shape=(), dtype=float32, numpy=-1.2153584>])\n",
      "origional lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "updated lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "(<tf.Tensor: shape=(), dtype=float32, numpy=-18.776932>, [<tf.Tensor: shape=(), dtype=float32, numpy=-18.566221>, <tf.Tensor: shape=(), dtype=float32, numpy=-19.05812>, <tf.Tensor: shape=(), dtype=float32, numpy=-18.706453>])\n",
      "origional lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "updated lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "(<tf.Tensor: shape=(), dtype=float32, numpy=-17.04699>, [<tf.Tensor: shape=(), dtype=float32, numpy=-17.101952>, <tf.Tensor: shape=(), dtype=float32, numpy=-17.098255>, <tf.Tensor: shape=(), dtype=float32, numpy=-16.940762>])\n",
      "origional lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "updated lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "(<tf.Tensor: shape=(), dtype=float32, numpy=-18.117737>, [<tf.Tensor: shape=(), dtype=float32, numpy=-19.259056>, <tf.Tensor: shape=(), dtype=float32, numpy=-17.947464>, <tf.Tensor: shape=(), dtype=float32, numpy=-17.14669>])\n",
      "origional lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "updated lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "(<tf.Tensor: shape=(), dtype=float32, numpy=-18.27481>, [<tf.Tensor: shape=(), dtype=float32, numpy=-18.767473>, <tf.Tensor: shape=(), dtype=float32, numpy=-18.770298>, <tf.Tensor: shape=(), dtype=float32, numpy=-17.286661>])\n",
      "origional lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "updated lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "(<tf.Tensor: shape=(), dtype=float32, numpy=-17.247145>, [<tf.Tensor: shape=(), dtype=float32, numpy=-17.6681>, <tf.Tensor: shape=(), dtype=float32, numpy=-18.213047>, <tf.Tensor: shape=(), dtype=float32, numpy=-15.860287>])\n",
      "origional lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "updated lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "(<tf.Tensor: shape=(), dtype=float32, numpy=-18.387163>, [<tf.Tensor: shape=(), dtype=float32, numpy=-17.776957>, <tf.Tensor: shape=(), dtype=float32, numpy=-17.993114>, <tf.Tensor: shape=(), dtype=float32, numpy=-19.39142>])\n",
      "origional lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "updated lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "(<tf.Tensor: shape=(), dtype=float32, numpy=-18.57676>, [<tf.Tensor: shape=(), dtype=float32, numpy=-18.803473>, <tf.Tensor: shape=(), dtype=float32, numpy=-17.93269>, <tf.Tensor: shape=(), dtype=float32, numpy=-18.99412>])\n",
      "origional lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "updated lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "(<tf.Tensor: shape=(), dtype=float32, numpy=-19.102034>, [<tf.Tensor: shape=(), dtype=float32, numpy=-19.255472>, <tf.Tensor: shape=(), dtype=float32, numpy=-19.405415>, <tf.Tensor: shape=(), dtype=float32, numpy=-18.645212>])\n",
      "origional lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "updated lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "(<tf.Tensor: shape=(), dtype=float32, numpy=-18.7576>, [<tf.Tensor: shape=(), dtype=float32, numpy=-18.74952>, <tf.Tensor: shape=(), dtype=float32, numpy=-18.705204>, <tf.Tensor: shape=(), dtype=float32, numpy=-18.818077>])\n",
      "origional lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "updated lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "(<tf.Tensor: shape=(), dtype=float32, numpy=-18.581945>, [<tf.Tensor: shape=(), dtype=float32, numpy=-18.708513>, <tf.Tensor: shape=(), dtype=float32, numpy=-18.326471>, <tf.Tensor: shape=(), dtype=float32, numpy=-18.710848>])\n",
      "origional lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "updated lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "(<tf.Tensor: shape=(), dtype=float32, numpy=-18.83709>, [<tf.Tensor: shape=(), dtype=float32, numpy=-20.114128>, <tf.Tensor: shape=(), dtype=float32, numpy=-18.181732>, <tf.Tensor: shape=(), dtype=float32, numpy=-18.215408>])\n",
      "origional lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "updated lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "(<tf.Tensor: shape=(), dtype=float32, numpy=-18.964653>, [<tf.Tensor: shape=(), dtype=float32, numpy=-17.780287>, <tf.Tensor: shape=(), dtype=float32, numpy=-19.242025>, <tf.Tensor: shape=(), dtype=float32, numpy=-19.871647>])\n",
      "origional lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "updated lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "(<tf.Tensor: shape=(), dtype=float32, numpy=-18.989145>, [<tf.Tensor: shape=(), dtype=float32, numpy=-18.48199>, <tf.Tensor: shape=(), dtype=float32, numpy=-18.802053>, <tf.Tensor: shape=(), dtype=float32, numpy=-19.683395>])\n",
      "origional lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "updated lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "(<tf.Tensor: shape=(), dtype=float32, numpy=-19.360626>, [<tf.Tensor: shape=(), dtype=float32, numpy=-18.031796>, <tf.Tensor: shape=(), dtype=float32, numpy=-20.165024>, <tf.Tensor: shape=(), dtype=float32, numpy=-19.885061>])\n",
      "origional lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "updated lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "(<tf.Tensor: shape=(), dtype=float32, numpy=-19.216057>, [<tf.Tensor: shape=(), dtype=float32, numpy=-18.881884>, <tf.Tensor: shape=(), dtype=float32, numpy=-19.970419>, <tf.Tensor: shape=(), dtype=float32, numpy=-18.795868>])\n",
      "origional lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "updated lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "(<tf.Tensor: shape=(), dtype=float32, numpy=-18.157822>, [<tf.Tensor: shape=(), dtype=float32, numpy=-18.634666>, <tf.Tensor: shape=(), dtype=float32, numpy=-17.261572>, <tf.Tensor: shape=(), dtype=float32, numpy=-18.577227>])\n",
      "origional lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "updated lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "(<tf.Tensor: shape=(), dtype=float32, numpy=-18.727892>, [<tf.Tensor: shape=(), dtype=float32, numpy=-17.609632>, <tf.Tensor: shape=(), dtype=float32, numpy=-19.864279>, <tf.Tensor: shape=(), dtype=float32, numpy=-18.709763>])\n",
      "origional lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "updated lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "(<tf.Tensor: shape=(), dtype=float32, numpy=-19.291908>, [<tf.Tensor: shape=(), dtype=float32, numpy=-19.505013>, <tf.Tensor: shape=(), dtype=float32, numpy=-19.424973>, <tf.Tensor: shape=(), dtype=float32, numpy=-18.945742>])\n",
      "origional lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "updated lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "(<tf.Tensor: shape=(), dtype=float32, numpy=-19.246119>, [<tf.Tensor: shape=(), dtype=float32, numpy=-19.108288>, <tf.Tensor: shape=(), dtype=float32, numpy=-18.857454>, <tf.Tensor: shape=(), dtype=float32, numpy=-19.772614>])\n",
      "origional lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "updated lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "(<tf.Tensor: shape=(), dtype=float32, numpy=-18.898926>, [<tf.Tensor: shape=(), dtype=float32, numpy=-18.876114>, <tf.Tensor: shape=(), dtype=float32, numpy=-18.753956>, <tf.Tensor: shape=(), dtype=float32, numpy=-19.066706>])\n",
      "origional lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "updated lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "(<tf.Tensor: shape=(), dtype=float32, numpy=-18.625885>, [<tf.Tensor: shape=(), dtype=float32, numpy=-18.676805>, <tf.Tensor: shape=(), dtype=float32, numpy=-18.616735>, <tf.Tensor: shape=(), dtype=float32, numpy=-18.584114>])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origional lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "updated lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "(<tf.Tensor: shape=(), dtype=float32, numpy=-18.691551>, [<tf.Tensor: shape=(), dtype=float32, numpy=-18.695385>, <tf.Tensor: shape=(), dtype=float32, numpy=-18.403854>, <tf.Tensor: shape=(), dtype=float32, numpy=-18.975414>])\n",
      "origional lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "updated lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "(<tf.Tensor: shape=(), dtype=float32, numpy=-18.489832>, [<tf.Tensor: shape=(), dtype=float32, numpy=-19.902456>, <tf.Tensor: shape=(), dtype=float32, numpy=-17.601349>, <tf.Tensor: shape=(), dtype=float32, numpy=-17.96569>])\n",
      "origional lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "updated lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "(<tf.Tensor: shape=(), dtype=float32, numpy=-18.913248>, [<tf.Tensor: shape=(), dtype=float32, numpy=-19.116617>, <tf.Tensor: shape=(), dtype=float32, numpy=-18.742393>, <tf.Tensor: shape=(), dtype=float32, numpy=-18.88074>])\n",
      "origional lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "updated lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "(<tf.Tensor: shape=(), dtype=float32, numpy=-19.395033>, [<tf.Tensor: shape=(), dtype=float32, numpy=-19.754156>, <tf.Tensor: shape=(), dtype=float32, numpy=-19.394566>, <tf.Tensor: shape=(), dtype=float32, numpy=-19.036375>])\n",
      "origional lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "updated lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "(<tf.Tensor: shape=(), dtype=float32, numpy=-19.207638>, [<tf.Tensor: shape=(), dtype=float32, numpy=-19.106945>, <tf.Tensor: shape=(), dtype=float32, numpy=-18.779144>, <tf.Tensor: shape=(), dtype=float32, numpy=-19.736824>])\n",
      "origional lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "updated lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "(<tf.Tensor: shape=(), dtype=float32, numpy=-18.512877>, [<tf.Tensor: shape=(), dtype=float32, numpy=-17.574097>, <tf.Tensor: shape=(), dtype=float32, numpy=-18.689789>, <tf.Tensor: shape=(), dtype=float32, numpy=-19.274746>])\n",
      "origional lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "updated lr: <tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.01>\n",
      "(<tf.Tensor: shape=(), dtype=float32, numpy=-18.477152>, [<tf.Tensor: shape=(), dtype=float32, numpy=-18.034681>, <tf.Tensor: shape=(), dtype=float32, numpy=-18.635359>, <tf.Tensor: shape=(), dtype=float32, numpy=-18.76142>])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-149-6b34360abcd6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeta_learner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_test_for_meta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive - University of Southern California\\Desktop\\ProbDownscale\\probdownscale\\MetaTrain.py\u001b[0m in \u001b[0;36m_train_on_batch\u001b[1;34m(self, batch_size, use_test_for_meta)\u001b[0m\n\u001b[0;32m     85\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeta_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask_weights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m                     \u001b[0mY_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeta_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_Y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1094\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1096\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1097\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_keras_call_info_injected'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    450\u001b[0m     \"\"\"\n\u001b[0;32m    451\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m--> 452\u001b[1;33m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 679\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m     \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1094\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1096\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1097\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_keras_call_info_injected'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\keras\\layers\\convolutional_recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[0;32m    845\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m     return super(ConvLSTM, self).call(\n\u001b[1;32m--> 847\u001b[1;33m         inputs, mask=mask, training=training, initial_state=initial_state)\n\u001b[0m\u001b[0;32m    848\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\keras\\layers\\convolutional_recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask, training, initial_state, constants)\u001b[0m\n\u001b[0;32m    305\u001b[0m                                                \u001b[0mgo_backwards\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgo_backwards\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                                                \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m                                                input_length=timesteps)\n\u001b[0m\u001b[0;32m    308\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m       updates = [\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\keras\\backend.py\u001b[0m in \u001b[0;36mrnn\u001b[1;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask)\u001b[0m\n\u001b[0;32m   4744\u001b[0m           \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4745\u001b[0m           \u001b[0mloop_vars\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_ta\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4746\u001b[1;33m           **while_loop_kwargs)\n\u001b[0m\u001b[0;32m   4747\u001b[0m       \u001b[0mnew_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4748\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[0;32m   2793\u001b[0m                                               list(loop_vars))\n\u001b[0;32m   2794\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2795\u001b[1;33m         \u001b[0mloop_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2796\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2797\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\keras\\backend.py\u001b[0m in \u001b[0;36m_step\u001b[1;34m(time, output_ta_t, *states)\u001b[0m\n\u001b[0;32m   4728\u001b[0m         \u001b[0mcurrent_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4729\u001b[0m         output, new_states = step_function(current_input,\n\u001b[1;32m-> 4730\u001b[1;33m                                            tuple(states) + tuple(constants))\n\u001b[0m\u001b[0;32m   4731\u001b[0m         \u001b[0mflat_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4732\u001b[0m         \u001b[0mflat_new_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\keras\\layers\\convolutional_recurrent.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(inputs, states)\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     last_output, outputs, states = backend.rnn(step,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\keras\\layers\\convolutional_recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, states, training)\u001b[0m\n\u001b[0;32m    608\u001b[0m       \u001b[0mbias_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias_c\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias_o\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[0mx_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m     \u001b[0mx_f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m     \u001b[0mx_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs_c\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_c\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias_c\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\keras\\layers\\convolutional_recurrent.py\u001b[0m in \u001b[0;36minput_conv\u001b[1;34m(self, x, w, b, padding)\u001b[0m\n\u001b[0;32m    642\u001b[0m         dilation_rate=self.dilation_rate)\n\u001b[0;32m    643\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m       \u001b[0mconv_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mconv_out\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Downscale_env\\lib\\site-packages\\keras\\backend.py\u001b[0m in \u001b[0;36mbias_add\u001b[1;34m(x, bias, data_format)\u001b[0m\n\u001b[0;32m   6322\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'channels_first'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'NCHW'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6324\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'NHWC'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6325\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'channels_first'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mbias_add\u001b[1;34m(value, bias, data_format, name)\u001b[0m\n\u001b[0;32m   3521\u001b[0m       \u001b[0mbias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"bias\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3523\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_nn_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mbias_add\u001b[1;34m(value, bias, data_format, name)\u001b[0m\n\u001b[0;32m    672\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m--> 674\u001b[1;33m         _ctx, \"BiasAdd\", name, value, bias, \"data_format\", data_format)\n\u001b[0m\u001b[0;32m    675\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while 1 > 0:\n",
    "    print(meta_learner._train_on_batch(3, use_test_for_meta=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 10, 80)\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 2, 20, 80)\n",
      "<class 'numpy.ndarray'>\n",
      "(80,)\n",
      "<class 'numpy.ndarray'>\n",
      "(2, 2, 1, 20)\n",
      "<class 'numpy.ndarray'>\n",
      "(20,)\n",
      "<class 'numpy.ndarray'>\n",
      "(1,)\n",
      "<class 'numpy.ndarray'>\n",
      "(1,)\n",
      "<class 'numpy.ndarray'>\n",
      "(1,)\n",
      "<class 'numpy.ndarray'>\n",
      "(1,)\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 30)\n",
      "<class 'numpy.ndarray'>\n",
      "(30,)\n",
      "<class 'numpy.ndarray'>\n",
      "(1830, 10000)\n",
      "<class 'numpy.ndarray'>\n",
      "(10000,)\n",
      "<class 'numpy.ndarray'>\n",
      "(1830, 10000)\n",
      "<class 'numpy.ndarray'>\n",
      "(10000,)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "for t in MDN_model.get_weights():\n",
    "    print(t.shape)\n",
    "    print(type(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 10, 80)\n",
      "(1, 2, 20, 80)\n",
      "(80,)\n",
      "(2, 2, 1, 20)\n",
      "(20,)\n",
      "(1,)\n",
      "(1,)\n",
      "(1, 30)\n",
      "(30,)\n",
      "(1830, 10000)\n",
      "(10000,)\n",
      "(1830, 10000)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "for t in MDN_model.trainable_variables:\n",
    "    print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7485470997143776"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Downscale_env",
   "language": "python",
   "name": "downscale_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
